

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>core.torch_agent &mdash; ParlAI  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/parlai_theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="core.build_data" href="build_data.html" />
    <link rel="prev" title="core.agents" href="agents.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> ParlAI
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorial_quick.html">ParlAI Quick-start</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_basic.html">Intro to ParlAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_task.html">Tasks and Datasets in ParlAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_worlds.html">Data Handling, Batching, and Hogwild</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_seq2seq.html">Creating an Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_torch_ranker_agent.html">Using Torch Ranker Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_tipsntricks.html">Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_mturk.html">Using Mechanical Turk</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_messenger.html">Using Facebook Messenger</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_tensorboard.html">Using tensorboard for metric tracking</a></li>
</ul>
<p class="caption"><span class="caption-text">Tasks &amp; Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="zoo.html">Model Zoo</a></li>
</ul>
<p class="caption"><span class="caption-text">Core Library</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="observations.html">observations</a></li>
<li class="toctree-l1"><a class="reference internal" href="agents.html">core.agents</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">core.torch_agent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-parlai.core.torch_agent">Torch Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-parlai.core.torch_ranker_agent">Torch Ranker Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-parlai.core.torch_generator_agent">Torch Generator Agent</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="build_data.html">core.build_data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dict.html">core.dict</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">core.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="params.html">core.params</a></li>
<li class="toctree-l1"><a class="reference internal" href="teachers.html">core.teachers</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">core.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="thread_utils.html">core.thread_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="worlds.html">core.worlds</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="repeat_label.html">agents.repeat_label</a></li>
<li class="toctree-l1"><a class="reference internal" href="unigram_agent.html">agents.unigram</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_seq2seq.html">agents.example_seq2seq</a></li>
</ul>
<p class="caption"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cli_usage.html">Command Line Usage</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ParlAI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>core.torch_agent</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/torch_agent.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="core-torch-agent">
<h1>core.torch_agent<a class="headerlink" href="#core-torch-agent" title="Permalink to this headline">¶</a></h1>
<p>Torch Agent implements much of the boilerplate necessary for creating
a neural dialogue agent, so you can focus on modeling. Torch Agent limits its
functionality to maintaining dialogue history, transforming text into vectors of
indicies, and loading/saving models. The user is required to implement their own
logic in methods like <cite>train_step</cite> and <cite>eval_step</cite>.</p>
<p>Torch Ranker Agent and Torch Generator have more specialized stub methods, and provide
many rich features and benefits. Torch Ranker Agent assumes your model ranks possible
responses from a set of possible candidates, and provides options around negative
sampling, candidate sampling, and large-scale candidate prediction. Torch Generator
Agent assumes your model generates utterances auto-regressively, and provides
generic implementations of beam search.</p>
<div class="section" id="module-parlai.core.torch_agent">
<span id="torch-agent"></span><h2>Torch Agent<a class="headerlink" href="#module-parlai.core.torch_agent" title="Permalink to this headline">¶</a></h2>
<p>General utility code for building PyTorch-based agents in ParlAI.</p>
<p>Contains the following main utilities:</p>
<ul class="simple">
<li><p>TorchAgent class which serves as a useful parent class for other model agents</p></li>
<li><p>Batch namedtuple which is the input type of the main abstract methods of
the TorchAgent class</p></li>
<li><p>Output namedtuple which is the expected output type of the main abstract
methods of the TorchAgent class</p></li>
</ul>
<p>See below for documentation on each specific tool.</p>
<dl class="class">
<dt id="parlai.core.torch_agent.Batch">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_agent.</code><code class="sig-name descname">Batch</code><span class="sig-paren">(</span><em class="sig-param">text_vec=None</em>, <em class="sig-param">text_lengths=None</em>, <em class="sig-param">label_vec=None</em>, <em class="sig-param">label_lengths=None</em>, <em class="sig-param">labels=None</em>, <em class="sig-param">valid_indices=None</em>, <em class="sig-param">candidates=None</em>, <em class="sig-param">candidate_vecs=None</em>, <em class="sig-param">image=None</em>, <em class="sig-param">observations=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.Batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="utils.html#parlai.utils.misc.AttrDict" title="parlai.utils.misc.AttrDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.utils.misc.AttrDict</span></code></a></p>
<p>Batch is a namedtuple containing data being sent to an agent.</p>
<p>This is the input type of the train_step and eval_step functions.
Agents can override the batchify function to return an extended namedtuple
with additional fields if they would like, though we recommend calling the
parent function to set up these fields as a base.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text_vec</strong> – bsz x seqlen tensor containing the parsed text data.</p></li>
<li><p><strong>text_lengths</strong> – list of length bsz containing the lengths of the text in same order as
text_vec; necessary for pack_padded_sequence.</p></li>
<li><p><strong>label_vec</strong> – bsz x seqlen tensor containing the parsed label (one per batch row).</p></li>
<li><p><strong>label_lengths</strong> – list of length bsz containing the lengths of the labels in same order as
label_vec.</p></li>
<li><p><strong>labels</strong> – list of length bsz containing the selected label for each batch row (some
datasets have multiple labels per input example).</p></li>
<li><p><strong>valid_indices</strong> – list of length bsz containing the original indices of each example in the
batch. we use these to map predictions back to their proper row, since e.g.
we may sort examples by their length or some examples may be invalid.</p></li>
<li><p><strong>candidates</strong> – list of lists of text. outer list has size bsz, inner lists vary in size
based on the number of candidates for each row in the batch.</p></li>
<li><p><strong>candidate_vecs</strong> – list of lists of tensors. outer list has size bsz, inner lists vary in size
based on the number of candidates for each row in the batch.</p></li>
<li><p><strong>image</strong> – list of image features in the format specified by the –image-mode arg.</p></li>
<li><p><strong>observations</strong> – the original observations in the batched order</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="parlai.core.torch_agent.Batch.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">text_vec=None</em>, <em class="sig-param">text_lengths=None</em>, <em class="sig-param">label_vec=None</em>, <em class="sig-param">label_lengths=None</em>, <em class="sig-param">labels=None</em>, <em class="sig-param">valid_indices=None</em>, <em class="sig-param">candidates=None</em>, <em class="sig-param">candidate_vecs=None</em>, <em class="sig-param">image=None</em>, <em class="sig-param">observations=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.Batch.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize AttrDict using input dict.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_agent.Output">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_agent.</code><code class="sig-name descname">Output</code><span class="sig-paren">(</span><em class="sig-param">text=None</em>, <em class="sig-param">text_candidates=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.Output" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="utils.html#parlai.utils.misc.AttrDict" title="parlai.utils.misc.AttrDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.utils.misc.AttrDict</span></code></a></p>
<p>Output is an object containing agent predictions.</p>
<p>This is the expected return type of the train_step and eval_step functions,
though agents can choose to return None if they do not want to answer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of strings of length bsz containing the predictions of the model</p></li>
<li><p><strong>text_candidates</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em>) – list of lists of length bsz containing ranked predictions of the model.
each sub-list is an ordered ranking of strings, of variable length.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="parlai.core.torch_agent.Output.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">text=None</em>, <em class="sig-param">text_candidates=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.Output.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize AttrDict using input dict.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_agent.History">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_agent.</code><code class="sig-name descname">History</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">field='text'</em>, <em class="sig-param">vec_type='deque'</em>, <em class="sig-param">maxlen=None</em>, <em class="sig-param">size=-1</em>, <em class="sig-param">p1_token='__p1__'</em>, <em class="sig-param">p2_token='__p2__'</em>, <em class="sig-param">dict_agent=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>History handles tracking the dialogue state over the course of an episode.</p>
<p>History may also be used to track the history of any field.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>field</strong> – field in the observation to track over the course of the episode
(defaults to ‘text’)</p></li>
<li><p><strong>vec_type</strong> – specify a ‘list’ or ‘deque’ to save the history in this object</p></li>
<li><p><strong>maxlen</strong> – if <cite>vec_type</cite> is ‘deque’, this sets the maximum length of that object</p></li>
<li><p><strong>p1_token</strong> – token indicating ‘person 1’; opt must have ‘person_tokens’ set to True
for this to be added</p></li>
<li><p><strong>p1_token</strong> – token indicating ‘person 2’; opt must have ‘person_tokens’ set to True
for this to be added</p></li>
<li><p><strong>dict_agent</strong> – DictionaryAgent object for tokenizing the history</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="parlai.core.torch_agent.History.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">field='text'</em>, <em class="sig-param">vec_type='deque'</em>, <em class="sig-param">maxlen=None</em>, <em class="sig-param">size=-1</em>, <em class="sig-param">p1_token='__p1__'</em>, <em class="sig-param">p2_token='__p2__'</em>, <em class="sig-param">dict_agent=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.History.parse">
<code class="sig-name descname">parse</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History.parse" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize text with the given dictionary.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.History.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the history.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.History.update_history">
<code class="sig-name descname">update_history</code><span class="sig-paren">(</span><em class="sig-param">obs</em>, <em class="sig-param">add_next=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History.update_history" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the history with the given observation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>add_next</strong> – string to append to history prior to updating it with the
observation</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.History.get_history_str">
<code class="sig-name descname">get_history_str</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History.get_history_str" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the string version of the history.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.History.get_history_vec">
<code class="sig-name descname">get_history_vec</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History.get_history_vec" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a vectorized version of the history.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.History.get_history_vec_list">
<code class="sig-name descname">get_history_vec_list</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.History.get_history_vec_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list of history vecs.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_agent.TorchAgent">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_agent.</code><code class="sig-name descname">TorchAgent</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">shared=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code>, <a class="reference internal" href="agents.html#parlai.core.agents.Agent" title="parlai.core.agents.Agent"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.core.agents.Agent</span></code></a></p>
<p>A provided abstract base agent for any model that wants to use Torch.</p>
<p>Exists to make it easier to implement a new agent.
Not necessary, but reduces duplicated code.</p>
<p>Many methods are intended to be either used as is when the default is
acceptable, or to be overriden and called with super(), with the extra
functionality added to the initial result. See the method comment for
recommended behavior.</p>
<p>This agent serves as a common framework for all ParlAI models which want
to use PyTorch.</p>
<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.optim_opts">
<em class="property">classmethod </em><code class="sig-name descname">optim_opts</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.optim_opts" title="Permalink to this definition">¶</a></dt>
<dd><p>Fetch optimizer selection.</p>
<p>By default, collects everything in torch.optim, as well as importing:
- qhm / qhmadam if installed from github.com/facebookresearch/qhoptim</p>
<p>Override this (and probably call super()) to add your own optimizers.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.dictionary_class">
<em class="property">static </em><code class="sig-name descname">dictionary_class</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.dictionary_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the dictionary class that this agent expects to use.</p>
<p>Can be overriden if a more complex dictionary is required.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.history_class">
<em class="property">classmethod </em><code class="sig-name descname">history_class</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.history_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the history class that this agent expects to use.</p>
<p>Can be overriden if a more complex history is required.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.add_cmdline_args">
<em class="property">classmethod </em><code class="sig-name descname">add_cmdline_args</code><span class="sig-paren">(</span><em class="sig-param">argparser</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.add_cmdline_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Add the default commandline args we expect most agents to want.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">shared=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize agent.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.build_history">
<code class="sig-name descname">build_history</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.build_history" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the constructed history object.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.build_dictionary">
<code class="sig-name descname">build_dictionary</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.build_dictionary" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the constructed dictionary, which will be set to self.dict.</p>
<p>If you need to add additional tokens to the dictionary, this is likely
the right place to do it.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.build_model">
<code class="sig-name descname">build_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.build_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct the model and return it.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.init_optim">
<code class="sig-name descname">init_optim</code><span class="sig-paren">(</span><em class="sig-param">params</em>, <em class="sig-param">optim_states=None</em>, <em class="sig-param">saved_optim_type=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.init_optim" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize optimizer with model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – parameters from the model</p></li>
<li><p><strong>optim_states</strong> – optional argument providing states of optimizer to load</p></li>
<li><p><strong>saved_optim_type</strong> – type of optimizer being loaded, if changed will skip loading
optimizer states</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.build_lr_scheduler">
<code class="sig-name descname">build_lr_scheduler</code><span class="sig-paren">(</span><em class="sig-param">states=None</em>, <em class="sig-param">hard_reset=False</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.build_lr_scheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the learning rate scheduler, and assign it to self.scheduler.</p>
<p>This scheduler will be updated upon a call to receive_metrics.
May also create self.warmup_scheduler, if appropriate.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> (<em>state_dict</em>) – Possible state_dict provided by model
checkpoint, for restoring LR state</p></li>
<li><p><strong>hard_reset</strong> (<em>bool</em>) – If true, the LR scheduler should ignore the
state dictionary.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Report metrics.</p>
<p>Report includes learning rate and number of training updates.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.receive_metrics">
<code class="sig-name descname">receive_metrics</code><span class="sig-paren">(</span><em class="sig-param">metrics_dict</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.receive_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the metrics to decide when to adjust LR schedule.</p>
<p>This uses the loss as the validation metric if present, if not this
function does nothing. Note that the model must be reporting loss for
this to work.</p>
<p>Override this to override the behavior.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.share">
<code class="sig-name descname">share</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.share" title="Permalink to this definition">¶</a></dt>
<dd><p>Share fields from parent as well as useful objects in this class.</p>
<p>Subclasses will likely want to share their model as well.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.vectorize">
<code class="sig-name descname">vectorize</code><span class="sig-paren">(</span><em class="sig-param">obs</em>, <em class="sig-param">history</em>, <em class="sig-param">add_start=True</em>, <em class="sig-param">add_end=True</em>, <em class="sig-param">text_truncate=None</em>, <em class="sig-param">label_truncate=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.vectorize" title="Permalink to this definition">¶</a></dt>
<dd><p>Make vectors out of observation fields and store in the observation.</p>
<p>In particular, the ‘text’ and ‘labels’/’eval_labels’ fields are
processed and a new field is added to the observation with the suffix
‘_vec’.</p>
<p>If you want to use additional fields on your subclass, you can override
this function, call super().vectorize(…) to process the text and
labels, and then process the other fields in your subclass.</p>
<p>Additionally, if you want to override some of these default parameters,
then we recommend using a pattern like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">vectorize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;add_start&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> – Single observation from observe function.</p></li>
<li><p><strong>add_start</strong> – default True, adds the start token to each label.</p></li>
<li><p><strong>add_end</strong> – default True, adds the end token to each label.</p></li>
<li><p><strong>text_truncate</strong> – default None, if set truncates text vectors to the specified
length.</p></li>
<li><p><strong>label_truncate</strong> – default None, if set truncates label vectors to the specified
length.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the input observation, with ‘text_vec’, ‘label_vec’, and
‘cands_vec’ fields added.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.is_valid">
<code class="sig-name descname">is_valid</code><span class="sig-paren">(</span><em class="sig-param">obs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.is_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine if an observation is valid or not.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.batchify">
<code class="sig-name descname">batchify</code><span class="sig-paren">(</span><em class="sig-param">obs_batch</em>, <em class="sig-param">sort=False</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.batchify" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a batch of valid observations from an unchecked batch.</p>
<p>A valid observation is one that passes the lambda provided to the
function, which defaults to checking if the preprocessed ‘text_vec’
field is present which would have been set by this agent’s ‘vectorize’
function.</p>
<p>Returns a namedtuple Batch. See original definition above for in-depth
explanation of each field.</p>
<p>If you want to include additonal fields in the batch, you can subclass
this function and return your own “Batch” namedtuple: copy the Batch
namedtuple at the top of this class, and then add whatever additional
fields that you want to be able to access. You can then call
super().batchify(…) to set up the original fields and then set up the
additional fields in your subclass and return that batch instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs_batch</strong> – List of vectorized observations</p></li>
<li><p><strong>sort</strong> – Default False, orders the observations by length of vectors. Set to
true when using torch.nn.utils.rnn.pack_padded_sequence.  Uses the text
vectors if available, otherwise uses the label vectors if available.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.match_batch">
<code class="sig-name descname">match_batch</code><span class="sig-paren">(</span><em class="sig-param">batch_reply</em>, <em class="sig-param">valid_inds</em>, <em class="sig-param">output=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.match_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Match sub-batch of predictions to the original batch indices.</p>
<p>Batches may be only partially filled (i.e when completing the remainder
at the end of the validation or test set), or we may want to sort by
e.g the length of the input sequences if using pack_padded_sequence.</p>
<p>This matches rows back with their original row in the batch for
calculating metrics like accuracy.</p>
<p>If output is None (model choosing not to provide any predictions), we
will just return the batch of replies.</p>
<p>Otherwise, output should be a parlai.core.torch_agent.Output object.
This is a namedtuple, which can provide text predictions and/or
text_candidates predictions. If you would like to map additional
fields into the batch_reply, you can override this method as well as
providing your own namedtuple with additional fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_reply</strong> – Full-batchsize list of message dictionaries to put responses into.</p></li>
<li><p><strong>valid_inds</strong> – Original indices of the predictions.</p></li>
<li><p><strong>output</strong> – Output namedtuple which contains sub-batchsize list of text outputs
from model. May be None (default) if model chooses not to answer.
This method will check for <code class="docutils literal notranslate"><span class="pre">text</span></code> and <code class="docutils literal notranslate"><span class="pre">text_candidates</span></code> fields.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.last_reply">
<code class="sig-name descname">last_reply</code><span class="sig-paren">(</span><em class="sig-param">use_reply='label'</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.last_reply" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieve the last reply from the model.</p>
<p>If available, we use the true label instead of the model’s prediction.</p>
<p>By default, batch_act stores the batch of replies and this method
will extract the reply of the current instance from the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>use_label</strong> – default true, use the label when available instead of the model’s
generated response.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.observe">
<code class="sig-name descname">observe</code><span class="sig-paren">(</span><em class="sig-param">observation</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.observe" title="Permalink to this definition">¶</a></dt>
<dd><p>Process incoming message in preparation for producing a response.</p>
<p>This includes remembering the past history of the conversation.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the state dict for saving.</p>
<p>Override this method for more specific saving.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">path=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save model parameters to path (or default to model_file arg).</p>
<p>Please try to refrain from overriding this function, and instead
override <cite>state_dict(self)</cite> for more specific saving.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param">state_dict</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the state dict into model.</p>
<p>This is easily overridable to facilitate transfer of state dicts.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Return opt and model states.</p>
<p>Override this method for more specific loading.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear internal states.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.reset_metrics">
<code class="sig-name descname">reset_metrics</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.reset_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset all TorchAgentMetrics.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.act">
<code class="sig-name descname">act</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.act" title="Permalink to this definition">¶</a></dt>
<dd><p>Call batch_act with the singleton batch.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.batch_act">
<code class="sig-name descname">batch_act</code><span class="sig-paren">(</span><em class="sig-param">observations</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.batch_act" title="Permalink to this definition">¶</a></dt>
<dd><p>Process a batch of observations (batchsize list of message dicts).</p>
<p>These observations have been preprocessed by the observe method.</p>
<p>Subclasses can override this for special functionality, but if the
default behaviors are fine then just override the <code class="docutils literal notranslate"><span class="pre">train_step</span></code> and
<code class="docutils literal notranslate"><span class="pre">eval_step</span></code> methods instead. The former is called when labels are
present in the observations batch; otherwise, the latter is called.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.train_step">
<em class="property">abstract </em><code class="sig-name descname">train_step</code><span class="sig-paren">(</span><em class="sig-param">batch</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.train_step" title="Permalink to this definition">¶</a></dt>
<dd><p>[Abstract] Process one batch with training labels.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.eval_step">
<em class="property">abstract </em><code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">batch</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>[Abstract] Process one batch but do not train on it.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.set_interactive_mode">
<code class="sig-name descname">set_interactive_mode</code><span class="sig-paren">(</span><em class="sig-param">mode</em>, <em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.set_interactive_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Set interactive mode on or off.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.backward">
<code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">loss</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a backward pass.</p>
<p>It is recommended you use this instead of
loss.backward(), for integration with distributed training and FP16
training.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.update_params">
<code class="sig-name descname">update_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.update_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform step of optimization.</p>
<p>Handles clipping gradients and adjusting LR schedule if needed.
Gradient accumulation is also performed if agent is called with
–update-freq.</p>
<p>It is recommended (but not forced) that you call this in train_step.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_agent.TorchAgent.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_agent.TorchAgent.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Zero out optimizer.</p>
<p>It is recommended you call this in train_step. It automatically handles
gradient accumulation if agent is called with –update-freq.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-parlai.core.torch_ranker_agent">
<span id="torch-ranker-agent"></span><h2>Torch Ranker Agent<a class="headerlink" href="#module-parlai.core.torch_ranker_agent" title="Permalink to this headline">¶</a></h2>
<p>Torch Ranker Agents provide functionality for building ranking models.</p>
<p>See the TorchRankerAgent tutorial for examples.</p>
<dl class="class">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_ranker_agent.</code><code class="sig-name descname">TorchRankerAgent</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">shared=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#parlai.core.torch_agent.TorchAgent" title="parlai.core.torch_agent.TorchAgent"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.core.torch_agent.TorchAgent</span></code></a></p>
<p>Abstract TorchRankerAgent class; only meant to be extended.</p>
<p>TorchRankerAgents aim to provide convenient functionality for building ranking
models. This includes:</p>
<ul class="simple">
<li><p>Training/evaluating on candidates from a variety of sources.</p></li>
<li><p>Computing hits&#64;1, hits&#64;5, mean reciprical rank (MRR), and other metrics.</p></li>
<li><p>Caching representations for fast runtime when deploying models to production.</p></li>
</ul>
<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.add_cmdline_args">
<em class="property">classmethod </em><code class="sig-name descname">add_cmdline_args</code><span class="sig-paren">(</span><em class="sig-param">argparser</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.add_cmdline_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Add CLI args.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">shared=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize agent.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.build_criterion">
<code class="sig-name descname">build_criterion</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.build_criterion" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return the loss function.</p>
<p>By default torch.nn.CrossEntropyLoss.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.set_interactive_mode">
<code class="sig-name descname">set_interactive_mode</code><span class="sig-paren">(</span><em class="sig-param">mode</em>, <em class="sig-param">shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.set_interactive_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Set interactive mode on or off.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.score_candidates">
<em class="property">abstract </em><code class="sig-name descname">score_candidates</code><span class="sig-paren">(</span><em class="sig-param">batch</em>, <em class="sig-param">cand_vecs</em>, <em class="sig-param">cand_encs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.score_candidates" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a batch and candidate set, return scores (for ranking).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<a class="reference internal" href="#parlai.core.torch_agent.Batch" title="parlai.core.torch_agent.Batch"><em>Batch</em></a>) – a Batch object (defined in torch_agent.py)</p></li>
<li><p><strong>cand_vecs</strong> (<em>LongTensor</em>) – padded and tokenized candidates</p></li>
<li><p><strong>cand_encs</strong> (<em>FloatTensor</em>) – encoded candidates, if these are passed into the function (in cases
where we cache the candidate encodings), you do not need to call
self.model on cand_vecs</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.is_valid">
<code class="sig-name descname">is_valid</code><span class="sig-paren">(</span><em class="sig-param">obs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.is_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>Override from TorchAgent.</p>
<p>Check to see if label candidates contain the label.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.train_step">
<code class="sig-name descname">train_step</code><span class="sig-paren">(</span><em class="sig-param">batch</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.train_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Train on a single batch of examples.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">batch</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate a single batch of examples.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.block_repeats">
<code class="sig-name descname">block_repeats</code><span class="sig-paren">(</span><em class="sig-param">cand_preds</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.block_repeats" title="Permalink to this definition">¶</a></dt>
<dd><p>Heuristic to block a model repeating a line from the history.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.share">
<code class="sig-name descname">share</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.share" title="Permalink to this definition">¶</a></dt>
<dd><p>Share model parameters.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.reset_metrics">
<code class="sig-name descname">reset_metrics</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.reset_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset metrics.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Report loss and mean_rank from model’s perspective.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.set_vocab_candidates">
<code class="sig-name descname">set_vocab_candidates</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.set_vocab_candidates" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the tokens from the vocab as candidates.</p>
<p>self.vocab_candidates will contain a [num_cands] list of strings
self.vocab_candidate_vecs will contain a [num_cands, 1] LongTensor</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.set_fixed_candidates">
<code class="sig-name descname">set_fixed_candidates</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.set_fixed_candidates" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a set of fixed candidates and their vectors (or vectorize them here).</p>
<p>self.fixed_candidates will contain a [num_cands] list of strings
self.fixed_candidate_vecs will contain a [num_cands, seq_len] LongTensor</p>
<p>See the note on the –fixed-candidate-vecs flag for an explanation of the
‘reuse’, ‘replace’, or path options.</p>
<p>Note: TorchRankerAgent by default converts candidates to vectors by vectorizing
in the common sense (i.e., replacing each token with its index in the
dictionary). If a child model wants to additionally perform encoding, it can
overwrite the vectorize_fixed_candidates() method to produce encoded vectors
instead of just vectorized ones.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.load_candidates">
<code class="sig-name descname">load_candidates</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">cand_type='vectors'</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.load_candidates" title="Permalink to this definition">¶</a></dt>
<dd><p>Load fixed candidates from a path.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.encode_candidates">
<code class="sig-name descname">encode_candidates</code><span class="sig-paren">(</span><em class="sig-param">padded_cands</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.encode_candidates" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the given candidates to vectors.</p>
<p>This is an abstract method that must be implemented by the user.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padded_cands</strong> – The padded candidates.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_ranker_agent.TorchRankerAgent.vectorize_fixed_candidates">
<code class="sig-name descname">vectorize_fixed_candidates</code><span class="sig-paren">(</span><em class="sig-param">cands_batch</em>, <em class="sig-param">add_start=False</em>, <em class="sig-param">add_end=False</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_ranker_agent.TorchRankerAgent.vectorize_fixed_candidates" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a batch of candidates from text to vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cands_batch</strong> – a [batchsize] list of candidates (strings)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a [num_cands] list of candidate vectors</p>
</dd>
</dl>
<p>By default, candidates are simply vectorized (tokens replaced by token ids).
A child class may choose to overwrite this method to perform vectorization as
well as encoding if so desired.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-parlai.core.torch_generator_agent">
<span id="torch-generator-agent"></span><h2>Torch Generator Agent<a class="headerlink" href="#module-parlai.core.torch_generator_agent" title="Permalink to this headline">¶</a></h2>
<p>Generic PyTorch-based Generator agent.</p>
<p>Implements quite a bit of boilerplate, including forced-decoding loss and beam
search.</p>
<p>Contains the following utilities:</p>
<ul class="simple">
<li><p><cite>ref:TorchGeneratorAgent</cite> class, which serves as a useful parent for generative torch
agents.</p></li>
<li><p>Beam class which provides some generic beam functionality for classes to use</p></li>
</ul>
<dl class="class">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorModel">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_generator_agent.</code><code class="sig-name descname">TorchGeneratorModel</code><span class="sig-paren">(</span><em class="sig-param">padding_idx=0</em>, <em class="sig-param">start_idx=1</em>, <em class="sig-param">end_idx=2</em>, <em class="sig-param">unknown_idx=3</em>, <em class="sig-param">input_dropout=0</em>, <em class="sig-param">longest_label=1</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract TorchGeneratorModel.</p>
<p>This interface expects you to implement model with the following reqs:</p>
<dl class="field-list simple">
<dt class="field-odd">Attribute model.encoder</dt>
<dd class="field-odd"><p>takes input returns tuple (enc_out, enc_hidden, attn_mask)</p>
</dd>
<dt class="field-even">Attribute model.decoder</dt>
<dd class="field-even"><p>takes decoder params and returns decoder outputs after attn</p>
</dd>
<dt class="field-odd">Attribute model.output</dt>
<dd class="field-odd"><p>takes decoder outputs and returns distr over dictionary</p>
</dd>
</dl>
<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorModel.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">padding_idx=0</em>, <em class="sig-param">start_idx=1</em>, <em class="sig-param">end_idx=2</em>, <em class="sig-param">unknown_idx=3</em>, <em class="sig-param">input_dropout=0</em>, <em class="sig-param">longest_label=1</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorModel.decode_forced">
<code class="sig-name descname">decode_forced</code><span class="sig-paren">(</span><em class="sig-param">encoder_states</em>, <em class="sig-param">ys</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorModel.decode_forced" title="Permalink to this definition">¶</a></dt>
<dd><p>Decode with a fixed, true sequence, computing loss.</p>
<p>Useful for training, or ranking fixed candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>LongTensor</em><em>[</em><em>bsz</em><em>, </em><em>time</em><em>]</em>) – the prediction targets. Contains both the start and end tokens.</p></li>
<li><p><strong>encoder_states</strong> (<em>model specific</em>) – Output of the encoder. Model specific types.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>pair (logits, choices) containing the logits and MLE predictions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(FloatTensor[bsz, ys, vocab], LongTensor[bsz, ys])</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorModel.reorder_encoder_states">
<em class="property">abstract </em><code class="sig-name descname">reorder_encoder_states</code><span class="sig-paren">(</span><em class="sig-param">encoder_states</em>, <em class="sig-param">indices</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorModel.reorder_encoder_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Reorder encoder states according to a new set of indices.</p>
<p>This is an abstract method, and <em>must</em> be implemented by the user.</p>
<p>Its purpose is to provide beam search with a model-agnostic interface for
beam search. For example, this method is used to sort hypotheses,
expand beams, etc.</p>
<p>For example, assume that encoder_states is an bsz x 1 tensor of values</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">encoder_states</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">]</span>
                  <span class="p">[</span><span class="mf">0.2</span><span class="p">]</span>
                  <span class="p">[</span><span class="mf">0.3</span><span class="p">]]</span>
</pre></div>
</div>
<p>then the output will be</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">]</span>
          <span class="p">[</span><span class="mf">0.3</span><span class="p">]</span>
          <span class="p">[</span><span class="mf">0.3</span><span class="p">]]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_states</strong> (<em>model specific</em>) – output from encoder. type is model specific.</p></li>
<li><p><strong>indices</strong> (<em>list</em><em>[</em><em>int</em><em>]</em>) – the indices to select over. The user must support non-tensor
inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The re-ordered encoder states. It should be of the same type as
encoder states, and it must be a valid input to the decoder.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model specific</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorModel.reorder_decoder_incremental_state">
<em class="property">abstract </em><code class="sig-name descname">reorder_decoder_incremental_state</code><span class="sig-paren">(</span><em class="sig-param">incremental_state</em>, <em class="sig-param">inds</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorModel.reorder_decoder_incremental_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Reorder incremental state for the decoder.</p>
<p>Used to expand selected beams in beam search. Unlike reorder_encoder_states,
implementing this method is optional. However, without incremental decoding,
decoding a single beam becomes O(n^2) instead of O(n), which can make
beam search impractically slow.</p>
<p>In order to fall back to non-incremental decoding, just return None from this
method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>incremental_state</strong> (<em>model specific</em>) – second output of model.decoder</p></li>
<li><p><strong>inds</strong> (<em>LongTensor</em><em>[</em><em>n</em><em>]</em>) – indices to select and reorder over.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The re-ordered decoder incremental states. It should be the same
type as incremental_state, and usable as an input to the decoder.
This method should return None if the model does not support
incremental decoding.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model specific</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*xs</em>, <em class="sig-param">ys=None</em>, <em class="sig-param">prev_enc=None</em>, <em class="sig-param">maxlen=None</em>, <em class="sig-param">bsz=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Get output predictions from the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>LongTensor</em><em>[</em><em>bsz</em><em>, </em><em>seqlen</em><em>]</em>) – input to the encoder</p></li>
<li><p><strong>ys</strong> (<em>LongTensor</em><em>[</em><em>bsz</em><em>, </em><em>outlen</em><em>]</em>) – Expected output from the decoder. Used
for teacher forcing to calculate loss.</p></li>
<li><p><strong>prev_enc</strong> – if you know you’ll pass in the same xs multiple times, you can pass
in the encoder output from the last forward pass to skip
recalcuating the same encoder output.</p></li>
<li><p><strong>maxlen</strong> – max number of tokens to decode. if not set, will use the length of
the longest label this model has seen. ignored when ys is not None.</p></li>
<li><p><strong>bsz</strong> – if ys is not provided, then you must specify the bsz for greedy
decoding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>(scores, candidate_scores, encoder_states) tuple</p>
<ul class="simple">
<li><p>scores contains the model’s predicted token scores.
(FloatTensor[bsz, seqlen, num_features])</p></li>
<li><p>candidate_scores are the score the model assigned to each candidate.
(FloatTensor[bsz, num_cands])</p></li>
<li><p>encoder_states are the output of model.encoder. Model specific types.
Feed this back in to skip encoding on the next call.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_generator_agent.</code><code class="sig-name descname">TorchGeneratorAgent</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">shared=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#parlai.core.torch_agent.TorchAgent" title="parlai.core.torch_agent.TorchAgent"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.core.torch_agent.TorchAgent</span></code></a></p>
<p>Abstract Generator agent; only meant to be extended.</p>
<p>TorchGeneratorAgent aims to handle much of the bookkeeping and
infrastructure work for any generative models, like seq2seq or transformer.
It implements the train_step and eval_step. The only requirement is that
your model <em>must</em> implemented the interface TorchGeneratorModel interface.</p>
<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.upgrade_opt">
<em class="property">classmethod </em><code class="sig-name descname">upgrade_opt</code><span class="sig-paren">(</span><em class="sig-param">opt_from_disk</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.upgrade_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Upgrade legacy options when loading an opt file from disk.</p>
<p>This is primarily made available to provide a safe space to handle
backwards-compatible behavior. For example, perhaps we introduce a
new option today, which wasn’t previously available. We can have the
argument have a new default, but fall back to the “legacy” compatibility
behavior if the option doesn’t exist.</p>
<p><code class="docutils literal notranslate"><span class="pre">upgrade_opt</span></code> provides an opportunity for such checks for backwards
compatibility. It is called shortly after loading the opt file from
disk, and is called before the Agent is initialized.</p>
<p>Other possible examples include:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Renaming an option,</p></li>
<li><p>Deprecating an old option,</p></li>
<li><p>Splitting coupled behavior, etc.</p></li>
</ol>
</div></blockquote>
<p>Implementations of <code class="docutils literal notranslate"><span class="pre">upgrade_opt</span></code> should conform to high standards,
due to the risk of these methods becoming complicated and difficult to
reason about. We recommend the following behaviors:</p>
<blockquote>
<div><p>1. <code class="docutils literal notranslate"><span class="pre">upgrade_opt</span></code> should only be used to provide backwards
compatibility.  Other behavior should find a different location.
2. Children should always call the parent’s <code class="docutils literal notranslate"><span class="pre">upgrade_opt</span></code> first.
3. <code class="docutils literal notranslate"><span class="pre">upgrade_opt</span></code> should always warn when an option was overwritten.
4. Include comments annotating the date and purpose of each upgrade.
5. Add an integration test which ensures your old work behaves
appropriately.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>opt_from_disk</strong> (<a class="reference internal" href="utils.html#parlai.utils.misc.Opt" title="parlai.utils.misc.Opt"><em>Opt</em></a>) – The opt file, as loaded from the <code class="docutils literal notranslate"><span class="pre">.opt</span></code> file on disk.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The modified options</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="utils.html#parlai.utils.misc.Opt" title="parlai.utils.misc.Opt">Opt</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.add_cmdline_args">
<em class="property">classmethod </em><code class="sig-name descname">add_cmdline_args</code><span class="sig-paren">(</span><em class="sig-param">argparser</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.add_cmdline_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Add command line arguments.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">opt</em>, <em class="sig-param">shared=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize agent.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.build_criterion">
<code class="sig-name descname">build_criterion</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.build_criterion" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return the loss function.</p>
<p>By default torch.nn.CrossEntropyLoss.</p>
<p>If overridden, this model should produce a sum that can be used for a per-token loss.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.set_interactive_mode">
<code class="sig-name descname">set_interactive_mode</code><span class="sig-paren">(</span><em class="sig-param">mode</em>, <em class="sig-param">shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.set_interactive_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Turn on interactive mode.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.reset_metrics">
<code class="sig-name descname">reset_metrics</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.reset_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset metrics for reporting loss and perplexity.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.share">
<code class="sig-name descname">share</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.share" title="Permalink to this definition">¶</a></dt>
<dd><p>Share internal states between parent and child instances.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.report">
<code class="sig-name descname">report</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.report" title="Permalink to this definition">¶</a></dt>
<dd><p>Report loss and perplexity from model’s perspective.</p>
<p>Note that this includes predicting __END__ and __UNK__ tokens and may
differ from a truly independent measurement.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.vectorize">
<code class="sig-name descname">vectorize</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.vectorize" title="Permalink to this definition">¶</a></dt>
<dd><p>Override vectorize for generative models.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.compute_loss">
<code class="sig-name descname">compute_loss</code><span class="sig-paren">(</span><em class="sig-param">batch</em>, <em class="sig-param">return_output=False</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.compute_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute and return the loss for the given batch.</p>
<p>Easily overridable for customized loss functions.</p>
<p>If return_output is True, the full output from the call to self.model()
is also returned, via a (loss, model_output) pair.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.train_step">
<code class="sig-name descname">train_step</code><span class="sig-paren">(</span><em class="sig-param">batch</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.train_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Train on a single batch of examples.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TorchGeneratorAgent.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">batch</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TorchGeneratorAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate a single batch of examples.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_generator_agent.TreeSearch">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_generator_agent.</code><code class="sig-name descname">TreeSearch</code><span class="sig-paren">(</span><em class="sig-param">beam_size</em>, <em class="sig-param">padding_token=0</em>, <em class="sig-param">bos_token=1</em>, <em class="sig-param">eos_token=2</em>, <em class="sig-param">min_length=3</em>, <em class="sig-param">min_n_best=3</em>, <em class="sig-param">device='cpu'</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Abstract Tree Search class.</p>
<p>It keeps information about beam_size concurrent, developing hypotheses.
Concrete implementations make choices about which token to explore next at
each point in the tree. Different choices result in different generation
algorithms.</p>
<dl class="method">
<dt id="parlai.core.torch_generator_agent.TreeSearch.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">beam_size</em>, <em class="sig-param">padding_token=0</em>, <em class="sig-param">bos_token=1</em>, <em class="sig-param">eos_token=2</em>, <em class="sig-param">min_length=3</em>, <em class="sig-param">min_n_best=3</em>, <em class="sig-param">device='cpu'</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate Beam object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>beam_size</strong> – number of hypothesis in the beam</p></li>
<li><p><strong>padding_token</strong> – padding token ID</p></li>
<li><p><strong>bos_token</strong> – beginning of sentence token ID</p></li>
<li><p><strong>eos_token</strong> – end of sentence token ID</p></li>
<li><p><strong>min_length</strong> – minimum length of the predicted sequence</p></li>
<li><p><strong>min_n_best</strong> – Search will not be finished until a minimum number of utterances are
completed.</p></li>
<li><p><strong>device</strong> – What device to use for computations</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TreeSearch.get_output_from_current_step">
<code class="sig-name descname">get_output_from_current_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch.get_output_from_current_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the outputput at the current step.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TreeSearch.get_backtrack_from_current_step">
<code class="sig-name descname">get_backtrack_from_current_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch.get_backtrack_from_current_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the backtrack at the current step.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TreeSearch.select_paths">
<em class="property">abstract </em><code class="sig-name descname">select_paths</code><span class="sig-paren">(</span><em class="sig-param">logprobs</em>, <em class="sig-param">prior_scores</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch.select_paths" title="Permalink to this definition">¶</a></dt>
<dd><p>Select the next vocabulary item in these beams.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logprobs</strong> – a (beamsize x vocab) tensor of log probabilities. If this is the first
turn in the dialogue, it will be a (1 x vocab) tensor.</p></li>
<li><p><strong>prior_scores</strong> – a (beamsize) tensor of weights with the cumulative running
log-probability of each beam. If the first turn, it will be a (1) tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>a (hypothesis_ids, token_id, scores) tuple, where:</p>
<ul class="simple">
<li><p>hypothesis_ids is a LongTensor of hypotheses we’re extending. May have
repeats, but should always be (beamsize) long.</p></li>
<li><p>token_ids is a (beamsize) LongTensor of next-token choices for
each of the hypotheses.</p></li>
<li><p>scores is a (beamsize) Tensor with the updated cumulative log-probs
of each beam.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TreeSearch.advance">
<code class="sig-name descname">advance</code><span class="sig-paren">(</span><em class="sig-param">logprobs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch.advance" title="Permalink to this definition">¶</a></dt>
<dd><p>Advance the beam one step.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TreeSearch.is_done">
<code class="sig-name descname">is_done</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch.is_done" title="Permalink to this definition">¶</a></dt>
<dd><p>Return whether beam search is complete.</p>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TreeSearch.get_top_hyp">
<code class="sig-name descname">get_top_hyp</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TreeSearch.get_top_hyp" title="Permalink to this definition">¶</a></dt>
<dd><p>Get single best hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>hypothesis sequence and the final score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_generator_agent.GreedySearch">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_generator_agent.</code><code class="sig-name descname">GreedySearch</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.GreedySearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#parlai.core.torch_generator_agent.TreeSearch" title="parlai.core.torch_generator_agent.TreeSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.core.torch_generator_agent.TreeSearch</span></code></a></p>
<p>Greedy search.</p>
<p>Picks the highest probability utterance at each step.  Only works with
–beam-size 1.</p>
<dl class="method">
<dt id="parlai.core.torch_generator_agent.GreedySearch.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.GreedySearch.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate Beam object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>beam_size</strong> – number of hypothesis in the beam</p></li>
<li><p><strong>padding_token</strong> – padding token ID</p></li>
<li><p><strong>bos_token</strong> – beginning of sentence token ID</p></li>
<li><p><strong>eos_token</strong> – end of sentence token ID</p></li>
<li><p><strong>min_length</strong> – minimum length of the predicted sequence</p></li>
<li><p><strong>min_n_best</strong> – Search will not be finished until a minimum number of utterances are
completed.</p></li>
<li><p><strong>device</strong> – What device to use for computations</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.GreedySearch.select_paths">
<code class="sig-name descname">select_paths</code><span class="sig-paren">(</span><em class="sig-param">logprobs</em>, <em class="sig-param">prior_scores</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.GreedySearch.select_paths" title="Permalink to this definition">¶</a></dt>
<dd><p>Select the next vocabulary item in these beams.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logprobs</strong> – a (beamsize x vocab) tensor of log probabilities. If this is the first
turn in the dialogue, it will be a (1 x vocab) tensor.</p></li>
<li><p><strong>prior_scores</strong> – a (beamsize) tensor of weights with the cumulative running
log-probability of each beam. If the first turn, it will be a (1) tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>a (hypothesis_ids, token_id, scores) tuple, where:</p>
<ul class="simple">
<li><p>hypothesis_ids is a LongTensor of hypotheses we’re extending. May have
repeats, but should always be (beamsize) long.</p></li>
<li><p>token_ids is a (beamsize) LongTensor of next-token choices for
each of the hypotheses.</p></li>
<li><p>scores is a (beamsize) Tensor with the updated cumulative log-probs
of each beam.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_generator_agent.BeamSearch">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_generator_agent.</code><code class="sig-name descname">BeamSearch</code><span class="sig-paren">(</span><em class="sig-param">beam_size</em>, <em class="sig-param">padding_token=0</em>, <em class="sig-param">bos_token=1</em>, <em class="sig-param">eos_token=2</em>, <em class="sig-param">min_length=3</em>, <em class="sig-param">min_n_best=3</em>, <em class="sig-param">device='cpu'</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.BeamSearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#parlai.core.torch_generator_agent.TreeSearch" title="parlai.core.torch_generator_agent.TreeSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.core.torch_generator_agent.TreeSearch</span></code></a></p>
<p>Beam search.</p>
<dl class="method">
<dt id="parlai.core.torch_generator_agent.BeamSearch.select_paths">
<code class="sig-name descname">select_paths</code><span class="sig-paren">(</span><em class="sig-param">logprobs</em>, <em class="sig-param">prior_scores</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.BeamSearch.select_paths" title="Permalink to this definition">¶</a></dt>
<dd><p>Select the next vocabulary item in these beams.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_generator_agent.TopKSampling">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_generator_agent.</code><code class="sig-name descname">TopKSampling</code><span class="sig-paren">(</span><em class="sig-param">k</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TopKSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#parlai.core.torch_generator_agent.TreeSearch" title="parlai.core.torch_generator_agent.TreeSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.core.torch_generator_agent.TreeSearch</span></code></a></p>
<p>Top-K sampling (Fan et al., 2018).</p>
<p>Samples from a truncated distribution where only the most probable K words
are considered at each time.</p>
<p>Typical values of k are 2, 10, 50.</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/1805.04833">https://arxiv.org/abs/1805.04833</a> for details.</p>
<dl class="method">
<dt id="parlai.core.torch_generator_agent.TopKSampling.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">k</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TopKSampling.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate Beam object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>beam_size</strong> – number of hypothesis in the beam</p></li>
<li><p><strong>padding_token</strong> – padding token ID</p></li>
<li><p><strong>bos_token</strong> – beginning of sentence token ID</p></li>
<li><p><strong>eos_token</strong> – end of sentence token ID</p></li>
<li><p><strong>min_length</strong> – minimum length of the predicted sequence</p></li>
<li><p><strong>min_n_best</strong> – Search will not be finished until a minimum number of utterances are
completed.</p></li>
<li><p><strong>device</strong> – What device to use for computations</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.TopKSampling.select_paths">
<code class="sig-name descname">select_paths</code><span class="sig-paren">(</span><em class="sig-param">logprobs</em>, <em class="sig-param">prior_scores</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.TopKSampling.select_paths" title="Permalink to this definition">¶</a></dt>
<dd><p>Select the next vocabulary item in these beams.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logprobs</strong> – a (beamsize x vocab) tensor of log probabilities. If this is the first
turn in the dialogue, it will be a (1 x vocab) tensor.</p></li>
<li><p><strong>prior_scores</strong> – a (beamsize) tensor of weights with the cumulative running
log-probability of each beam. If the first turn, it will be a (1) tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>a (hypothesis_ids, token_id, scores) tuple, where:</p>
<ul class="simple">
<li><p>hypothesis_ids is a LongTensor of hypotheses we’re extending. May have
repeats, but should always be (beamsize) long.</p></li>
<li><p>token_ids is a (beamsize) LongTensor of next-token choices for
each of the hypotheses.</p></li>
<li><p>scores is a (beamsize) Tensor with the updated cumulative log-probs
of each beam.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="parlai.core.torch_generator_agent.NucleusSampling">
<em class="property">class </em><code class="sig-prename descclassname">parlai.core.torch_generator_agent.</code><code class="sig-name descname">NucleusSampling</code><span class="sig-paren">(</span><em class="sig-param">p</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.NucleusSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#parlai.core.torch_generator_agent.TreeSearch" title="parlai.core.torch_generator_agent.TreeSearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">parlai.core.torch_generator_agent.TreeSearch</span></code></a></p>
<p>Nucelus, aka top-p sampling (Holtzman et al., 2019).</p>
<p>Samples from a truncated distribution which covers a fixed CDF proportion
of the original distribution.</p>
<p>Typical values of p are 0.3 and 0.9.</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/1904.09751">https://arxiv.org/abs/1904.09751</a> for details.</p>
<dl class="method">
<dt id="parlai.core.torch_generator_agent.NucleusSampling.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">p</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.NucleusSampling.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate Beam object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>beam_size</strong> – number of hypothesis in the beam</p></li>
<li><p><strong>padding_token</strong> – padding token ID</p></li>
<li><p><strong>bos_token</strong> – beginning of sentence token ID</p></li>
<li><p><strong>eos_token</strong> – end of sentence token ID</p></li>
<li><p><strong>min_length</strong> – minimum length of the predicted sequence</p></li>
<li><p><strong>min_n_best</strong> – Search will not be finished until a minimum number of utterances are
completed.</p></li>
<li><p><strong>device</strong> – What device to use for computations</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parlai.core.torch_generator_agent.NucleusSampling.select_paths">
<code class="sig-name descname">select_paths</code><span class="sig-paren">(</span><em class="sig-param">logprobs</em>, <em class="sig-param">prior_scores</em><span class="sig-paren">)</span><a class="headerlink" href="#parlai.core.torch_generator_agent.NucleusSampling.select_paths" title="Permalink to this definition">¶</a></dt>
<dd><p>Select the next vocabulary item in these beams.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logprobs</strong> – a (beamsize x vocab) tensor of log probabilities. If this is the first
turn in the dialogue, it will be a (1 x vocab) tensor.</p></li>
<li><p><strong>prior_scores</strong> – a (beamsize) tensor of weights with the cumulative running
log-probability of each beam. If the first turn, it will be a (1) tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>a (hypothesis_ids, token_id, scores) tuple, where:</p>
<ul class="simple">
<li><p>hypothesis_ids is a LongTensor of hypotheses we’re extending. May have
repeats, but should always be (beamsize) long.</p></li>
<li><p>token_ids is a (beamsize) LongTensor of next-token choices for
each of the hypotheses.</p></li>
<li><p>scores is a (beamsize) Tensor with the updated cumulative log-probs
of each beam.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="build_data.html" class="btn btn-neutral float-right" title="core.build_data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="agents.html" class="btn btn-neutral float-left" title="core.agents" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Facebook AI Research

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>