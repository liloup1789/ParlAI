

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using Mechanical Turk &mdash; ParlAI  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/parlai_theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using Facebook Messenger" href="tutorial_messenger.html" />
    <link rel="prev" title="Tips and Tricks" href="tutorial_tipsntricks.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> ParlAI
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="tutorial_quick.html">ParlAI Quick-start</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_basic.html">Intro to ParlAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_task.html">Tasks and Datasets in ParlAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_worlds.html">Data Handling, Batching, and Hogwild</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_seq2seq.html">Creating an Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_torch_ranker_agent.html">Using Torch Ranker Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_tipsntricks.html">Tips and Tricks</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Using Mechanical Turk</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#example-tasks">Example Tasks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#task-1-collecting-data">Task 1: Collecting Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-2-evaluating-a-dialog-model">Task 2: Evaluating a Dialog Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-3-multi-agent-dialog">Task 3: Multi-Agent Dialog</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-4-advanced-functionality-deal-or-no-deal">Task 4: Advanced Functionality - Deal or No Deal</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-5-advanced-functionality-mturk-qualification-flow">Task 5: Advanced Functionality - MTurk Qualification Flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-6-advanced-functionality-react-task-demo">Task 6: Advanced Functionality - React Task Demo</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#creating-your-own-task">Creating Your Own Task</a></li>
<li class="toctree-l2"><a class="reference internal" href="#advanced-task-techniques">Advanced Task Techniques</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#custom-frontend-components">Custom Frontend Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="#displaying-task-context">Displaying Task Context</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#running-a-task">Running a Task</a></li>
<li class="toctree-l2"><a class="reference internal" href="#handling-turker-disconnects">Handling Turker Disconnects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reviewing-turker-s-work">Reviewing Turker’s Work</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parlai-mturk-tips-and-tricks">ParlAI-MTurk Tips and Tricks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#approving-work">Approving Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rejecting-work">Rejecting Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="#filtering-workers">Filtering Workers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#soft-blocking-vs-hard-blocking">Soft-blocking vs. Hard-blocking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preventing-and-handling-crashes">Preventing and Handling Crashes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-design">Task Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-tips">Other Tips</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#parlai-mturk-alpha-functionality">ParlAI-MTurk Alpha Functionality</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#running-the-parlai-mturk-webapp">Running the ParlAI-MTurk Webapp</a></li>
<li class="toctree-l3"><a class="reference internal" href="#testing-a-task-in-the-webapp">Testing a task in the webapp</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reviewing-tasks-in-the-webapp">Reviewing tasks in the webapp</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-and-loading-data-via-the-database">Saving and Loading data via the database</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_messenger.html">Using Facebook Messenger</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_tensorboard.html">Using tensorboard for metric tracking</a></li>
</ul>
<p class="caption"><span class="caption-text">Tasks &amp; Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="zoo.html">Model Zoo</a></li>
</ul>
<p class="caption"><span class="caption-text">Core Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="observations.html">observations</a></li>
<li class="toctree-l1"><a class="reference internal" href="agents.html">core.agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_agent.html">core.torch_agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="build_data.html">core.build_data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dict.html">core.dict</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">core.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="params.html">core.params</a></li>
<li class="toctree-l1"><a class="reference internal" href="teachers.html">core.teachers</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">core.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="thread_utils.html">core.thread_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="worlds.html">core.worlds</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="repeat_label.html">agents.repeat_label</a></li>
<li class="toctree-l1"><a class="reference internal" href="unigram_agent.html">agents.unigram</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_seq2seq.html">agents.example_seq2seq</a></li>
</ul>
<p class="caption"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cli_usage.html">Command Line Usage</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ParlAI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Using Mechanical Turk</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/tutorial_mturk.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="using-mechanical-turk">
<h1>Using Mechanical Turk<a class="headerlink" href="#using-mechanical-turk" title="Permalink to this headline">¶</a></h1>
<p><strong>Authors</strong>: Jack Urbanek, Emily Dinan, Will Feng</p>
<p>In ParlAI, you can use Amazon Mechanical Turk for <strong>data collection</strong>, <strong>training</strong>, or <strong>evaluation</strong> of your dialog model.</p>
<p>Human Turkers are viewed as just another type of agent in ParlAI; hence, agents in a group chat consisting of any number of humans and/or bots can communicate with each other within the same framework.</p>
<p>The human Turkers communicate in observation/action dict format, the same as all other agents in ParlAI. During the conversation, human Turkers receive a message that is rendered on the live chat webpage, such as the following:</p>
<div class="figure align-center" id="id1">
<img alt="_images/mturk-small.png" src="_images/mturk-small.png" />
<p class="caption"><span class="caption-text"><em>Example: Human Turker participating in a QA data collection task</em></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Each MTurk task has at least one human Turker that connects to ParlAI via the Mechanical Turk Live Chat interface, encapsulated as an <code class="docutils literal notranslate"><span class="pre">MTurkAgent</span></code> object.</p>
<p>Each MTurk task also consists of a <code class="docutils literal notranslate"><span class="pre">World</span></code> where all agents live and interact within.</p>
<div class="section" id="example-tasks">
<h2>Example Tasks<a class="headerlink" href="#example-tasks" title="Permalink to this headline">¶</a></h2>
<p>We provide a few examples of using Mechanical Turk with ParlAI:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/qa_data_collection/">QA Data Collection</a>: collect questions and answers from Turkers, given a random Wikipedia paragraph from SQuAD.</p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/model_evaluator/">Model Evaluator</a>: ask Turkers to evaluate the information retrieval baseline model on the Reddit movie dialog dataset.</p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/multi_agent_dialog/">Multi-Agent Dialog</a>: round-robin chat between a local human agent and two Turkers.</p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/dealnodeal/">Deal or No Deal</a>: negotiation chat between two agents over how to fairly divide a fixed set of items when each agent values the items differently.</p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/qualification_flow_example">Qualification Flow Example</a>: filter out workers from working on more instances of your task if they fail to complete a test instance properly.</p></li>
<li><p><a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/react_task_demo">React Task Demo</a>: Demo task for displaying custom components using the React frontend.</p></li>
</ul>
<div class="section" id="task-1-collecting-data">
<h3>Task 1: Collecting Data<a class="headerlink" href="#task-1-collecting-data" title="Permalink to this headline">¶</a></h3>
<p>One of the biggest use cases of Mechanical Turk is to collect natural language data from human Turkers.</p>
<p>As an example, the <a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/qa_data_collection/">QA Data Collection task</a> does the following:</p>
<ol class="arabic simple">
<li><p>Pick a random Wikipedia paragraph from SQuAD dataset.</p></li>
<li><p>Ask a Turker to provide a question given the paragraph.</p></li>
<li><p>Ask the same Turker to provide an answer to their question.</p></li>
</ol>
<p>In <code class="docutils literal notranslate"><span class="pre">QADataCollectionWorld</span></code>, there are two agents: one is the human Turker (<code class="docutils literal notranslate"><span class="pre">MTurkAgent</span></code>), the other is the task agent (<code class="docutils literal notranslate"><span class="pre">DefaultTeacher</span></code> from SQuAD) that provides the Wikipedia paragraph.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">QADataCollectionWorld</span></code> uses <code class="docutils literal notranslate"><span class="pre">turn_index</span></code> to denote what stage the conversation is at. One <em>turn</em> means that <code class="docutils literal notranslate"><span class="pre">world.parley()</span></code> has been called once.</p>
<p>After two turns, the task is finished, and the Turker’s work is submitted for review.</p>
</div>
<div class="section" id="task-2-evaluating-a-dialog-model">
<h3>Task 2: Evaluating a Dialog Model<a class="headerlink" href="#task-2-evaluating-a-dialog-model" title="Permalink to this headline">¶</a></h3>
<p>You can easily evaluate your dialog model’s performance with human Turkers using ParlAI. As an example, the <a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/model_evaluator/">Model Evaluator task</a> does the following:</p>
<ol class="arabic simple">
<li><p>Initialize a task world with a dialog model agent (<a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/agents/ir_baseline/ir_baseline.py#L98">ir_baseline</a>) and a dataset (<a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/tasks/moviedialog/agents.py#L57">MovieDD-Reddit</a>).</p></li>
<li><p>Let all the agents in the task world <code class="docutils literal notranslate"><span class="pre">observe()</span></code> and <code class="docutils literal notranslate"><span class="pre">act()</span></code> once, by calling <code class="docutils literal notranslate"><span class="pre">parley()</span></code> on the world.</p></li>
<li><p>Ask the human Turker to rate the dialog model agent’s response on a scale of 0-10.</p></li>
</ol>
<p>In <code class="docutils literal notranslate"><span class="pre">ModelEvaluatorWorld</span></code>, there are two main components: one is the <code class="docutils literal notranslate"><span class="pre">task_world</span></code> that contains the task and the dialog model we are evaluating, the other is the <code class="docutils literal notranslate"><span class="pre">MTurkAgent</span></code> which is an interface to the human Turker.</p>
<p>Note that since the human Turker speaks only once to provide the rating, the <code class="docutils literal notranslate"><span class="pre">ModelEvaluatorWorld</span></code> doesn’t need to use <code class="docutils literal notranslate"><span class="pre">turn_index</span></code> to keep track of the turns.</p>
<p>After one turn, the task is finished, and the Turker’s work is submitted for review.</p>
</div>
<div class="section" id="task-3-multi-agent-dialog">
<h3>Task 3: Multi-Agent Dialog<a class="headerlink" href="#task-3-multi-agent-dialog" title="Permalink to this headline">¶</a></h3>
<p>ParlAI supports dialogs between multiple agents, whether they are local ParlAI agents or human Turkers. In the <a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/multi_agent_dialog/">Multi-Agent Dialog task</a>, one local human agents and two Turkers engage in a round-robin chat, until the first local human agent sends a message ending with <code class="docutils literal notranslate"><span class="pre">[DONE]</span></code>, after which other agents will send a final message and the task is concluded.</p>
<p>This task uses the <code class="docutils literal notranslate"><span class="pre">MultiAgentDialogWorld</span></code> which is already implemented in <code class="docutils literal notranslate"><span class="pre">parlai.core.worlds</span></code>.</p>
</div>
<div class="section" id="task-4-advanced-functionality-deal-or-no-deal">
<h3>Task 4: Advanced Functionality - Deal or No Deal<a class="headerlink" href="#task-4-advanced-functionality-deal-or-no-deal" title="Permalink to this headline">¶</a></h3>
<p>ParlAI is able to support more than just generic chat. The <a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/dealnodeal/">Deal or No Deal task</a> provides additional functionality over the regular chat window to allow users to view the items they are dividing, select an allocation, and then submit a deal.</p>
<p>This task leverages the ability to override base functionality of the core.html page using <code class="docutils literal notranslate"><span class="pre">task_config.py</span></code>. Javascript is added here to replace the task description with additional buttons and UI elements that are required for the more complicated task. These trigger within an overridden handle_new_message function, which will only fire after an agent has entered the chat.
In general it is easier/preferred to use a custom webpage as described in step 4 of “Creating Your Own Task”, though this is an alternate that can be used if you specifically only want to show additional components in the task description pane of the chat window.</p>
</div>
<div class="section" id="task-5-advanced-functionality-mturk-qualification-flow">
<h3>Task 5: Advanced Functionality - MTurk Qualification Flow<a class="headerlink" href="#task-5-advanced-functionality-mturk-qualification-flow" title="Permalink to this headline">¶</a></h3>
<p>ParlAI MTurk is able to support filtering users through a form of qualification system. The <a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/qualification_flow_example">Qualification Flow task</a> demos this functionality using a simple “addition” task.</p>
<p>In this task, all users see a test version of the task on the first time they enter it and a real version every subsequent time, however users that fail to pass the test version are assigned a qualification that prevents them from working on the task again. Thus ParlAI users are able to filter out workers from the very beginning who don’t necessarily meet the specifications you are going for.
This is preferred to filtering out workers using the onboarding world for tasks that require a full instance’s worth of work to verify a worker’s readiness.</p>
</div>
<div class="section" id="task-6-advanced-functionality-react-task-demo">
<h3>Task 6: Advanced Functionality - React Task Demo<a class="headerlink" href="#task-6-advanced-functionality-react-task-demo" title="Permalink to this headline">¶</a></h3>
<p>ParlAI MTurk allows creation of arbitrary tasks, so long as the required components can be created in React. The <a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/react_task_demo">React Task Demo</a> task exists to show how this is set up for both cases where you are building your own components from scratch and cases where you want to import other components as dependancies.</p>
<p>This task consists of 3 agents participating in different roles with different frontend needs. By setting <code class="docutils literal notranslate"><span class="pre">MTurkAgent.id</span></code> to the correct values, different interfaces are displayed to an ‘Asker’ who can ask any questions, an ‘Answerer’ who is only able to respond with numeric values, and an <cite>Evaluator</cite> who observes the chat and approves or rejects at the end. These components are defined and linked in the <code class="docutils literal notranslate"><span class="pre">frontend/components/custom.jsx</span></code> file.</p>
</div>
</div>
<div class="section" id="creating-your-own-task">
<h2>Creating Your Own Task<a class="headerlink" href="#creating-your-own-task" title="Permalink to this headline">¶</a></h2>
<p>ParlAI provides a generic MTurk dialog interface that one can use to implement any kind of dialog tasks. To create your own task, start with reading the tutorials on the provided examples, and then copy and modify the example <code class="docutils literal notranslate"><span class="pre">worlds.py</span></code>, <code class="docutils literal notranslate"><span class="pre">run.py</span></code> and <code class="docutils literal notranslate"><span class="pre">task_config.py</span></code> files to create your task. Be sure to update import locations!</p>
<p>A few things to keep in mind:</p>
<ol class="arabic simple">
<li><p>To end a conversation, you should check to see if an action has <code class="docutils literal notranslate"><span class="pre">episode_done</span></code> set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, as this signals that the world should start returning <code class="docutils literal notranslate"><span class="pre">True</span></code> for the <code class="docutils literal notranslate"><span class="pre">episode_done</span></code> function.</p></li>
<li><p>Make sure to test your dialog task using MTurk’s sandbox mode before pushing it live, by using the <code class="docutils literal notranslate"><span class="pre">--sandbox</span></code> flag (enabled by default) when running <code class="docutils literal notranslate"><span class="pre">run.py</span></code>.</p></li>
<li><p>Your <code class="docutils literal notranslate"><span class="pre">worlds.py</span></code> worlds should be handling different types of agent disconnect messages. <code class="docutils literal notranslate"><span class="pre">MTurkAgent.act()</span></code> can return any of <code class="docutils literal notranslate"><span class="pre">MTURK_DISCONNECT_MESSAGE</span></code>, <code class="docutils literal notranslate"><span class="pre">RETURN_MESSAGE</span></code>, and <code class="docutils literal notranslate"><span class="pre">TIMEOUT_MESSAGE</span></code> as defined in <code class="docutils literal notranslate"><span class="pre">MTurkAgent</span></code>. Your world should still be able to continue to completion in any of these circumstances.</p></li>
<li><p>NO DATA is saved automatically in the way that regular MTurk tasks save data. Unless you’re using the Alpha saving and loading functionality described below, you’ll need to save your data in your <code class="docutils literal notranslate"><span class="pre">world.shutdown()</span></code> function.</p></li>
</ol>
</div>
<div class="section" id="advanced-task-techniques">
<h2>Advanced Task Techniques<a class="headerlink" href="#advanced-task-techniques" title="Permalink to this headline">¶</a></h2>
<p>The ParlAI-MTurk platform allows for a number of advanced customization techniques to cover specialized tasks. The below sections explain how to leverage these more advanced features for task control.</p>
<div class="section" id="custom-frontend-components">
<h3>Custom Frontend Components<a class="headerlink" href="#custom-frontend-components" title="Permalink to this headline">¶</a></h3>
<p>If you want to show a custom webpage (instead of the default one) for any of your MTurk agents, you can create an <code class="docutils literal notranslate"><span class="pre">frontend</span></code> folder within your task directory, and then create the <code class="docutils literal notranslate"><span class="pre">custom.jsx</span></code> within (see the React Task Demo for an example). For most custom tasks, creating your desired frontend is as simple as creating a <code class="docutils literal notranslate"><span class="pre">frontend/components/custom.jsx</span></code> file in your task directory that overrides a component you want to replace, and setting <cite>task_config[‘frontend_version’] = 1</cite> in your <code class="docutils literal notranslate"><span class="pre">task_config.py</span></code>. Custom task components are keyed on the <code class="docutils literal notranslate"><span class="pre">MTurkAgent.id</span></code> field, as such it is possible to render different frontends for different agents in a task. The react task demo displays this possibility by having 3 roles, each with custom components.</p>
<p>In general, if you want to create a custom component that replaces a component from the baseline UI, you should start off by copying the component you want to replace from <a class="reference external" href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/core/react_server/dev/components/core_components.jsx">the core components file</a> into your <code class="docutils literal notranslate"><span class="pre">frontend/components/custom.jsx</span></code> file. After creating your own version of a component, you’ll need to export it properly, as displayed below:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="kr">export</span> <span class="k">default</span> <span class="p">{</span>
  <span class="c1">// XWantedComponentName: {&#39;agent_id&#39;: ReplacementComponentForAgent},</span>
<span class="p">};</span>
</pre></div>
</div>
<p>In the above code snippet, we’re intending to replace <code class="docutils literal notranslate"><span class="pre">WantedComponentName</span></code> (like <code class="docutils literal notranslate"><span class="pre">ChatMessage</span></code> or <code class="docutils literal notranslate"><span class="pre">TextResponse</span></code>). For the system to properly pick this up, we prepend <code class="docutils literal notranslate"><span class="pre">X</span></code> to the component name in the module that we export. The object that corresponds to the component we want to replace should be a map from the value in the <code class="docutils literal notranslate"><span class="pre">MTurkAgent.id</span></code> field for a given agent to the specific custom component you want them to be able to see. You can use <code class="docutils literal notranslate"><span class="pre">'default'</span></code> to have the same component displayed for all agent ids. If on runtime the linker finds no custom component for a given agent’s id, it will use the default defined in <code class="docutils literal notranslate"><span class="pre">core_components.jsx</span></code>.</p>
</div>
<div class="section" id="displaying-task-context">
<h3>Displaying Task Context<a class="headerlink" href="#displaying-task-context" title="Permalink to this headline">¶</a></h3>
<p>Some tasks may want to display additional context, such as an image. In order to support this as controllable from your <code class="docutils literal notranslate"><span class="pre">worlds.py</span></code> file, we support a special field that can be observed from the <code class="docutils literal notranslate"><span class="pre">act</span></code> dict supplied to <code class="docutils literal notranslate"><span class="pre">MTurkAgent.observe(act)</span></code>. This is the <code class="docutils literal notranslate"><span class="pre">act['task_data']</span></code> field, and anything you put inside it will be available to all frontend components in the  <code class="docutils literal notranslate"><span class="pre">this.props.task_data</span></code> field. It will also be rendered in the <code class="docutils literal notranslate"><span class="pre">ContextView</span></code> component in the left pane.</p>
<p>More details and an example coming soon.</p>
</div>
</div>
<div class="section" id="running-a-task">
<h2>Running a Task<a class="headerlink" href="#running-a-task" title="Permalink to this headline">¶</a></h2>
<p>If you have not used Mechanical Turk before, you will need an MTurk Requester Account and an AWS account (these are two separate accounts). Follow the steps below:</p>
<ul class="simple">
<li><p>Sign up for an AWS account at <a class="reference external" href="https://aws.amazon.com/">aws.amazon.com</a></p></li>
<li><p>Sign up for an MTurk account at <a class="reference external" href="https://requester.mturk.com/">requester.mturk.com</a></p></li>
<li><p>Go to the developer tab (<a class="reference external" href="https://requester.mturk.com/developer">https://requester.mturk.com/developer</a>) and link your AWS account to your MTurk account (Step 2 on that screen)</p></li>
<li><p>MTurk also has a “Sandbox” which is a test version of the MTurk marketplace. You can use it to test publishing and completing tasks without paying any money. ParlAI supports the Sandbox. To use the Sandbox, you need to sign up for a <a class="reference external" href="http://requestersandbox.mturk.com/">Sandbox account</a>. You will then also need to <a class="reference external" href="http://requestersandbox.mturk.com/developer">link your AWS account</a> to your Sandbox account. In order to test faster, you will also want to create a <a class="reference external" href="http://workersandbox.mturk.com/">Sandbox Worker account</a>. You can then view tasks your publish from ParlAI and complete them yourself.</p></li>
<li><p>ParlAI’s MTurk default functionality requires a free heroku account which can be obtained <a class="reference external" href="https://signup.heroku.com/">here</a>. Running any ParlAI MTurk operation will walk you through linking the two. If, instead, you wish to run ParlAI MTurk’s node server on the same machine you are running ParlAI from, use the flag <code class="docutils literal notranslate"><span class="pre">--local</span></code>. Note that if you specify this flag, you will need to set up SSL for your server.</p></li>
</ul>
<p>Then, to run an MTurk task, first ensure that the task directory is in <a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/">parlai/mturk/tasks/</a>. Then, run its <code class="docutils literal notranslate"><span class="pre">run.py</span></code> file with proper flags:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">python run.py -nc &lt;num_conversations&gt; -r &lt;reward&gt; [--sandbox]/[--live]</span>
</pre></div>
</div>
<p>E.g. to create 2 conversations for the <a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/qa_data_collection/">QA Data Collection</a> example with a reward of $0.05 per assignment in sandbox mode, first go into the task directory and then run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">python run.py -nc 2 -r 0.05 --sandbox</span>
</pre></div>
</div>
<p>Please make sure to test your task in MTurk sandbox mode first (<code class="docutils literal notranslate"><span class="pre">--sandbox</span></code>) before pushing it live (<code class="docutils literal notranslate"><span class="pre">--live</span></code>).</p>
<p>Additional flags can be used for more specific purposes.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--unique</span></code> ensures that an Turker is only able to complete one assignment, thus ensuring each assignment is completed by a unique person.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--unique-qual-name</span> <span class="pre">&lt;name&gt;</span></code> lets you use the above functionality across more than one task. Workers will only be able to complete a task launched with this flag for a given <cite>&lt;name&gt;</cite> once.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--allowed-conversations</span> <span class="pre">&lt;num&gt;</span></code> prevents a Turker from entering more than &lt;num&gt; conversations at once (by using multiple windows/tabs). This defaults to 0, which is unlimited.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--count-complete</span></code> only counts completed assignments towards the num_conversations requested. This may lead to more conversations being had than requested (and thus higher costs for instances where one Turker disconnects and we pay the other) but it ensures that if you request 1,000 conversations you end up with at least 1,000 completed data points.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--max-connections</span></code> controls the number of HITs can be launched at the same time. If not specified, it defaults to 30; 0 is unlimited.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--max-time</span></code> sets a maximum limit in seconds for how many seconds per day a specific worker can work on your task. Data is logged to <code class="docutils literal notranslate"><span class="pre">working_time.pickle</span></code>, so all runs on the same machine will share the daily work logs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--max-time-qual</span></code> sets the specific qualification name for the max-time soft block. Using this can allow you to limit worker time between separate machines where <code class="docutils literal notranslate"><span class="pre">working_time.pickle</span></code> isn’t shared</p></li>
</ul>
</div>
<div class="section" id="handling-turker-disconnects">
<h2>Handling Turker Disconnects<a class="headerlink" href="#handling-turker-disconnects" title="Permalink to this headline">¶</a></h2>
<p>Sometimes you may find that a task you have created is leading to a lot of workers disconnecting in the middle of a conversation, or that a few people are disconnecting repeatedly. ParlAI MTurk offers two kinds of blocks to stop these workers from doing your hits.</p>
<ul class="simple">
<li><p>soft blocks can be created by using the <code class="docutils literal notranslate"><span class="pre">--disconnect-qualification</span> <span class="pre">&lt;name&gt;</span></code> flag with a name that you want to associate to your ParlAI tasks. Any user that hits the disconnect cap for a HIT with this flag active will not be able to participate in any HITs using this flag.</p></li>
<li><p>hard blocks can be used by setting the <code class="docutils literal notranslate"><span class="pre">--hard-block</span></code> flag. Soft blocks in general are preferred, as Turkers can be block-averse (as it may affect their reputation) and sometimes the disconnects are out of their control. This will prevent any Turkers that hit the disconnect cap with this flag active from participating in any of your future HITs of any type.</p></li>
</ul>
</div>
<div class="section" id="reviewing-turker-s-work">
<h2>Reviewing Turker’s Work<a class="headerlink" href="#reviewing-turker-s-work" title="Permalink to this headline">¶</a></h2>
<p>You can programmatically review work using the commands available in the <cite>MTurkManager</cite> class. See, for example, the  <a class="reference external" href="https://github.com/facebookresearch/ParlAI/blob/master/parlai/mturk/tasks/personachat/personachat_collect_personas/worlds.py/">review_work function</a> in the <code class="docutils literal notranslate"><span class="pre">personachat_collect_personas</span></code> task. In this task, HITs are automatically approved if they are deemed completed by the world.</p>
<p>If you don’t take any action in 1 week, all HITs will be auto-approved and Turkers will be paid.</p>
</div>
<div class="section" id="parlai-mturk-tips-and-tricks">
<h2>ParlAI-MTurk Tips and Tricks<a class="headerlink" href="#parlai-mturk-tips-and-tricks" title="Permalink to this headline">¶</a></h2>
<div class="section" id="approving-work">
<h3>Approving Work<a class="headerlink" href="#approving-work" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Unless you explicitly set the flag <cite>—auto-approve-delay</cite> or approve the agents work by calling <cite>mturk_agent.approve_work()</cite>, work will be auto approved after 30 days; workers generally like getting paid sooner than this so set the <cite>auto_approve_delay</cite> to be shorter when possible.</p></li>
<li><p>Occasionally Turkers will take advantage of getting paid immediately without review if you auto approve their work by calling <cite>mturk_agent.approve_work()</cite> at the close of the task. If you aren’t using any kind of validation before you <cite>approve_work</cite> or if you don’t intend to review the work manually, consider setting the <cite>—-auto-approve-delay</cite> flag rather than approving immediately.</p></li>
</ul>
</div>
<div class="section" id="rejecting-work">
<h3>Rejecting Work<a class="headerlink" href="#rejecting-work" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Most Turkers take their work very seriously, so if you find yourself with many different workers making similar mistakes on your task, it’s possible the task itself is unclear. You <strong>shouldn’t</strong> be rejecting work in this case, rather you should update your instructions and see if the problem resolves.</p></li>
<li><p>Reject sparingly at first and give clear reasons for rejection/how to improve. Rejections with no context are a violation of Amazon’s TOS.</p></li>
</ul>
</div>
<div class="section" id="filtering-workers">
<h3>Filtering Workers<a class="headerlink" href="#filtering-workers" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>For tasks where it is reasonably easy to tell whether or not a worker is capable of working on the task (generally less than 5 minutes of reading and interacting), it’s appropriate to build a testing stage into your onboarding world. This stage should only be shown to workers once, and failing the task should soft block the worker and expire the HIT.</p></li>
<li><p>For tasks where it can be difficult to assess a worker’s quality level, you should use the kind of flow demonstrated in the MTurk Qualification Flow demo task.</p></li>
</ul>
</div>
<div class="section" id="soft-blocking-vs-hard-blocking">
<h3>Soft-blocking vs. Hard-blocking<a class="headerlink" href="#soft-blocking-vs-hard-blocking" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Hard block sparingly; it’s possible workers that aren’t doing well on a particular task are perfectly good at others. Hard blocking reduces your possible worker pool.</p></li>
<li><p>Soft blocking workers that are clearly trying on a task but not <strong>quite</strong> getting it allows those workers to work on other tasks for you in the future. You can soft block workers by calling <cite>mturk_manager.soft_block_worker(&lt;worker id&gt;)</cite> after setting <cite>—-block-qualification</cite>. That worker will not be able to work on any tasks that use the same <cite>—-block-qualification</cite>.</p></li>
</ul>
</div>
<div class="section" id="preventing-and-handling-crashes">
<h3>Preventing and Handling Crashes<a class="headerlink" href="#preventing-and-handling-crashes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Set the <cite>–max-connections</cite> flag sufficiently low for your task; this controls the number of people who can work on your task at any given time. Leaving this too high might leave your heroku server running into issues depending on how many messages per second it’s trying to process, and on how much data is being sent in those messages (such as picture or video data).</p></li>
<li><p>If you’re using a model on your local machine, try to share the model parameters whenever possible. Needing new parameters for each of your conversations might run your machine out of memory, causing the data collection to crash in an manner that ParlAI can’t handle</p></li>
<li><p>If your task crashes, you’ll need to run the <cite>delete_hits</cite> script and find the task that had crashed to remove the orphan tasks.</p></li>
<li><p>If workers email you about task crashes with sufficient evidence that they were working on the task, offer to compensate by sending them a bonus for the failed task on one of their other completed tasks, then bonus that <cite>HITId</cite> with the <cite>bonus_workers</cite> script.</p></li>
</ul>
</div>
<div class="section" id="task-design">
<h3>Task Design<a class="headerlink" href="#task-design" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Design and test your task using the developer sandbox feature (used by default when calling a <cite>run.py</cite>), only launch <cite>–live</cite> after you’ve tested your flow entirely.</p></li>
<li><p>Launch a few small pilot hits <cite>–live</cite> before your main data collection, and manually review every response to see how well the workers are understanding your task. Use this time to tweak your task instructions until you’re satisfied with the results, as this will improve the quality of the received data.</p></li>
</ul>
</div>
<div class="section" id="other-tips">
<h3>Other Tips<a class="headerlink" href="#other-tips" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Check your MTurk-associated email frequently when running a task, and be responsive to the workers working on your tasks. This is important to keep a good reputation in the MTurk community.</p></li>
<li><p>If you notice that certain workers are doing a really good job on the task, send them bonuses, as this will encourage them to work on your HITs more in the future. It will also be a visible way for you to acknowledge their good work.</p></li>
</ul>
</div>
</div>
<div class="section" id="parlai-mturk-alpha-functionality">
<h2>ParlAI-MTurk Alpha Functionality<a class="headerlink" href="#parlai-mturk-alpha-functionality" title="Permalink to this headline">¶</a></h2>
<p>ParlAI-MTurk has a number of alpha features that surround maintaining a local database of run information. This alpha functionality includes a local webapp for testing, monitoring, and reviewing tasks, as well as a standardized flow for saving the data collected during a task run. Using this alpha functionality is blocked behind <code class="docutils literal notranslate"><span class="pre">MTurkManager(use_db=True)</span></code>. Setting this flag to true when initializing your <code class="docutils literal notranslate"><span class="pre">MTurkManager</span></code> begins storing information locally in a place that the PMT platform knows where to find it. This functionality is very much still in alpha, and thus the documentation is going to be brief and primarily point to code as the source of truth.</p>
<div class="section" id="running-the-parlai-mturk-webapp">
<h3>Running the ParlAI-MTurk Webapp<a class="headerlink" href="#running-the-parlai-mturk-webapp" title="Permalink to this headline">¶</a></h3>
<p>To launch the webapp, you’ll need to run <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">server.py</span></code> from within the <code class="docutils literal notranslate"><span class="pre">ParlAI/parlai/mturk/webapp</span></code> folder. At the moment, you will need to kill and restart this server in order to apply any changes to task files.</p>
</div>
<div class="section" id="testing-a-task-in-the-webapp">
<h3>Testing a task in the webapp<a class="headerlink" href="#testing-a-task-in-the-webapp" title="Permalink to this headline">¶</a></h3>
<p>One primary feature of the webapp is an easy-to-iterate way to test new tasks without needing to launch to sandbox. If you’re using the react frontend (which you should be), you can test tasks by navigating to <code class="docutils literal notranslate"><span class="pre">/app/tasks/&lt;your_task_name&gt;</span></code>, where <code class="docutils literal notranslate"><span class="pre">&lt;your_task_name&gt;</span></code> is the task directory that contains your <code class="docutils literal notranslate"><span class="pre">run.py</span></code> and <code class="docutils literal notranslate"><span class="pre">worlds.py</span></code> files. Making edits to these files will require relaunching the webapp to test changes at the moment.</p>
</div>
<div class="section" id="reviewing-tasks-in-the-webapp">
<h3>Reviewing tasks in the webapp<a class="headerlink" href="#reviewing-tasks-in-the-webapp" title="Permalink to this headline">¶</a></h3>
<p>Another primary feature of the webapp is being able to review work from a task that is complete or still running. Generally this can be accessed from a particular run’s page, which can be navigated to from the home page.</p>
</div>
<div class="section" id="saving-and-loading-data-via-the-database">
<h3>Saving and Loading data via the database<a class="headerlink" href="#saving-and-loading-data-via-the-database" title="Permalink to this headline">¶</a></h3>
<p>If using <code class="docutils literal notranslate"><span class="pre">use_db</span></code>, all runs will attempt to save data into local directories and link them via their run ids and worker ids. The data that is saved by default is defined in the <code class="docutils literal notranslate"><span class="pre">MTurkDataWorld</span></code> class, along with instructions on how to save custom data. The actual saving process occurs in <code class="docutils literal notranslate"><span class="pre">MTurkDataHandler</span></code>.</p>
<p>Data can later be queried using <code class="docutils literal notranslate"><span class="pre">MTurkDataHandler</span></code>. Below is a code snippet example for building an array of all of the runs and associated data by leveraging the class directly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">importlib</span> <span class="kn">import</span> <span class="nb">reload</span>
<span class="kn">from</span> <span class="nn">parlai.mturk.core.mturk_data_handler</span> <span class="kn">import</span> <span class="n">MTurkDataHandler</span>
<span class="n">db_logger</span> <span class="o">=</span> <span class="n">MTurkDataHandler</span><span class="p">()</span>

<span class="n">all_runs</span> <span class="o">=</span> <span class="n">db_logger</span><span class="o">.</span><span class="n">get_all_run_data</span><span class="p">()</span>

<span class="n">pairings</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">run_id</span> <span class="ow">in</span> <span class="n">all_runs</span><span class="p">:</span>
    <span class="n">pairings</span> <span class="o">=</span> <span class="n">pairings</span> <span class="o">+</span> <span class="n">db_logger</span><span class="o">.</span><span class="n">get_pairings_for_run</span><span class="p">(</span><span class="n">run_id</span><span class="p">[</span><span class="s1">&#39;run_id&#39;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">row_to_dict</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
     <span class="k">return</span> <span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">row</span><span class="p">)))</span>

<span class="n">pairings</span> <span class="o">=</span> <span class="p">[</span><span class="n">row_to_dict</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pairings</span><span class="p">]</span>

<span class="k">for</span> <span class="n">pairing</span> <span class="ow">in</span> <span class="n">pairings</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;conversation_id&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;assign_data&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">db_logger</span><span class="o">.</span><span class="n">get_conversation_data</span><span class="p">(</span><span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;run_id&#39;</span><span class="p">],</span> <span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;conversation_id&#39;</span><span class="p">],</span> <span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;worker_id&#39;</span><span class="p">],</span> <span class="bp">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;assign_data&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

<span class="k">for</span> <span class="n">pairing</span> <span class="ow">in</span> <span class="n">pairings</span><span class="p">:</span>
    <span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;review_status&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">db_logger</span><span class="o">.</span><span class="n">get_assignment_data</span><span class="p">(</span><span class="n">pairing</span><span class="p">[</span><span class="s1">&#39;assignment_id&#39;</span><span class="p">])[</span><span class="s1">&#39;status&#39;</span><span class="p">]</span>

<span class="n">pairings</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pairings</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="s1">&#39;assign_data&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
<span class="n">pairings</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pairings</span> <span class="k">if</span> <span class="n">p</span><span class="p">[</span><span class="s1">&#39;assign_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>

<span class="n">pairings_by_conv_run_id</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pairings</span><span class="p">:</span>
    <span class="n">key_id</span> <span class="o">=</span> <span class="s1">&#39;{}|{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;conversation_id&#39;</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="s1">&#39;run_id&#39;</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">key_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pairings_by_conv_run_id</span><span class="p">:</span>
        <span class="n">pairings_by_conv_run_id</span><span class="p">[</span><span class="n">key_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;workers_info&#39;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="n">pairings_by_conv_run_id</span><span class="p">[</span><span class="n">key_id</span><span class="p">][</span><span class="s1">&#39;workers_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="k">for</span> <span class="n">key_id</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pairings_by_conv_run_id</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">stuff</span> <span class="o">=</span> <span class="n">key_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)</span>
    <span class="n">conv_id</span> <span class="o">=</span> <span class="n">stuff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">run_id</span> <span class="o">=</span> <span class="n">stuff</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">p</span><span class="p">[</span><span class="s1">&#39;conv_info&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">db_logger</span><span class="o">.</span><span class="n">get_full_conversation_data</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">conv_id</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
<p>* Turker icon credit: <a class="reference external" href="https://requester.mturk.com/">Amazon Mechanical Turk</a>. Robot icon credit: <a class="reference external" href="https://icons8.com/">Icons8</a>.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tutorial_messenger.html" class="btn btn-neutral float-right" title="Using Facebook Messenger" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="tutorial_tipsntricks.html" class="btn btn-neutral float-left" title="Tips and Tricks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Facebook AI Research

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>