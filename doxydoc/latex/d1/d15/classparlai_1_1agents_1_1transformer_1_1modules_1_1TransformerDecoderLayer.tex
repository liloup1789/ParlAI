\hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer}{}\section{parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer Class Reference}
\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer}\index{parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer@{parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer}}


Inheritance diagram for parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=247pt]{d2/daa/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=247pt]{df/d83/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ad893ac51805fd662173f777c91b2cca4}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, n\+\_\+heads, embedding\+\_\+size, ffn\+\_\+size, attention\+\_\+dropout=0.\+0, relu\+\_\+dropout=0.\+0, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aba87c66e402b0cfdf196872c3f038d43}{dropout}=0.\+0, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a33276633e128020853db98128f1d93c3}{activation}=\textquotesingle{}relu\textquotesingle{}, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a94a9a714a2585fd6a675a08643e3ce6b}{variant}=\textquotesingle{}aiayn\textquotesingle{})
\item 
def \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a7b6ccf1e786de774f14397ec6368f342}{forward} (self, x, encoder\+\_\+output, encoder\+\_\+mask, incr\+\_\+state=None)
\item 
def \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a480d752ddd50f821078667af9f6ad20f}{reorder\+\_\+incremental\+\_\+state}
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_afc3159ec4e88329e2967edf28923ea20}{dim}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a296aa88e8a31be628bb31f55de0a0360}{ffn\+\_\+dim}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a94a9a714a2585fd6a675a08643e3ce6b}{variant}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a33276633e128020853db98128f1d93c3}{activation}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aba87c66e402b0cfdf196872c3f038d43}{dropout}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ad656c203b5b2ab890ea419febace286f}{self\+\_\+attention}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aa82d4bae763a0867633b6d5bc8484129}{norm1}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a50be54030dc6526fd5cae1f48a448f04}{encoder\+\_\+attention}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ac581c47d531c120ca010ce5fa3836b24}{norm2}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a394248deb2cfa738a51f890d4c232224}{ffn}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a24e685c1a13c11ce7bd4a839bc93ab2a}{norm3}
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aae73c8122e4c7da619c05118630b1a03}{attn\+\_\+types}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}Implements a single Transformer decoder layer.

Decoder layers are similar to encoder layers but:

1. Self-attention is limited in a casaul (auto-regressive) manner.
2. Attend over all of the encoder states.
\end{DoxyVerb}
 

Definition at line 741 of file modules.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ad893ac51805fd662173f777c91b2cca4}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ad893ac51805fd662173f777c91b2cca4}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{n\+\_\+heads,  }\item[{}]{embedding\+\_\+size,  }\item[{}]{ffn\+\_\+size,  }\item[{}]{attention\+\_\+dropout = {\ttfamily 0.0},  }\item[{}]{relu\+\_\+dropout = {\ttfamily 0.0},  }\item[{}]{dropout = {\ttfamily 0.0},  }\item[{}]{activation = {\ttfamily \textquotesingle{}relu\textquotesingle{}},  }\item[{}]{variant = {\ttfamily \textquotesingle{}aiayn\textquotesingle{}} }\end{DoxyParamCaption})}



Definition at line 761 of file modules.\+py.


\begin{DoxyCode}
761     ):
762         super().\_\_init\_\_()
763         self.dim = embedding\_size
764         self.ffn\_dim = ffn\_size
765         self.variant = variant
766         self.activation = activation
767         self.dropout = nn.Dropout(p=dropout)
768 
769         self.self\_attention = MultiHeadAttention(
770             n\_heads, embedding\_size, dropout=attention\_dropout
771         )
772         self.norm1 = LayerNorm(embedding\_size, eps=LAYER\_NORM\_EPS)
773 
774         self.encoder\_attention = MultiHeadAttention(
775             n\_heads, embedding\_size, dropout=attention\_dropout
776         )
777         self.norm2 = LayerNorm(embedding\_size, eps=LAYER\_NORM\_EPS)
778 
779         self.ffn = TransformerFFN(
780             embedding\_size, ffn\_size, relu\_dropout=relu\_dropout, activation=activation
781         )
782         self.norm3 = LayerNorm(embedding\_size, eps=LAYER\_NORM\_EPS)
783 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a7b6ccf1e786de774f14397ec6368f342}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a7b6ccf1e786de774f14397ec6368f342}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!forward@{forward}}
\index{forward@{forward}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily def parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+forward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{x,  }\item[{}]{encoder\+\_\+output,  }\item[{}]{encoder\+\_\+mask,  }\item[{}]{incr\+\_\+state = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Forward pass.

The incremental state is a dict with values for self- and encoder-attention
states.
\end{DoxyVerb}
 

Definition at line 784 of file modules.\+py.


\begin{DoxyCode}
784     \textcolor{keyword}{def }forward(self, x, encoder\_output, encoder\_mask, incr\_state=None):
785         \textcolor{stringliteral}{"""}
786 \textcolor{stringliteral}{        Forward pass.}
787 \textcolor{stringliteral}{}
788 \textcolor{stringliteral}{        The incremental state is a dict with values for self- and encoder-attention}
789 \textcolor{stringliteral}{        states.}
790 \textcolor{stringliteral}{        """}
791 
792         \textcolor{keywordflow}{if} incr\_state \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
793             incr\_state = \{\}
794 
795         decoder\_mask = self.\_create\_selfattn\_mask(x)
796         \textcolor{comment}{# first self attn}
797         residual = x
798         \textcolor{comment}{# don't peak into the future!}
799         x, final\_self\_attn\_incr\_state = self.self\_attention(
800             query=x,
801             mask=decoder\_mask,
802             incr\_state=incr\_state.get(\textcolor{stringliteral}{'self\_attn'}),
803             static\_kv=\textcolor{keyword}{False},
804         )
805         x = self.dropout(x)  \textcolor{comment}{# --dropout}
806         x = x + residual
807         x = \_normalize(x, self.norm1)
808 
809         residual = x
810         x, final\_encoder\_attn\_incr\_state = self.encoder\_attention(
811             query=x,
812             key=encoder\_output,
813             value=encoder\_output,
814             mask=encoder\_mask,
815             incr\_state=incr\_state.get(\textcolor{stringliteral}{'encoder\_attn'}),
816             static\_kv=\textcolor{keyword}{True},
817         )
818         x = self.dropout(x)  \textcolor{comment}{# --dropout}
819         x = residual + x
820         x = \_normalize(x, self.norm2)
821 
822         \textcolor{comment}{# finally the ffn}
823         residual = x
824         x = self.ffn(x)
825         x = self.dropout(x)  \textcolor{comment}{# --dropout}
826         x = residual + x
827         x = \_normalize(x, self.norm3)
828 
829         new\_incr\_state = \{
830             \textcolor{stringliteral}{'self\_attn'}: final\_self\_attn\_incr\_state,
831             \textcolor{stringliteral}{'encoder\_attn'}: final\_encoder\_attn\_incr\_state,
832         \}
833         \textcolor{keywordflow}{return} x, new\_incr\_state
834 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a480d752ddd50f821078667af9f6ad20f}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a480d752ddd50f821078667af9f6ad20f}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!reorder\+\_\+incremental\+\_\+state@{reorder\+\_\+incremental\+\_\+state}}
\index{reorder\+\_\+incremental\+\_\+state@{reorder\+\_\+incremental\+\_\+state}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{reorder\+\_\+incremental\+\_\+state()}{reorder\_incremental\_state()}}
{\footnotesize\ttfamily def parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+reorder\+\_\+incremental\+\_\+state (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{incremental\+\_\+state }\end{DoxyParamCaption})}



Definition at line 846 of file modules.\+py.


\begin{DoxyCode}
846         self, incremental\_state: Dict[str, dict], inds: torch.Tensor
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a33276633e128020853db98128f1d93c3}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a33276633e128020853db98128f1d93c3}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!activation@{activation}}
\index{activation@{activation}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{activation}{activation}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+activation}



Definition at line 766 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aae73c8122e4c7da619c05118630b1a03}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aae73c8122e4c7da619c05118630b1a03}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!attn\+\_\+types@{attn\+\_\+types}}
\index{attn\+\_\+types@{attn\+\_\+types}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{attn\+\_\+types}{attn\_types}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+attn\+\_\+types\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 851 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_afc3159ec4e88329e2967edf28923ea20}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_afc3159ec4e88329e2967edf28923ea20}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!dim@{dim}}
\index{dim@{dim}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{dim}{dim}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+dim}



Definition at line 763 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aba87c66e402b0cfdf196872c3f038d43}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aba87c66e402b0cfdf196872c3f038d43}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!dropout@{dropout}}
\index{dropout@{dropout}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{dropout}{dropout}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+dropout}



Definition at line 767 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a50be54030dc6526fd5cae1f48a448f04}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a50be54030dc6526fd5cae1f48a448f04}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!encoder\+\_\+attention@{encoder\+\_\+attention}}
\index{encoder\+\_\+attention@{encoder\+\_\+attention}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{encoder\+\_\+attention}{encoder\_attention}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+encoder\+\_\+attention}



Definition at line 774 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a394248deb2cfa738a51f890d4c232224}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a394248deb2cfa738a51f890d4c232224}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!ffn@{ffn}}
\index{ffn@{ffn}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{ffn}{ffn}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+ffn}



Definition at line 779 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a296aa88e8a31be628bb31f55de0a0360}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a296aa88e8a31be628bb31f55de0a0360}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!ffn\+\_\+dim@{ffn\+\_\+dim}}
\index{ffn\+\_\+dim@{ffn\+\_\+dim}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{ffn\+\_\+dim}{ffn\_dim}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+ffn\+\_\+dim}



Definition at line 764 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aa82d4bae763a0867633b6d5bc8484129}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_aa82d4bae763a0867633b6d5bc8484129}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!norm1@{norm1}}
\index{norm1@{norm1}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{norm1}{norm1}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+norm1}



Definition at line 772 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ac581c47d531c120ca010ce5fa3836b24}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ac581c47d531c120ca010ce5fa3836b24}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!norm2@{norm2}}
\index{norm2@{norm2}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{norm2}{norm2}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+norm2}



Definition at line 777 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a24e685c1a13c11ce7bd4a839bc93ab2a}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a24e685c1a13c11ce7bd4a839bc93ab2a}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!norm3@{norm3}}
\index{norm3@{norm3}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{norm3}{norm3}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+norm3}



Definition at line 782 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ad656c203b5b2ab890ea419febace286f}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_ad656c203b5b2ab890ea419febace286f}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!self\+\_\+attention@{self\+\_\+attention}}
\index{self\+\_\+attention@{self\+\_\+attention}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{self\+\_\+attention}{self\_attention}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+self\+\_\+attention}



Definition at line 769 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a94a9a714a2585fd6a675a08643e3ce6b}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoderLayer_a94a9a714a2585fd6a675a08643e3ce6b}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}!variant@{variant}}
\index{variant@{variant}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Decoder\+Layer}}
\subsubsection{\texorpdfstring{variant}{variant}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Decoder\+Layer.\+variant}



Definition at line 765 of file modules.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/agents/transformer/\hyperlink{parlai_2agents_2transformer_2modules_8py}{modules.\+py}\end{DoxyCompactItemize}
