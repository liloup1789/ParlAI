\hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer}{}\section{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer Class Reference}
\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer}\index{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer@{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer}}


Inheritance diagram for parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=231pt]{d6/d37/classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=231pt]{d9/d50/classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a69a5d8b41630a6bb53b3680a68136e8f}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, kwargs)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_af7fb8c70ddbd8c11e3e32365af30e567}{tokenize} (self, text)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a7364a69ba2dbb4faeeab4565d191f134}{classpath}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a3813fe96a6ae9af6f6490a6d3f4d6ea8}{annotators}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_aa8bdbec985051101da11c5c7c40bfac7}{mem}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_ac9ad0c796f3251450ed666160b4c35b3}{corenlp}
\end{DoxyCompactItemize}


\subsection{Detailed Description}


Definition at line 20 of file corenlp\+\_\+tokenizer.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a69a5d8b41630a6bb53b3680a68136e8f}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a69a5d8b41630a6bb53b3680a68136e8f}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{kwargs }\end{DoxyParamCaption})}

\begin{DoxyVerb}Args:
    annotators: set that can include pos, lemma, and ner.
    classpath: Path to the corenlp directory of jars
    mem: Java heap memory
\end{DoxyVerb}
 

Definition at line 21 of file corenlp\+\_\+tokenizer.\+py.


\begin{DoxyCode}
21     \textcolor{keyword}{def }\_\_init\_\_(self, **kwargs):
22         \textcolor{stringliteral}{"""}
23 \textcolor{stringliteral}{        Args:}
24 \textcolor{stringliteral}{            annotators: set that can include pos, lemma, and ner.}
25 \textcolor{stringliteral}{            classpath: Path to the corenlp directory of jars}
26 \textcolor{stringliteral}{            mem: Java heap memory}
27 \textcolor{stringliteral}{        """}
28         self.classpath = kwargs.get(\textcolor{stringliteral}{'classpath'}) \textcolor{keywordflow}{or} DEFAULTS[\textcolor{stringliteral}{'corenlp\_classpath'}]
29         self.annotators = copy.deepcopy(kwargs.get(\textcolor{stringliteral}{'annotators'}, set()))
30         self.mem = kwargs.get(\textcolor{stringliteral}{'mem'}, \textcolor{stringliteral}{'2g'})
31         self.\_launch()
32 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_af7fb8c70ddbd8c11e3e32365af30e567}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_af7fb8c70ddbd8c11e3e32365af30e567}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}!tokenize@{tokenize}}
\index{tokenize@{tokenize}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}}
\subsubsection{\texorpdfstring{tokenize()}{tokenize()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+tokenize (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}



Definition at line 89 of file corenlp\+\_\+tokenizer.\+py.


\begin{DoxyCode}
89     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1tfidf__retriever_1_1build__tfidf_a1fdb457e98eb4e4c26047e229686a616}{tokenize}(self, text):
90         \textcolor{comment}{# Since we're feeding text to the commandline, we're waiting on seeing}
91         \textcolor{comment}{# the NLP> prompt. Hacky!}
92         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'NLP>'} \textcolor{keywordflow}{in} text:
93             \textcolor{keywordflow}{raise} RuntimeError(\textcolor{stringliteral}{'Bad token (NLP>) in text!'})
94 
95         \textcolor{comment}{# Sending q will cause the process to quit -- manually override}
96         \textcolor{keywordflow}{if} text.lower().strip() == \textcolor{stringliteral}{'q'}:
97             token = text.strip()
98             index = text.index(token)
99             data = [(token, text[index:], (index, index + 1), \textcolor{stringliteral}{'NN'}, \textcolor{stringliteral}{'q'}, \textcolor{stringliteral}{'O'})]
100             \textcolor{keywordflow}{return} Tokens(data, self.annotators)
101 
102         \textcolor{comment}{# Minor cleanup before tokenizing.}
103         clean\_text = text.replace(\textcolor{stringliteral}{'\(\backslash\)n'}, \textcolor{stringliteral}{' '})
104 
105         self.corenlp.sendline(clean\_text.encode(\textcolor{stringliteral}{'utf-8'}))
106         self.corenlp.expect\_exact(\textcolor{stringliteral}{'NLP>'}, searchwindowsize=100)
107 
108         \textcolor{comment}{# Skip to start of output (may have been stderr logging messages)}
109         output = self.corenlp.before
110         start = output.find(b\textcolor{stringliteral}{'\{"sentences":'})
111         output = json.loads(output[start:].decode(\textcolor{stringliteral}{'utf-8'}))
112 
113         data = []
114         tokens = [t \textcolor{keywordflow}{for} s \textcolor{keywordflow}{in} output[\textcolor{stringliteral}{'sentences'}] \textcolor{keywordflow}{for} t \textcolor{keywordflow}{in} s[\textcolor{stringliteral}{'tokens'}]]
115         \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(len(tokens)):
116             \textcolor{comment}{# Get whitespace}
117             start\_ws = tokens[i][\textcolor{stringliteral}{'characterOffsetBegin'}]
118             \textcolor{keywordflow}{if} i + 1 < len(tokens):
119                 end\_ws = tokens[i + 1][\textcolor{stringliteral}{'characterOffsetBegin'}]
120             \textcolor{keywordflow}{else}:
121                 end\_ws = tokens[i][\textcolor{stringliteral}{'characterOffsetEnd'}]
122 
123             data.append(
124                 (
125                     self.\_convert(tokens[i][\textcolor{stringliteral}{'word'}]),
126                     text[start\_ws:end\_ws],
127                     (
128                         tokens[i][\textcolor{stringliteral}{'characterOffsetBegin'}],
129                         tokens[i][\textcolor{stringliteral}{'characterOffsetEnd'}],
130                     ),
131                     tokens[i].get(\textcolor{stringliteral}{'pos'}, \textcolor{keywordtype}{None}),
132                     tokens[i].get(\textcolor{stringliteral}{'lemma'}, \textcolor{keywordtype}{None}),
133                     tokens[i].get(\textcolor{stringliteral}{'ner'}, \textcolor{keywordtype}{None}),
134                 )
135             )
136         \textcolor{keywordflow}{return} Tokens(data, self.annotators)
137 \end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a3813fe96a6ae9af6f6490a6d3f4d6ea8}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a3813fe96a6ae9af6f6490a6d3f4d6ea8}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}!annotators@{annotators}}
\index{annotators@{annotators}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}}
\subsubsection{\texorpdfstring{annotators}{annotators}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+annotators}



Definition at line 29 of file corenlp\+\_\+tokenizer.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a7364a69ba2dbb4faeeab4565d191f134}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_a7364a69ba2dbb4faeeab4565d191f134}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}!classpath@{classpath}}
\index{classpath@{classpath}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}}
\subsubsection{\texorpdfstring{classpath}{classpath}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+classpath}



Definition at line 28 of file corenlp\+\_\+tokenizer.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_ac9ad0c796f3251450ed666160b4c35b3}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_ac9ad0c796f3251450ed666160b4c35b3}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}!corenlp@{corenlp}}
\index{corenlp@{corenlp}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}}
\subsubsection{\texorpdfstring{corenlp}{corenlp}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+corenlp}



Definition at line 65 of file corenlp\+\_\+tokenizer.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_aa8bdbec985051101da11c5c7c40bfac7}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1corenlp__tokenizer_1_1CoreNLPTokenizer_aa8bdbec985051101da11c5c7c40bfac7}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}!mem@{mem}}
\index{mem@{mem}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::corenlp\+\_\+tokenizer\+::\+Core\+N\+L\+P\+Tokenizer}}
\subsubsection{\texorpdfstring{mem}{mem}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+mem}



Definition at line 30 of file corenlp\+\_\+tokenizer.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/agents/tfidf\+\_\+retriever/tokenizers/\hyperlink{corenlp__tokenizer_8py}{corenlp\+\_\+tokenizer.\+py}\end{DoxyCompactItemize}
