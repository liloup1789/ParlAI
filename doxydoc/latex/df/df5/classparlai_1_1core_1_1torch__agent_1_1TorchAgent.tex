\hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent}{}\section{parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent Class Reference}
\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent}\index{parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent@{parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent}}


Inheritance diagram for parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d0/d92/classparlai_1_1core_1_1torch__agent_1_1TorchAgent__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=258pt]{d2/d85/classparlai_1_1core_1_1torch__agent_1_1TorchAgent__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9c622b8ed5a811841f30fe98cc297cde}{optim\+\_\+opts} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0bd9118252c602bb9d5a596ecae16717}{history\+\_\+class} (cls)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4a72bdd07d2cb5ce402d0058140cad0d}{add\+\_\+cmdline\+\_\+args} (cls, argparser)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afc9c818413b776a498c2bcc0bfe3c6f7}{\+\_\+\+\_\+init\+\_\+\+\_\+}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab22f61f153b522f429210c61eed2d5af}{build\+\_\+history} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a233316f9ec2805dd6a08fbf07f3a078a}{build\+\_\+dictionary} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9a21fa33fa5b2b928024fbc67826f233}{build\+\_\+model} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3784f1ddaa6ffad009716910f3f36dd4}{init\+\_\+optim} (self, params, optim\+\_\+states=None, saved\+\_\+optim\+\_\+type=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa51ac42dc34e3d2281a01cba78a96151}{build\+\_\+lr\+\_\+scheduler} (self, states=None, hard\+\_\+reset=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac694770cd4022eb047bf6fbb8f46035c}{report} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a02beaaedfa30463f9d0a97ea590b516f}{receive\+\_\+metrics} (self, metrics\+\_\+dict)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a373f0e276bf7c9d914a4e3363e9c2712}{share} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a48bb9b153353a0565ab7253dc1daef99}{vectorize} (self, obs, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}{history}, add\+\_\+start=True, add\+\_\+end=True, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}{text\+\_\+truncate}=None, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}{label\+\_\+truncate}=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afa491bf2384b017711ad722b5341b405}{is\+\_\+valid} (self, obs)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4c5824776df0c6cf995984a5e7a3f433}{batchify} (self, obs\+\_\+batch, sort=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aba56b961d929e5c5b5da9cf8bd331502}{match\+\_\+batch} (self, batch\+\_\+reply, valid\+\_\+inds, output=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a87b18f0d6ab11be3c49375af072d0d33}{observe} (self, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}{observation})
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a663cb0d6a276495d03aacdb8b9c79fb0}{self\+\_\+observe}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}{state\+\_\+dict} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adac7ee3db855786e8414e9f35fcb6e46}{save} (self, path=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dcfca62a677f8de97f09ce993258f84}{load\+\_\+state\+\_\+dict} (self, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}{state\+\_\+dict})
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac345f2da892d35d9f4921e0acf5594c8}{load}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6f568650dd8e245a274671680ebb7587}{reset} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a03e18955cfd44dd019d0847bc7a46893}{reset\+\_\+metrics} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a51174dfa508970e3392246b02d0d94b5}{act} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7754a74d6c87590f46e71ec486c285a8}{batch\+\_\+act} (self, observations)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8ba9d535736c0af100d00c5e7b02b61b}{train\+\_\+step} (self, batch)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a18de0a52aeec4ef721aedbdd6ac06cad}{eval\+\_\+step} (self, batch)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6a7aff29231816a0f3cade9c72409dfc}{set\+\_\+interactive\+\_\+mode} (self, mode, shared)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8df662b1258ec67752b4fc0ad45733f9}{backward} (self, loss)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7e2c9e180887397daa6229a0f9700b1c}{update\+\_\+params} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a91c163f3e2d39b380095b7083f673b6e}{zero\+\_\+grad} (self)
\end{DoxyCompactItemize}
\subsection*{Static Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aea8849fa69a3f5dbd3216c8b06f180ea}{dictionary\+\_\+class} ()
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a10b8d2605e619d5d3dc9f67777cb190a}{use\+\_\+cuda}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa6f916e01d876679b529a893ad4f52f6}{fp16}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_abebf29c0bb956bbc5ccc02777d2af3dd}{dict}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}{opt}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afe40410d2e3b2565ecd27441266011fc}{model}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a13d46ae8aed6052679b62c3961a4de62}{criterion}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a392ed66573001dfa2846d5042e8fc5a5}{metrics}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4ac66a09c1c164ea08f4b257c61c38a0}{id}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3a80083f0e34d8abc15b50123efec884}{E\+M\+P\+TY}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a95cedd561757c9fc10dbf3a956e7f912}{N\+U\+L\+L\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a2018afae9938937f80b61475314012cd}{S\+T\+A\+R\+T\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a31bb7c8bf380660ee4e3822756563599}{E\+N\+D\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a1ca476189900643fab04d1ac0ebfc719}{random}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a15cbb1f743c1d341d914ade47e49071b}{histsz}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3ae27e9fe68d255a960bcb5180f48a65}{truncate}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}{text\+\_\+truncate}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}{label\+\_\+truncate}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}{history}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab0bd6456c94dfd9afae73b86f05016cf}{is\+\_\+training}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6355b9b0c0ccb24ffe1b5e3d89903cc3}{rank\+\_\+candidates}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a63011fa9bd927de8acc9ffa676caa73a}{add\+\_\+person\+\_\+tokens}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9533344de40049bf13209739bc92199d}{optimizer}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a54d8632c546ab621c93c34f13c964726}{warmup\+\_\+scheduler}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0affe6b199275c182a27c9aa07393347}{scheduler}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a805a9e47552d54d56f5b232ab4d5121f}{proj\+\_\+rp}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}{observation}
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a292c402279f706390ffed9a7af868abf}{P1\+\_\+\+T\+O\+K\+EN}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a81b5bf5acfa70764e3601c14a8afae85}{P2\+\_\+\+T\+O\+K\+EN}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}A provided abstract base agent for any model that wants to use Torch.

Exists to make it easier to implement a new agent.
Not necessary, but reduces duplicated code.

Many methods are intended to be either used as is when the default is
acceptable, or to be overriden and called with super(), with the extra
functionality added to the initial result. See the method comment for
recommended behavior.

This agent serves as a common framework for all ParlAI models which want
to use PyTorch.
\end{DoxyVerb}
 

Definition at line 314 of file torch\+\_\+agent.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afc9c818413b776a498c2bcc0bfe3c6f7}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afc9c818413b776a498c2bcc0bfe3c6f7}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{opt }\end{DoxyParamCaption})}



Definition at line 644 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
644     \textcolor{keyword}{def }\_\_init\_\_(self, opt: Opt, shared=\textcolor{keywordtype}{None}):
645         \textcolor{stringliteral}{"""}
646 \textcolor{stringliteral}{        Initialize agent.}
647 \textcolor{stringliteral}{        """}
648         super().\_\_init\_\_(opt, shared)
649         opt = self.opt
650 
651         \textcolor{comment}{# Safety checkers to ensure TorchAgent assumptions aren't being violated.}
652         self.\_\_expecting\_clear\_history = \textcolor{keyword}{False}
653         self.\_\_expecting\_to\_reply = \textcolor{keyword}{False}
654 
655         \textcolor{comment}{# check for cuda}
656         self.use\_cuda = \textcolor{keywordflow}{not} opt[\textcolor{stringliteral}{'no\_cuda'}] \textcolor{keywordflow}{and} torch.cuda.is\_available()
657         \textcolor{keywordflow}{if} self.use\_cuda:
658             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} shared:
659                 print(\textcolor{stringliteral}{'[ Using CUDA ]'})
660             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} shared \textcolor{keywordflow}{and} opt[\textcolor{stringliteral}{'gpu'}] != -1:
661                 torch.cuda.set\_device(opt[\textcolor{stringliteral}{'gpu'}])
662         \textcolor{comment}{# indicate whether using fp16}
663         self.fp16 = self.use\_cuda \textcolor{keywordflow}{and} self.opt.get(\textcolor{stringliteral}{'fp16'}, \textcolor{keyword}{False})
664 
665         \textcolor{keywordflow}{if} shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
666             \textcolor{comment}{# intitialize any important structures from scratch}
667             self.dict = self.build\_dictionary()
668 
669             \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'fp16'}):
670                 \textcolor{comment}{# Volta cores revert to FP32 hardware if tensors are not multiples}
671                 \textcolor{comment}{# of 8 in all dimensions. This INCLUDES the embeddings layer! As}
672                 \textcolor{comment}{# such, we need some extra magic to ensure the dictionary is padded}
673                 \textcolor{comment}{# with extra tokens to make it a multiple of 8.}
674                 \textcolor{keywordflow}{if} len(self.dict) % 8 != 0:
675                     \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(8 - len(self.dict) % 8):
676                         self.dict[\textcolor{stringliteral}{'\_\_FP16\_PAD\_\{\}\_\_'}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(i)] = 1
677 
678             self.metrics: Dict[str, Any] = \{\}
679             \textcolor{comment}{# gradient norms}
680             self.metrics[\textcolor{stringliteral}{'gnorm'}] = 0.0
681             \textcolor{comment}{# gradient clipping rate}
682             self.metrics[\textcolor{stringliteral}{'clip'}] = 0.0
683             \textcolor{comment}{# number of calls to optimizer.step()}
684             self.metrics[\textcolor{stringliteral}{'updates'}] = 0
685         \textcolor{keywordflow}{else}:
686             \textcolor{comment}{# copy initialized data from shared table}
687             self.opt = shared[\textcolor{stringliteral}{'opt'}]
688             self.dict = shared[\textcolor{stringliteral}{'dict'}]
689             self.model = shared[\textcolor{stringliteral}{'model'}]
690             self.criterion = shared[\textcolor{stringliteral}{'criterion'}]
691             self.metrics = shared[\textcolor{stringliteral}{'metrics'}]
692 
693         \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1:
694             torch.set\_num\_threads(1)
695 
696         \textcolor{comment}{# Default to the class name, sans "Agent". child can override}
697         self.id = \hyperlink{namespaceparlai_1_1agents_1_1tfidf__retriever_1_1build__tfidf_ad5dfae268e23f506da084a9efb72f619}{type}(self).\_\_name\_\_.replace(\textcolor{stringliteral}{"Agent"}, \textcolor{stringliteral}{""})
698 
699         \textcolor{comment}{# now set up any fields that all instances may need}
700         self.EMPTY = torch.zeros(0, dtype=torch.long)
701         self.NULL\_IDX = self.dict[self.dict.null\_token]
702         self.START\_IDX = self.dict[self.dict.start\_token]
703         self.END\_IDX = self.dict[self.dict.end\_token]
704 
705         \textcolor{comment}{# for gradient acumulation}
706         self.\_number\_grad\_accum = 0
707         \textcolor{comment}{# for the LR scheduler}
708         self.\_number\_training\_updates = 0
709         \textcolor{comment}{# fixed random seed}
710         self.random = random.Random(42)
711         \textcolor{comment}{# can remember as few as zero utterances if desired}
712         self.histsz = opt[\textcolor{stringliteral}{'history\_size'}]
713         \textcolor{comment}{# truncate == 0 might give funny behavior}
714         self.truncate = opt[\textcolor{stringliteral}{'truncate'}] \textcolor{keywordflow}{if} opt[\textcolor{stringliteral}{'truncate'}] >= 0 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
715         text\_truncate = opt.get(\textcolor{stringliteral}{'text\_truncate'}) \textcolor{keywordflow}{or} opt[\textcolor{stringliteral}{'truncate'}]
716         self.text\_truncate = text\_truncate \textcolor{keywordflow}{if} text\_truncate >= 0 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
717         label\_truncate = opt.get(\textcolor{stringliteral}{'label\_truncate'}) \textcolor{keywordflow}{or} opt[\textcolor{stringliteral}{'truncate'}]
718         self.label\_truncate = label\_truncate \textcolor{keywordflow}{if} label\_truncate >= 0 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
719         \textcolor{comment}{# stores up to hist\_utt past observations within current dialog}
720         self.history = self.build\_history()
721 
722         self.is\_training = \textcolor{keyword}{False}  \textcolor{comment}{# track whether model is training}
723         self.rank\_candidates = opt[\textcolor{stringliteral}{'rank\_candidates'}]
724         self.add\_person\_tokens = opt.get(\textcolor{stringliteral}{'person\_tokens'}, \textcolor{keyword}{False})
725         \textcolor{comment}{# set interactive mode or not according to options.}
726         self.set\_interactive\_mode(opt[\textcolor{stringliteral}{'interactive\_mode'}], shared)
727 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a51174dfa508970e3392246b02d0d94b5}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a51174dfa508970e3392246b02d0d94b5}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!act@{act}}
\index{act@{act}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{act()}{act()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+act (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Call batch_act with the singleton batch.
\end{DoxyVerb}
 

Definition at line 1798 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1798     \textcolor{keyword}{def }act(self):
1799         \textcolor{stringliteral}{"""}
1800 \textcolor{stringliteral}{        Call batch\_act with the singleton batch.}
1801 \textcolor{stringliteral}{        """}
1802         \textcolor{comment}{# BatchWorld handles calling self\_observe, but we're in a Hogwild or Interactive}
1803         \textcolor{comment}{# world, so we need to handle this ourselves.}
1804         response = self.batch\_act([self.observation])[0]
1805         self.self\_observe(response)
1806         \textcolor{keywordflow}{return} response
1807 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4a72bdd07d2cb5ce402d0058140cad0d}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4a72bdd07d2cb5ce402d0058140cad0d}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}}
\index{add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{add\+\_\+cmdline\+\_\+args()}{add\_cmdline\_args()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+add\+\_\+cmdline\+\_\+args (\begin{DoxyParamCaption}\item[{}]{cls,  }\item[{}]{argparser }\end{DoxyParamCaption})}

\begin{DoxyVerb}Add the default commandline args we expect most agents to want.
\end{DoxyVerb}
 

Definition at line 387 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
387     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(cls, argparser):
388         \textcolor{stringliteral}{"""}
389 \textcolor{stringliteral}{        Add the default commandline args we expect most agents to want.}
390 \textcolor{stringliteral}{        """}
391         agent = argparser.add\_argument\_group(\textcolor{stringliteral}{'TorchAgent Arguments'})
392         agent.add\_argument(
393             \textcolor{stringliteral}{'-i'},
394             \textcolor{stringliteral}{'--interactive-mode'},
395             type=\textcolor{stringliteral}{'bool'},
396             default=\textcolor{keyword}{False},
397             help=\textcolor{stringliteral}{'Whether in full interactive mode or not,  which means generating text or'}
398             \textcolor{stringliteral}{' retrieving from a full set of candidates, which is necessary to actually'}
399             \textcolor{stringliteral}{' do full dialogue. However, during training or quick validation (e.g. PPL for'}
400             \textcolor{stringliteral}{' generation or ranking a few candidates for ranking models) you might want these'}
401             \textcolor{stringliteral}{' set to off.'}
402             \textcolor{stringliteral}{' Typically, scripts can set their preferred default behavior at the start,'}
403             \textcolor{stringliteral}{' e.g. eval scripts.'},
404         )
405         \textcolor{comment}{# pretrained embedding arguments}
406         agent.add\_argument(
407             \textcolor{stringliteral}{'-emb'},
408             \textcolor{stringliteral}{'--embedding-type'},
409             default=\textcolor{stringliteral}{'random'},
410             choices=[
411                 \textcolor{stringliteral}{'random'},
412                 \textcolor{stringliteral}{'glove'},
413                 \textcolor{stringliteral}{'glove-fixed'},
414                 \textcolor{stringliteral}{'glove-twitter-fixed'},
415                 \textcolor{stringliteral}{'fasttext'},
416                 \textcolor{stringliteral}{'fasttext-fixed'},
417                 \textcolor{stringliteral}{'fasttext\_cc'},
418                 \textcolor{stringliteral}{'fasttext\_cc-fixed'},
419             ],
420             help=\textcolor{stringliteral}{'Choose between different strategies for initializing word '}
421             \textcolor{stringliteral}{'embeddings. Default is random, but can also preinitialize '}
422             \textcolor{stringliteral}{'from Glove or Fasttext. Preinitialized embeddings can also '}
423             \textcolor{stringliteral}{'be fixed so they are not updated during training.'},
424         )
425         agent.add\_argument(
426             \textcolor{stringliteral}{'-embp'},
427             \textcolor{stringliteral}{'--embedding-projection'},
428             default=\textcolor{stringliteral}{'random'},
429             help=\textcolor{stringliteral}{'If pretrained embeddings have a different dimensionality '}
430             \textcolor{stringliteral}{'than your embedding size, strategy for projecting to the '}
431             \textcolor{stringliteral}{'correct size. If the dimensions are the same, this is '}
432             \textcolor{stringliteral}{'ignored unless you append "-force" to your choice.'},
433         )
434         agent.add\_argument(
435             \textcolor{stringliteral}{'--fp16'}, type=\textcolor{stringliteral}{'bool'}, default=\textcolor{keyword}{False}, help=\textcolor{stringliteral}{'Use fp16 computations.'}
436         )
437         \textcolor{comment}{# optimizer arguments}
438         optim\_group = agent.add\_argument\_group(\textcolor{stringliteral}{'Optimizer Arguments'})
439         optim\_group.add\_argument(
440             \textcolor{stringliteral}{'-opt'},
441             \textcolor{stringliteral}{'--optimizer'},
442             default=\textcolor{stringliteral}{'sgd'},
443             choices=cls.optim\_opts(),
444             help=\textcolor{stringliteral}{'Choose between pytorch optimizers. Any member of torch.optim'}
445             \textcolor{stringliteral}{' should be valid.'},
446         )
447         optim\_group.add\_argument(
448             \textcolor{stringliteral}{'-lr'}, \textcolor{stringliteral}{'--learningrate'}, type=float, default=1, help=\textcolor{stringliteral}{'Learning rate'}
449         )
450         optim\_group.add\_argument(
451             \textcolor{stringliteral}{'-clip'},
452             \textcolor{stringliteral}{'--gradient-clip'},
453             type=float,
454             default=0.1,
455             help=\textcolor{stringliteral}{'gradient clipping using l2 norm'},
456         )
457         optim\_group.add\_argument(
458             \textcolor{stringliteral}{'--adam-eps'},
459             type=float,
460             default=1e-8,
461             hidden=\textcolor{keyword}{True},
462             help=\textcolor{stringliteral}{'Epsilon value for Adam optimizers. Set to 1e-6 if your '}
463             \textcolor{stringliteral}{'large model has stability issues, but prefer the default.'},
464         )
465         optim\_group.add\_argument(
466             \textcolor{stringliteral}{'-mom'},
467             \textcolor{stringliteral}{'--momentum'},
468             default=0,
469             type=float,
470             help=\textcolor{stringliteral}{'if applicable, momentum value for optimizer.'},
471         )
472         optim\_group.add\_argument(
473             \textcolor{stringliteral}{'--nesterov'},
474             default=\textcolor{keyword}{True},
475             type=\textcolor{stringliteral}{'bool'},
476             help=\textcolor{stringliteral}{'if applicable, whether to use nesterov momentum.'},
477         )
478         optim\_group.add\_argument(
479             \textcolor{stringliteral}{'-nu'},
480             \textcolor{stringliteral}{'--nus'},
481             default=\textcolor{stringliteral}{'0.7'},
482             type=\textcolor{stringliteral}{'floats'},
483             help=\textcolor{stringliteral}{'if applicable, nu value(s) for optimizer. can use a single '}
484             \textcolor{stringliteral}{'value like 0.7 or a comma-separated tuple like 0.7,1.0'},
485         )
486         optim\_group.add\_argument(
487             \textcolor{stringliteral}{'-beta'},
488             \textcolor{stringliteral}{'--betas'},
489             default=\textcolor{stringliteral}{'0.9,0.999'},
490             type=\textcolor{stringliteral}{'floats'},
491             help=\textcolor{stringliteral}{'if applicable, beta value(s) for optimizer. can use a single '}
492             \textcolor{stringliteral}{'value like 0.9 or a comma-separated tuple like 0.9,0.999'},
493         )
494         optim\_group.add\_argument(
495             \textcolor{stringliteral}{'-wdecay'},
496             \textcolor{stringliteral}{'--weight-decay'},
497             type=float,
498             default=\textcolor{keywordtype}{None},
499             help=\textcolor{stringliteral}{'Weight decay on the weights.'},
500         )
501 
502         \textcolor{comment}{# lr scheduler}
503         lr\_group = agent.add\_argument\_group(\textcolor{stringliteral}{'Learning Rate Scheduler'})
504         lr\_group.add\_argument(
505             \textcolor{stringliteral}{'--lr-scheduler'},
506             type=str,
507             default=\textcolor{stringliteral}{'reduceonplateau'},
508             choices=[\textcolor{stringliteral}{'reduceonplateau'}, \textcolor{stringliteral}{'none'}, \textcolor{stringliteral}{'fixed'}, \textcolor{stringliteral}{'invsqrt'}],
509             help=\textcolor{stringliteral}{'Learning rate scheduler.'},
510         )
511         lr\_group.add\_argument(
512             \textcolor{stringliteral}{'--lr-scheduler-patience'},
513             type=int,
514             default=3,
515             help=\textcolor{stringliteral}{'LR scheduler patience. In number of validation runs. If using '}
516             \textcolor{stringliteral}{'fixed scheduler, LR is decayed every <patience> validations.'},
517         )
518         lr\_group.add\_argument(
519             \textcolor{stringliteral}{'--lr-scheduler-decay'},
520             type=float,
521             default=0.5,
522             help=\textcolor{stringliteral}{'Decay factor for LR scheduler, or how much LR is multiplied by '}
523             \textcolor{stringliteral}{'when it is lowered.'},
524         )
525         lr\_group.add\_argument(
526             \textcolor{stringliteral}{'--warmup-updates'},
527             type=int,
528             default=-1,
529             hidden=\textcolor{keyword}{True},
530             help=\textcolor{stringliteral}{'Learning rate warmup period, in number of SGD updates. '}
531             \textcolor{stringliteral}{'Linearly scales up LR over period. Only enabled if > 0.'},
532         )
533         lr\_group.add\_argument(
534             \textcolor{stringliteral}{'--warmup-rate'},
535             type=float,
536             default=1e-4,
537             hidden=\textcolor{keyword}{True},
538             help=\textcolor{stringliteral}{'Warmup learning rate *multiplier*. Initial LR is multiplied by '}
539             \textcolor{stringliteral}{'this value. Linearly adjusted up to 1.0 across --warmup-updates '}
540             \textcolor{stringliteral}{'steps.'},
541         )
542         lr\_group.add\_argument(
543             \textcolor{stringliteral}{'--update-freq'},
544             type=int,
545             default=1,
546             hidden=\textcolor{keyword}{True},
547             help=\textcolor{stringliteral}{'Accumulate gradients N times before performing an optimizer.step().'},
548         )
549 
550         \textcolor{comment}{# preprocessing arguments}
551         agent.add\_argument(
552             \textcolor{stringliteral}{'-rc'},
553             \textcolor{stringliteral}{'--rank-candidates'},
554             type=\textcolor{stringliteral}{'bool'},
555             default=\textcolor{keyword}{False},
556             help=\textcolor{stringliteral}{'Whether the model should parse candidates for ranking.'},
557         )
558         agent.add\_argument(
559             \textcolor{stringliteral}{'-tr'},
560             \textcolor{stringliteral}{'--truncate'},
561             default=-1,
562             type=int,
563             help=\textcolor{stringliteral}{'Truncate input lengths to increase speed / use less memory.'},
564         )
565         agent.add\_argument(
566             \textcolor{stringliteral}{'--text-truncate'},
567             type=int,
568             help=\textcolor{stringliteral}{'Text input truncation length: if not specified, this will '}
569             \textcolor{stringliteral}{'default to `truncate`'},
570         )
571         agent.add\_argument(
572             \textcolor{stringliteral}{'--label-truncate'},
573             type=int,
574             help=\textcolor{stringliteral}{'Label truncation length: if not specified, this will default '}
575             \textcolor{stringliteral}{'to `truncate`'},
576         )
577         agent.add\_argument(
578             \textcolor{stringliteral}{'-histsz'},
579             \textcolor{stringliteral}{'--history-size'},
580             default=-1,
581             type=int,
582             help=\textcolor{stringliteral}{'Number of past dialog utterances to remember.'},
583         )
584         agent.add\_argument(
585             \textcolor{stringliteral}{'-pt'},
586             \textcolor{stringliteral}{'--person-tokens'},
587             type=\textcolor{stringliteral}{'bool'},
588             default=\textcolor{keyword}{False},
589             help=\textcolor{stringliteral}{'add person tokens to history. adds \_\_p1\_\_ in front of input '}
590             \textcolor{stringliteral}{'text and \_\_p2\_\_ in front of past labels when available or '}
591             \textcolor{stringliteral}{'past utterances generated by the model. these are added to '}
592             \textcolor{stringliteral}{'the dictionary during initialization.'},
593         )
594         agent.add\_argument(
595             \textcolor{stringliteral}{'--split-lines'},
596             type=\textcolor{stringliteral}{'bool'},
597             default=\textcolor{keyword}{False},
598             help=\textcolor{stringliteral}{'split the dialogue history on newlines and save in separate '}
599             \textcolor{stringliteral}{'vectors'},
600         )
601         agent.add\_argument(
602             \textcolor{stringliteral}{'--use-reply'},
603             default=\textcolor{stringliteral}{'label'},
604             hidden=\textcolor{keyword}{True},
605             choices=[\textcolor{stringliteral}{'label'}, \textcolor{stringliteral}{'model'}, \textcolor{stringliteral}{'none'}],
606             help=\textcolor{stringliteral}{'Which previous replies to use as history. If label, use '}
607             \textcolor{stringliteral}{'gold dataset replies. If model, use model\(\backslash\)'s own replies. '}
608             \textcolor{stringliteral}{'If none, do not track replies in history.'},
609         )
610         agent.add\_argument(
611             \textcolor{stringliteral}{'--add-p1-after-newln'},
612             type=\textcolor{stringliteral}{'bool'},
613             default=\textcolor{keyword}{False},
614             hidden=\textcolor{keyword}{True},
615             help=\textcolor{stringliteral}{'Add the other speaker token before the last newline in the '}
616             \textcolor{stringliteral}{'input instead of at the beginning of the input. this is '}
617             \textcolor{stringliteral}{'useful for tasks that include some kind of context before '}
618             \textcolor{stringliteral}{'the actual utterance (e.g. squad, babi, personachat).'},
619         )
620         agent.add\_argument(
621             \textcolor{stringliteral}{'--delimiter'},
622             type=str,
623             default=\textcolor{stringliteral}{'\(\backslash\)n'},
624             help=\textcolor{stringliteral}{'Join history lines with this token, defaults to newline'},
625         )
626         \textcolor{comment}{# GPU arguments}
627         \textcolor{comment}{# these gpu options are all mutually exclusive, and should error if the}
628         \textcolor{comment}{# user tries to present multiple of them}
629         gpugroup = agent.add\_mutually\_exclusive\_group()
630         gpugroup.add\_argument(
631             \textcolor{stringliteral}{'-gpu'}, \textcolor{stringliteral}{'--gpu'}, type=int, default=-1, help=\textcolor{stringliteral}{'which GPU to use'}
632         )
633         gpugroup.add\_argument(
634             \textcolor{stringliteral}{'--no-cuda'},
635             default=\textcolor{keyword}{False},
636             action=\textcolor{stringliteral}{'store\_true'},
637             dest=\textcolor{stringliteral}{'no\_cuda'},
638             help=\textcolor{stringliteral}{'disable GPUs even if available. otherwise, will use GPUs if '}
639             \textcolor{stringliteral}{'available on the device.'},
640         )
641 
642         cls.dictionary\_class().\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(argparser)
643 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8df662b1258ec67752b4fc0ad45733f9}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8df662b1258ec67752b4fc0ad45733f9}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!backward@{backward}}
\index{backward@{backward}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{backward()}{backward()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+backward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{loss }\end{DoxyParamCaption})}

\begin{DoxyVerb}Perform a backward pass.

It is recommended you use this instead of loss.backward(), for integration with
distributed training and FP16 training.
\end{DoxyVerb}
 

Definition at line 1868 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1868     \textcolor{keyword}{def }backward(self, loss):
1869         \textcolor{stringliteral}{"""}
1870 \textcolor{stringliteral}{        Perform a backward pass.}
1871 \textcolor{stringliteral}{}
1872 \textcolor{stringliteral}{        It is recommended you use this instead of loss.backward(), for integration with}
1873 \textcolor{stringliteral}{        distributed training and FP16 training.}
1874 \textcolor{stringliteral}{        """}
1875         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'update\_freq'}, 1) > 1:
1876             \textcolor{comment}{# gradient accumulation, but still need to average across the minibatches}
1877             loss = loss / self.opt[\textcolor{stringliteral}{'update\_freq'}]
1878 
1879         \textcolor{keywordflow}{if} self.fp16:
1880             self.optimizer.backward(loss, update\_master\_grads=\textcolor{keyword}{False})
1881         \textcolor{keywordflow}{else}:
1882             loss.backward()
1883 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7754a74d6c87590f46e71ec486c285a8}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7754a74d6c87590f46e71ec486c285a8}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!batch\+\_\+act@{batch\+\_\+act}}
\index{batch\+\_\+act@{batch\+\_\+act}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{batch\+\_\+act()}{batch\_act()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+batch\+\_\+act (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{observations }\end{DoxyParamCaption})}

\begin{DoxyVerb}Process a batch of observations (batchsize list of message dicts).

These observations have been preprocessed by the observe method.

Subclasses can override this for special functionality, but if the
default behaviors are fine then just override the ``train_step`` and
``eval_step`` methods instead. The former is called when labels are
present in the observations batch; otherwise, the latter is called.
\end{DoxyVerb}
 

Definition at line 1808 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1808     \textcolor{keyword}{def }batch\_act(self, observations):
1809         \textcolor{stringliteral}{"""}
1810 \textcolor{stringliteral}{        Process a batch of observations (batchsize list of message dicts).}
1811 \textcolor{stringliteral}{}
1812 \textcolor{stringliteral}{        These observations have been preprocessed by the observe method.}
1813 \textcolor{stringliteral}{}
1814 \textcolor{stringliteral}{        Subclasses can override this for special functionality, but if the}
1815 \textcolor{stringliteral}{        default behaviors are fine then just override the ``train\_step`` and}
1816 \textcolor{stringliteral}{        ``eval\_step`` methods instead. The former is called when labels are}
1817 \textcolor{stringliteral}{        present in the observations batch; otherwise, the latter is called.}
1818 \textcolor{stringliteral}{        """}
1819         batch\_size = len(observations)
1820         \textcolor{comment}{# initialize a list of replies with this agent's id}
1821         batch\_reply = [
1822             Message(\{\textcolor{stringliteral}{'id'}: self.getID(), \textcolor{stringliteral}{'episode\_done'}: \textcolor{keyword}{False}\})
1823             \textcolor{keywordflow}{for} \_ \textcolor{keywordflow}{in} range(batch\_size)
1824         ]
1825 
1826         \textcolor{comment}{# check if there are any labels available, if so we will train on them}
1827         self.is\_training = any(\textcolor{stringliteral}{'labels'} \textcolor{keywordflow}{in} obs \textcolor{keywordflow}{for} obs \textcolor{keywordflow}{in} observations)
1828 
1829         \textcolor{comment}{# create a batch from the vectors}
1830         batch = self.batchify(observations)
1831 
1832         \textcolor{keywordflow}{if} self.is\_training:
1833             output = self.train\_step(batch)
1834         \textcolor{keywordflow}{else}:
1835             with torch.no\_grad():
1836                 \textcolor{comment}{# save memory and compute by disabling autograd.}
1837                 \textcolor{comment}{# use `with torch.enable\_grad()` to gain back graidients.}
1838                 output = self.eval\_step(batch)
1839 
1840         \textcolor{keywordflow}{if} output \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1841             \textcolor{keywordflow}{return} batch\_reply
1842 
1843         self.match\_batch(batch\_reply, batch.valid\_indices, output)
1844         \textcolor{keywordflow}{return} batch\_reply
1845 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4c5824776df0c6cf995984a5e7a3f433}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4c5824776df0c6cf995984a5e7a3f433}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!batchify@{batchify}}
\index{batchify@{batchify}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{batchify()}{batchify()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+batchify (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{obs\+\_\+batch,  }\item[{}]{sort = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create a batch of valid observations from an unchecked batch.

A valid observation is one that passes the lambda provided to the
function, which defaults to checking if the preprocessed 'text_vec'
field is present which would have been set by this agent's 'vectorize'
function.

Returns a namedtuple Batch. See original definition above for in-depth
explanation of each field.

If you want to include additonal fields in the batch, you can subclass
this function and return your own "Batch" namedtuple: copy the Batch
namedtuple at the top of this class, and then add whatever additional
fields that you want to be able to access. You can then call
super().batchify(...) to set up the original fields and then set up the
additional fields in your subclass and return that batch instead.

:param obs_batch:
    List of vectorized observations

:param sort:
    Default False, orders the observations by length of vectors. Set to
    true when using torch.nn.utils.rnn.pack_padded_sequence.  Uses the text
    vectors if available, otherwise uses the label vectors if available.
\end{DoxyVerb}
 

Definition at line 1422 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1422     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1utils_aca22dd97c5b6dcda2a7479c1cb22ef1e}{batchify}(self, obs\_batch, sort=False):
1423         \textcolor{stringliteral}{"""}
1424 \textcolor{stringliteral}{        Create a batch of valid observations from an unchecked batch.}
1425 \textcolor{stringliteral}{}
1426 \textcolor{stringliteral}{        A valid observation is one that passes the lambda provided to the}
1427 \textcolor{stringliteral}{        function, which defaults to checking if the preprocessed 'text\_vec'}
1428 \textcolor{stringliteral}{        field is present which would have been set by this agent's 'vectorize'}
1429 \textcolor{stringliteral}{        function.}
1430 \textcolor{stringliteral}{}
1431 \textcolor{stringliteral}{        Returns a namedtuple Batch. See original definition above for in-depth}
1432 \textcolor{stringliteral}{        explanation of each field.}
1433 \textcolor{stringliteral}{}
1434 \textcolor{stringliteral}{        If you want to include additonal fields in the batch, you can subclass}
1435 \textcolor{stringliteral}{        this function and return your own "Batch" namedtuple: copy the Batch}
1436 \textcolor{stringliteral}{        namedtuple at the top of this class, and then add whatever additional}
1437 \textcolor{stringliteral}{        fields that you want to be able to access. You can then call}
1438 \textcolor{stringliteral}{        super().batchify(...) to set up the original fields and then set up the}
1439 \textcolor{stringliteral}{        additional fields in your subclass and return that batch instead.}
1440 \textcolor{stringliteral}{}
1441 \textcolor{stringliteral}{        :param obs\_batch:}
1442 \textcolor{stringliteral}{            List of vectorized observations}
1443 \textcolor{stringliteral}{}
1444 \textcolor{stringliteral}{        :param sort:}
1445 \textcolor{stringliteral}{            Default False, orders the observations by length of vectors. Set to}
1446 \textcolor{stringliteral}{            true when using torch.nn.utils.rnn.pack\_padded\_sequence.  Uses the text}
1447 \textcolor{stringliteral}{            vectors if available, otherwise uses the label vectors if available.}
1448 \textcolor{stringliteral}{        """}
1449         \textcolor{keywordflow}{if} len(obs\_batch) == 0:
1450             \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a74cfde390a2b9861179ac0fcd59da28c}{Batch}()
1451 
1452         valid\_obs = [(i, ex) \textcolor{keywordflow}{for} i, ex \textcolor{keywordflow}{in} enumerate(obs\_batch) \textcolor{keywordflow}{if} self.is\_valid(ex)]
1453 
1454         \textcolor{keywordflow}{if} len(valid\_obs) == 0:
1455             \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a74cfde390a2b9861179ac0fcd59da28c}{Batch}()
1456 
1457         valid\_inds, exs = zip(*valid\_obs)
1458 
1459         \textcolor{comment}{# TEXT}
1460         xs, x\_lens = \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}
1461         \textcolor{keywordflow}{if} any(ex.get(\textcolor{stringliteral}{'text\_vec'}) \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None} \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs):
1462             \_xs = [ex.get(\textcolor{stringliteral}{'text\_vec'}, self.EMPTY) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1463             xs, x\_lens = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_adb5a414ae439f14c54e8c760b91cc4c8}{padded\_tensor}(
1464                 \_xs, self.NULL\_IDX, self.use\_cuda, fp16friendly=self.opt.get(\textcolor{stringliteral}{'fp16'})
1465             )
1466             \textcolor{keywordflow}{if} sort:
1467                 sort = \textcolor{keyword}{False}  \textcolor{comment}{# now we won't sort on labels}
1468                 xs, x\_lens, valid\_inds, exs = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_a1521e559b740f741ebb47b8755202bb2}{argsort}(
1469                     x\_lens, xs, x\_lens, valid\_inds, exs, descending=\textcolor{keyword}{True}
1470                 )
1471 
1472         \textcolor{comment}{# LABELS}
1473         labels\_avail = any(\textcolor{stringliteral}{'labels\_vec'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs)
1474         some\_labels\_avail = labels\_avail \textcolor{keywordflow}{or} any(\textcolor{stringliteral}{'eval\_labels\_vec'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs)
1475 
1476         ys, y\_lens, labels = \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}
1477         \textcolor{keywordflow}{if} some\_labels\_avail:
1478             field = \textcolor{stringliteral}{'labels'} \textcolor{keywordflow}{if} labels\_avail \textcolor{keywordflow}{else} \textcolor{stringliteral}{'eval\_labels'}
1479 
1480             label\_vecs = [ex.get(field + \textcolor{stringliteral}{'\_vec'}, self.EMPTY) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1481             labels = [ex.get(field + \textcolor{stringliteral}{'\_choice'}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1482             y\_lens = [y.shape[0] \textcolor{keywordflow}{for} y \textcolor{keywordflow}{in} label\_vecs]
1483 
1484             ys, y\_lens = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_adb5a414ae439f14c54e8c760b91cc4c8}{padded\_tensor}(
1485                 label\_vecs,
1486                 self.NULL\_IDX,
1487                 self.use\_cuda,
1488                 fp16friendly=self.opt.get(\textcolor{stringliteral}{'fp16'}),
1489             )
1490             \textcolor{keywordflow}{if} sort \textcolor{keywordflow}{and} xs \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1491                 ys, valid\_inds, label\_vecs, labels, y\_lens = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_a1521e559b740f741ebb47b8755202bb2}{argsort}(
1492                     y\_lens, ys, valid\_inds, label\_vecs, labels, y\_lens, descending=\textcolor{keyword}{True}
1493                 )
1494 
1495         \textcolor{comment}{# LABEL\_CANDIDATES}
1496         cands, cand\_vecs = \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}
1497         \textcolor{keywordflow}{if} any(\textcolor{stringliteral}{'label\_candidates\_vecs'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs):
1498             cands = [ex.get(\textcolor{stringliteral}{'label\_candidates'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1499             cand\_vecs = [ex.get(\textcolor{stringliteral}{'label\_candidates\_vecs'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1500 
1501         \textcolor{comment}{# IMAGE}
1502         imgs = \textcolor{keywordtype}{None}
1503         \textcolor{keywordflow}{if} any(\textcolor{stringliteral}{'image'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs):
1504             imgs = [ex.get(\textcolor{stringliteral}{'image'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1505 
1506         \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a74cfde390a2b9861179ac0fcd59da28c}{Batch}(
1507             text\_vec=xs,
1508             text\_lengths=x\_lens,
1509             label\_vec=ys,
1510             label\_lengths=y\_lens,
1511             labels=labels,
1512             valid\_indices=valid\_inds,
1513             candidates=cands,
1514             candidate\_vecs=cand\_vecs,
1515             image=imgs,
1516             observations=exs,
1517         )
1518 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a233316f9ec2805dd6a08fbf07f3a078a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a233316f9ec2805dd6a08fbf07f3a078a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+dictionary@{build\+\_\+dictionary}}
\index{build\+\_\+dictionary@{build\+\_\+dictionary}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+dictionary()}{build\_dictionary()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+dictionary (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return the constructed dictionary, which will be set to self.dict.

If you need to add additional tokens to the dictionary, this is likely the right
place to do it.
\end{DoxyVerb}
 

Definition at line 741 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
741     \textcolor{keyword}{def }build\_dictionary(self):
742         \textcolor{stringliteral}{"""}
743 \textcolor{stringliteral}{        Return the constructed dictionary, which will be set to self.dict.}
744 \textcolor{stringliteral}{}
745 \textcolor{stringliteral}{        If you need to add additional tokens to the dictionary, this is likely the right}
746 \textcolor{stringliteral}{        place to do it.}
747 \textcolor{stringliteral}{        """}
748         d = self.dictionary\_class()(self.opt)
749         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'person\_tokens'}):
750             d[self.P1\_TOKEN] = 999\_999\_999
751             d[self.P2\_TOKEN] = 999\_999\_998
752         \textcolor{keywordflow}{return} d
753 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab22f61f153b522f429210c61eed2d5af}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab22f61f153b522f429210c61eed2d5af}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+history@{build\+\_\+history}}
\index{build\+\_\+history@{build\+\_\+history}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+history()}{build\_history()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+history (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return the constructed history object.
\end{DoxyVerb}
 

Definition at line 728 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
728     \textcolor{keyword}{def }build\_history(self):
729         \textcolor{stringliteral}{"""}
730 \textcolor{stringliteral}{        Return the constructed history object.}
731 \textcolor{stringliteral}{        """}
732         \textcolor{keywordflow}{return} self.history\_class()(
733             self.opt,
734             maxlen=self.text\_truncate,
735             size=self.histsz,
736             p1\_token=self.P1\_TOKEN,
737             p2\_token=self.P2\_TOKEN,
738             dict\_agent=self.dict,
739         )
740 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa51ac42dc34e3d2281a01cba78a96151}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa51ac42dc34e3d2281a01cba78a96151}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+lr\+\_\+scheduler@{build\+\_\+lr\+\_\+scheduler}}
\index{build\+\_\+lr\+\_\+scheduler@{build\+\_\+lr\+\_\+scheduler}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+lr\+\_\+scheduler()}{build\_lr\_scheduler()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+lr\+\_\+scheduler (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{states = {\ttfamily None},  }\item[{}]{hard\+\_\+reset = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create the learning rate scheduler, and assign it to self.scheduler.

This scheduler will be updated upon a call to receive_metrics.
May also create self.warmup_scheduler, if appropriate.

:param state_dict states: Possible state_dict provided by model
    checkpoint, for restoring LR state

:param bool hard_reset: If true, the LR scheduler should ignore the
    state dictionary.
\end{DoxyVerb}
 

Definition at line 884 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
884     \textcolor{keyword}{def }build\_lr\_scheduler(self, states=None, hard\_reset=False):
885         \textcolor{stringliteral}{"""}
886 \textcolor{stringliteral}{        Create the learning rate scheduler, and assign it to self.scheduler.}
887 \textcolor{stringliteral}{}
888 \textcolor{stringliteral}{        This scheduler will be updated upon a call to receive\_metrics.}
889 \textcolor{stringliteral}{        May also create self.warmup\_scheduler, if appropriate.}
890 \textcolor{stringliteral}{}
891 \textcolor{stringliteral}{        :param state\_dict states: Possible state\_dict provided by model}
892 \textcolor{stringliteral}{            checkpoint, for restoring LR state}
893 \textcolor{stringliteral}{}
894 \textcolor{stringliteral}{        :param bool hard\_reset: If true, the LR scheduler should ignore the}
895 \textcolor{stringliteral}{            state dictionary.}
896 \textcolor{stringliteral}{        """}
897         \textcolor{comment}{# first make sure there are no null pointers}
898         \textcolor{keywordflow}{if} states \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
899             states = \{\}
900         optimizer = self.optimizer
901         \textcolor{keywordflow}{if} self.fp16:
902             \textcolor{comment}{# lr schedulers don't work with apex, they expect the "real" optimizer}
903             optimizer = optimizer.optimizer
904 
905         warmup\_updates = self.opt.get(\textcolor{stringliteral}{'warmup\_updates'}, -1)
906         updates\_so\_far = states.get(\textcolor{stringliteral}{'number\_training\_updates'}, 0)
907         \textcolor{keywordflow}{if} warmup\_updates > 0 \textcolor{keywordflow}{and} (updates\_so\_far < warmup\_updates \textcolor{keywordflow}{or} hard\_reset):
908 
909             \textcolor{keyword}{def }\_warmup\_lr(step):
910                 start = self.opt[\textcolor{stringliteral}{'warmup\_rate'}]
911                 end = 1.0
912                 progress = min(1.0, step / self.opt[\textcolor{stringliteral}{'warmup\_updates'}])
913                 lr\_mult = start + (end - start) * progress
914                 \textcolor{keywordflow}{return} lr\_mult
915 
916             self.warmup\_scheduler = optim.lr\_scheduler.LambdaLR(optimizer, \_warmup\_lr)
917         \textcolor{keywordflow}{else}:
918             self.warmup\_scheduler = \textcolor{keywordtype}{None}
919 
920         patience = self.opt.get(\textcolor{stringliteral}{'lr\_scheduler\_patience'}, 3)
921         decay = self.opt.get(\textcolor{stringliteral}{'lr\_scheduler\_decay'}, 0.5)
922 
923         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'none'}:
924             self.scheduler = \textcolor{keywordtype}{None}
925         \textcolor{keywordflow}{elif} decay == 1.0:
926             \hyperlink{namespaceparlai_1_1utils_1_1misc_a884a3aefa90581f53bc592fa6a78dc43}{warn\_once}(
927                 \textcolor{stringliteral}{"Your LR decay is set to 1.0. Assuming you meant you wanted "}
928                 \textcolor{stringliteral}{"to disable learning rate scheduling. Adjust --lr-scheduler-decay "}
929                 \textcolor{stringliteral}{"if this is not correct."}
930             )
931             self.scheduler = \textcolor{keywordtype}{None}
932         \textcolor{keywordflow}{elif} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'reduceonplateau'}:
933             self.scheduler = optim.lr\_scheduler.ReduceLROnPlateau(
934                 optimizer, \textcolor{stringliteral}{'min'}, factor=decay, patience=patience, verbose=\textcolor{keyword}{True}
935             )
936         \textcolor{keywordflow}{elif} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'fixed'}:
937             self.scheduler = optim.lr\_scheduler.StepLR(optimizer, patience, gamma=decay)
938         \textcolor{keywordflow}{elif} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'invsqrt'}:
939             \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'warmup\_updates'}, -1) <= 0:
940                 \textcolor{keywordflow}{raise} ValueError(
941                     \textcolor{stringliteral}{'--lr-scheduler invsqrt requires setting --warmup-updates'}
942                 )
943             warmup\_updates = self.opt[\textcolor{stringliteral}{'warmup\_updates'}]
944             decay\_factor = np.sqrt(max(1, warmup\_updates))
945 
946             \textcolor{keyword}{def }\_invsqrt\_lr(step):
947                 \textcolor{keywordflow}{return} decay\_factor / np.sqrt(max(1, step))
948 
949             self.scheduler = optim.lr\_scheduler.LambdaLR(optimizer, \_invsqrt\_lr)
950         \textcolor{keywordflow}{else}:
951             \textcolor{keywordflow}{raise} ValueError(
952                 \textcolor{stringliteral}{"Don't know what to do with lr\_scheduler '\{\}'"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(
953                     self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'})
954                 )
955             )
956 
957         \textcolor{comment}{# time to load LR state from the checkpoint, if possible.}
958         \textcolor{keywordflow}{if} (
959             \textcolor{comment}{# there is already an old LR scheduler saved on disk}
960             states
961             \textcolor{keywordflow}{and}
962             \textcolor{comment}{# and the old LR scheduler is different}
963             states.get(\textcolor{stringliteral}{'lr\_scheduler\_type'}) != self.opt[\textcolor{stringliteral}{'lr\_scheduler'}]
964             \textcolor{keywordflow}{and}
965             \textcolor{comment}{# and we're not already using a fresh scheduler}
966             \textcolor{keywordflow}{not} hard\_reset
967         ):
968             \textcolor{comment}{# the LR scheduler changed, start things fresh}
969             \hyperlink{namespaceparlai_1_1utils_1_1misc_a884a3aefa90581f53bc592fa6a78dc43}{warn\_once}(\textcolor{stringliteral}{"LR scheduler is different from saved. Starting fresh!"})
970             hard\_reset = \textcolor{keyword}{True}
971 
972         \textcolor{keywordflow}{if} hard\_reset:
973             \textcolor{comment}{# We're not going to use the LR schedule, let's just exit}
974             \textcolor{keywordflow}{return}
975 
976         \textcolor{comment}{# do the actual loading (if possible)}
977         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'number\_training\_updates'} \textcolor{keywordflow}{in} states:
978             self.\_number\_training\_updates = states[\textcolor{stringliteral}{'number\_training\_updates'}]
979         \textcolor{keywordflow}{if} self.scheduler \textcolor{keywordflow}{and} \textcolor{stringliteral}{'lr\_scheduler'} \textcolor{keywordflow}{in} states:
980             self.scheduler.load\_state\_dict(states[\textcolor{stringliteral}{'lr\_scheduler'}])
981         \textcolor{keywordflow}{if} states.get(\textcolor{stringliteral}{'warmup\_scheduler'}) \textcolor{keywordflow}{and} getattr(self, \textcolor{stringliteral}{'warmup\_scheduler'}, \textcolor{keywordtype}{None}):
982             self.warmup\_scheduler.load\_state\_dict(states[\textcolor{stringliteral}{'warmup\_scheduler'}])
983 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9a21fa33fa5b2b928024fbc67826f233}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9a21fa33fa5b2b928024fbc67826f233}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+model@{build\+\_\+model}}
\index{build\+\_\+model@{build\+\_\+model}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+model()}{build\_model()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+model (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Construct the model and return it.
\end{DoxyVerb}
 

Definition at line 793 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
793     \textcolor{keyword}{def }build\_model(self):
794         \textcolor{stringliteral}{"""}
795 \textcolor{stringliteral}{        Construct the model and return it.}
796 \textcolor{stringliteral}{        """}
797         \textcolor{keywordflow}{raise} NotImplementedError(\textcolor{stringliteral}{'not implemented for this class'})
798 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aea8849fa69a3f5dbd3216c8b06f180ea}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aea8849fa69a3f5dbd3216c8b06f180ea}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!dictionary\+\_\+class@{dictionary\+\_\+class}}
\index{dictionary\+\_\+class@{dictionary\+\_\+class}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{dictionary\+\_\+class()}{dictionary\_class()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+dictionary\+\_\+class (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}

\begin{DoxyVerb}Return the dictionary class that this agent expects to use.

Can be overriden if a more complex dictionary is required.
\end{DoxyVerb}
 

Definition at line 369 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
369     \textcolor{keyword}{def }dictionary\_class():
370         \textcolor{stringliteral}{"""}
371 \textcolor{stringliteral}{        Return the dictionary class that this agent expects to use.}
372 \textcolor{stringliteral}{}
373 \textcolor{stringliteral}{        Can be overriden if a more complex dictionary is required.}
374 \textcolor{stringliteral}{        """}
375         \textcolor{keywordflow}{return} DictionaryAgent
376 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a18de0a52aeec4ef721aedbdd6ac06cad}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a18de0a52aeec4ef721aedbdd6ac06cad}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!eval\+\_\+step@{eval\+\_\+step}}
\index{eval\+\_\+step@{eval\+\_\+step}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{eval\+\_\+step()}{eval\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+eval\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}[Abstract] Process one batch but do not train on it.
\end{DoxyVerb}
 

Definition at line 1854 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1854     \textcolor{keyword}{def }eval\_step(self, batch):
1855         \textcolor{stringliteral}{"""}
1856 \textcolor{stringliteral}{        [Abstract] Process one batch but do not train on it.}
1857 \textcolor{stringliteral}{        """}
1858         \textcolor{keywordflow}{pass}
1859 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0bd9118252c602bb9d5a596ecae16717}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0bd9118252c602bb9d5a596ecae16717}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!history\+\_\+class@{history\+\_\+class}}
\index{history\+\_\+class@{history\+\_\+class}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{history\+\_\+class()}{history\_class()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+history\+\_\+class (\begin{DoxyParamCaption}\item[{}]{cls }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return the history class that this agent expects to use.

Can be overriden if a more complex history is required.
\end{DoxyVerb}
 

Definition at line 378 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
378     \textcolor{keyword}{def }history\_class(cls):
379         \textcolor{stringliteral}{"""}
380 \textcolor{stringliteral}{        Return the history class that this agent expects to use.}
381 \textcolor{stringliteral}{}
382 \textcolor{stringliteral}{        Can be overriden if a more complex history is required.}
383 \textcolor{stringliteral}{        """}
384         \textcolor{keywordflow}{return} History
385 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3784f1ddaa6ffad009716910f3f36dd4}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3784f1ddaa6ffad009716910f3f36dd4}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!init\+\_\+optim@{init\+\_\+optim}}
\index{init\+\_\+optim@{init\+\_\+optim}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{init\+\_\+optim()}{init\_optim()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+init\+\_\+optim (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{params,  }\item[{}]{optim\+\_\+states = {\ttfamily None},  }\item[{}]{saved\+\_\+optim\+\_\+type = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Initialize optimizer with model parameters.

:param params:
    parameters from the model

:param optim_states:
    optional argument providing states of optimizer to load

:param saved_optim_type:
    type of optimizer being loaded, if changed will skip loading
    optimizer states
\end{DoxyVerb}
 

Definition at line 799 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
799     \textcolor{keyword}{def }init\_optim(self, params, optim\_states=None, saved\_optim\_type=None):
800         \textcolor{stringliteral}{"""}
801 \textcolor{stringliteral}{        Initialize optimizer with model parameters.}
802 \textcolor{stringliteral}{}
803 \textcolor{stringliteral}{        :param params:}
804 \textcolor{stringliteral}{            parameters from the model}
805 \textcolor{stringliteral}{}
806 \textcolor{stringliteral}{        :param optim\_states:}
807 \textcolor{stringliteral}{            optional argument providing states of optimizer to load}
808 \textcolor{stringliteral}{}
809 \textcolor{stringliteral}{        :param saved\_optim\_type:}
810 \textcolor{stringliteral}{            type of optimizer being loaded, if changed will skip loading}
811 \textcolor{stringliteral}{            optimizer states}
812 \textcolor{stringliteral}{        """}
813         opt = self.opt
814 
815         \textcolor{comment}{# set up optimizer args}
816         lr = opt[\textcolor{stringliteral}{'learningrate'}]
817         kwargs = \{\textcolor{stringliteral}{'lr'}: lr\}
818         \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'weight\_decay'}):
819             kwargs[\textcolor{stringliteral}{'weight\_decay'}] = opt[\textcolor{stringliteral}{'weight\_decay'}]
820         \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'momentum'}) > 0 \textcolor{keywordflow}{and} opt[\textcolor{stringliteral}{'optimizer'}] \textcolor{keywordflow}{in} [\textcolor{stringliteral}{'sgd'}, \textcolor{stringliteral}{'rmsprop'}, \textcolor{stringliteral}{'qhm'}]:
821             \textcolor{comment}{# turn on momentum for optimizers that use it}
822             kwargs[\textcolor{stringliteral}{'momentum'}] = opt[\textcolor{stringliteral}{'momentum'}]
823             \textcolor{keywordflow}{if} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'sgd'} \textcolor{keywordflow}{and} opt.get(\textcolor{stringliteral}{'nesterov'}, \textcolor{keyword}{True}):
824                 \textcolor{comment}{# for sgd, maybe nesterov}
825                 kwargs[\textcolor{stringliteral}{'nesterov'}] = opt.get(\textcolor{stringliteral}{'nesterov'}, \textcolor{keyword}{True})
826             \textcolor{keywordflow}{elif} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'qhm'}:
827                 \textcolor{comment}{# qhm needs a nu}
828                 kwargs[\textcolor{stringliteral}{'nu'}] = opt.get(\textcolor{stringliteral}{'nus'}, (0.7,))[0]
829         \textcolor{keywordflow}{elif} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'adam'}:
830             \textcolor{comment}{# turn on amsgrad for adam}
831             \textcolor{comment}{# amsgrad paper: https://openreview.net/forum?id=ryQu7f-RZ}
832             kwargs[\textcolor{stringliteral}{'amsgrad'}] = \textcolor{keyword}{True}
833         \textcolor{keywordflow}{elif} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'qhadam'}:
834             \textcolor{comment}{# set nus for qhadam}
835             kwargs[\textcolor{stringliteral}{'nus'}] = opt.get(\textcolor{stringliteral}{'nus'}, (0.7, 1.0))
836         \textcolor{keywordflow}{if} opt[\textcolor{stringliteral}{'optimizer'}] \textcolor{keywordflow}{in} [\textcolor{stringliteral}{'adam'}, \textcolor{stringliteral}{'sparseadam'}, \textcolor{stringliteral}{'fused\_adam'}, \textcolor{stringliteral}{'adamax'}, \textcolor{stringliteral}{'qhadam'}]:
837             \textcolor{comment}{# set betas for optims that use it}
838             kwargs[\textcolor{stringliteral}{'betas'}] = opt.get(\textcolor{stringliteral}{'betas'}, (0.9, 0.999))
839             \textcolor{comment}{# set adam optimizer, but only if user specified it}
840             \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'adam\_eps'}):
841                 kwargs[\textcolor{stringliteral}{'eps'}] = opt[\textcolor{stringliteral}{'adam\_eps'}]
842 
843         optim\_class = self.optim\_opts()[opt[\textcolor{stringliteral}{'optimizer'}]]
844         self.optimizer = optim\_class(params, **kwargs)
845         \textcolor{keywordflow}{if} self.fp16:
846             self.optimizer = \hyperlink{namespaceparlai_1_1utils_1_1torch_acd34433af9f43b196920120e6009494e}{fp16\_optimizer\_wrapper}(self.optimizer)
847 
848         \textcolor{comment}{# TODO: we might want to hard reset optimizers here in the}
849         \textcolor{comment}{# case of fine tuning. Some rudimentary experiments seemed to}
850         \textcolor{comment}{# indicate that keeping adam weights around was desirable, so this}
851         \textcolor{comment}{# will remain the behavior for the time being.}
852         \textcolor{keywordflow}{if} optim\_states \textcolor{keywordflow}{and} saved\_optim\_type != opt[\textcolor{stringliteral}{'optimizer'}]:
853             \textcolor{comment}{# we changed from adam to adamax, or sgd to adam, or similar}
854             print(\textcolor{stringliteral}{'WARNING: not loading optim state since optim class changed.'})
855         \textcolor{keywordflow}{elif} optim\_states:
856             \textcolor{comment}{# check for any fp16/fp32 conversions we need to do}
857             optimstate\_fp16 = \textcolor{stringliteral}{'loss\_scaler'} \textcolor{keywordflow}{in} optim\_states
858             \textcolor{keywordflow}{if} self.fp16 \textcolor{keywordflow}{and} optimstate\_fp16:
859                 \textcolor{comment}{# previously trained in fp16, now we're training in fp16.}
860                 \textcolor{comment}{# ideally no action needed, but APEX broke backwards}
861                 \textcolor{comment}{# compatibility and this is the hack around it.}
862                 optim\_states[\textcolor{stringliteral}{'loss\_scaler'}] = self.optimizer.state\_dict()[\textcolor{stringliteral}{'loss\_scaler'}]
863             \textcolor{keywordflow}{elif} optimstate\_fp16 \textcolor{keywordflow}{and} \textcolor{keywordflow}{not} self.fp16:
864                 \textcolor{comment}{# old optimizer was fp16 but now we're doing fp32,}
865                 \textcolor{comment}{# drop the fp16 wrapper from the state\_dict and just load}
866                 \textcolor{comment}{# the fp16 weights into the fp32 tensors}
867                 optim\_states = optim\_states[\textcolor{stringliteral}{'optimizer\_state\_dict'}]
868             \textcolor{keywordflow}{elif} \textcolor{keywordflow}{not} optimstate\_fp16 \textcolor{keywordflow}{and} self.fp16:
869                 \textcolor{comment}{# old optimizer was fp32, but now we're doing fp16.}
870                 \textcolor{comment}{# this is a bit clunky, but alternatives are worse}
871                 self.optimizer.optimizer.load\_state\_dict(optim\_states)
872                 \textcolor{keywordflow}{return}
873             \textcolor{keywordflow}{else}:
874                 \textcolor{comment}{# previously trained in fp32, loading in fp32.}
875                 \textcolor{comment}{# no special treatment needed.}
876                 \textcolor{keywordflow}{pass}
877 
878             \textcolor{comment}{# finally, try to actually load the optimizer state}
879             \textcolor{keywordflow}{try}:
880                 self.optimizer.load\_state\_dict(optim\_states)
881             \textcolor{keywordflow}{except} ValueError:
882                 print(\textcolor{stringliteral}{'WARNING: not loading optim state since model params changed.'})
883 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afa491bf2384b017711ad722b5341b405}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afa491bf2384b017711ad722b5341b405}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!is\+\_\+valid@{is\+\_\+valid}}
\index{is\+\_\+valid@{is\+\_\+valid}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{is\+\_\+valid()}{is\_valid()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+is\+\_\+valid (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{obs }\end{DoxyParamCaption})}

\begin{DoxyVerb}Determine if an observation is valid or not.
\end{DoxyVerb}
 

Definition at line 1416 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1416     \textcolor{keyword}{def }is\_valid(self, obs):
1417         \textcolor{stringliteral}{"""}
1418 \textcolor{stringliteral}{        Determine if an observation is valid or not.}
1419 \textcolor{stringliteral}{        """}
1420         \textcolor{keywordflow}{return} \textcolor{stringliteral}{'text\_vec'} \textcolor{keywordflow}{in} obs \textcolor{keywordflow}{or} \textcolor{stringliteral}{'image'} \textcolor{keywordflow}{in} obs
1421 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac345f2da892d35d9f4921e0acf5594c8}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac345f2da892d35d9f4921e0acf5594c8}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!load@{load}}
\index{load@{load}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{load()}{load()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+load (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{path }\end{DoxyParamCaption})}



Definition at line 1764 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1764     \textcolor{keyword}{def }load(self, path: str) -> Dict[str, Any]:
1765         \textcolor{stringliteral}{"""}
1766 \textcolor{stringliteral}{        Return opt and model states.}
1767 \textcolor{stringliteral}{}
1768 \textcolor{stringliteral}{        Override this method for more specific loading.}
1769 \textcolor{stringliteral}{        """}
1770         states = torch.load(path, map\_location=\textcolor{keyword}{lambda} cpu, \_: cpu)
1771         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'model'} \textcolor{keywordflow}{in} states:
1772             self.load\_state\_dict(states[\textcolor{stringliteral}{'model'}])
1773         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'optimizer'} \textcolor{keywordflow}{in} states \textcolor{keywordflow}{and} hasattr(self, \textcolor{stringliteral}{'optimizer'}):
1774             self.optimizer.load\_state\_dict(states[\textcolor{stringliteral}{'optimizer'}])
1775         \textcolor{keywordflow}{return} states
1776 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dcfca62a677f8de97f09ce993258f84}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dcfca62a677f8de97f09ce993258f84}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!load\+\_\+state\+\_\+dict@{load\+\_\+state\+\_\+dict}}
\index{load\+\_\+state\+\_\+dict@{load\+\_\+state\+\_\+dict}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{load\+\_\+state\+\_\+dict()}{load\_state\_dict()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+load\+\_\+state\+\_\+dict (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{state\+\_\+dict }\end{DoxyParamCaption})}

\begin{DoxyVerb}Load the state dict into model.

This is easily overridable to facilitate transfer of state dicts.
\end{DoxyVerb}
 

Definition at line 1756 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1756     \textcolor{keyword}{def }load\_state\_dict(self, state\_dict):
1757         \textcolor{stringliteral}{"""}
1758 \textcolor{stringliteral}{        Load the state dict into model.}
1759 \textcolor{stringliteral}{}
1760 \textcolor{stringliteral}{        This is easily overridable to facilitate transfer of state dicts.}
1761 \textcolor{stringliteral}{        """}
1762         self.model.load\_state\_dict(state\_dict)
1763 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aba56b961d929e5c5b5da9cf8bd331502}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aba56b961d929e5c5b5da9cf8bd331502}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!match\+\_\+batch@{match\+\_\+batch}}
\index{match\+\_\+batch@{match\+\_\+batch}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{match\+\_\+batch()}{match\_batch()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+match\+\_\+batch (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch\+\_\+reply,  }\item[{}]{valid\+\_\+inds,  }\item[{}]{output = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Match sub-batch of predictions to the original batch indices.

Batches may be only partially filled (i.e when completing the remainder
at the end of the validation or test set), or we may want to sort by
e.g the length of the input sequences if using pack_padded_sequence.

This matches rows back with their original row in the batch for
calculating metrics like accuracy.

If output is None (model choosing not to provide any predictions), we
will just return the batch of replies.

Otherwise, output should be a parlai.core.torch_agent.Output object.
This is a namedtuple, which can provide text predictions and/or
text_candidates predictions. If you would like to map additional
fields into the batch_reply, you can override this method as well as
providing your own namedtuple with additional fields.

:param batch_reply:
    Full-batchsize list of message dictionaries to put responses into.

:param valid_inds:
    Original indices of the predictions.

:param output:
    Output namedtuple which contains sub-batchsize list of text outputs
    from model. May be None (default) if model chooses not to answer.
    This method will check for ``text`` and ``text_candidates`` fields.
\end{DoxyVerb}
 

Definition at line 1519 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1519     \textcolor{keyword}{def }match\_batch(self, batch\_reply, valid\_inds, output=None):
1520         \textcolor{stringliteral}{"""}
1521 \textcolor{stringliteral}{        Match sub-batch of predictions to the original batch indices.}
1522 \textcolor{stringliteral}{}
1523 \textcolor{stringliteral}{        Batches may be only partially filled (i.e when completing the remainder}
1524 \textcolor{stringliteral}{        at the end of the validation or test set), or we may want to sort by}
1525 \textcolor{stringliteral}{        e.g the length of the input sequences if using pack\_padded\_sequence.}
1526 \textcolor{stringliteral}{}
1527 \textcolor{stringliteral}{        This matches rows back with their original row in the batch for}
1528 \textcolor{stringliteral}{        calculating metrics like accuracy.}
1529 \textcolor{stringliteral}{}
1530 \textcolor{stringliteral}{        If output is None (model choosing not to provide any predictions), we}
1531 \textcolor{stringliteral}{        will just return the batch of replies.}
1532 \textcolor{stringliteral}{}
1533 \textcolor{stringliteral}{        Otherwise, output should be a parlai.core.torch\_agent.Output object.}
1534 \textcolor{stringliteral}{        This is a namedtuple, which can provide text predictions and/or}
1535 \textcolor{stringliteral}{        text\_candidates predictions. If you would like to map additional}
1536 \textcolor{stringliteral}{        fields into the batch\_reply, you can override this method as well as}
1537 \textcolor{stringliteral}{        providing your own namedtuple with additional fields.}
1538 \textcolor{stringliteral}{}
1539 \textcolor{stringliteral}{        :param batch\_reply:}
1540 \textcolor{stringliteral}{            Full-batchsize list of message dictionaries to put responses into.}
1541 \textcolor{stringliteral}{}
1542 \textcolor{stringliteral}{        :param valid\_inds:}
1543 \textcolor{stringliteral}{            Original indices of the predictions.}
1544 \textcolor{stringliteral}{}
1545 \textcolor{stringliteral}{        :param output:}
1546 \textcolor{stringliteral}{            Output namedtuple which contains sub-batchsize list of text outputs}
1547 \textcolor{stringliteral}{            from model. May be None (default) if model chooses not to answer.}
1548 \textcolor{stringliteral}{            This method will check for ``text`` and ``text\_candidates`` fields.}
1549 \textcolor{stringliteral}{        """}
1550         \textcolor{keywordflow}{if} output \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1551             \textcolor{keywordflow}{return} batch\_reply
1552         \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} output.items():
1553             \textcolor{keywordflow}{if} v \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1554                 \textcolor{keywordflow}{continue}
1555             \textcolor{keywordflow}{for} i, sub\_val \textcolor{keywordflow}{in} zip(valid\_inds, v):
1556                 batch\_reply[i][k] = sub\_val
1557         \textcolor{keywordflow}{return} batch\_reply
1558 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a87b18f0d6ab11be3c49375af072d0d33}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a87b18f0d6ab11be3c49375af072d0d33}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!observe@{observe}}
\index{observe@{observe}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{observe()}{observe()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+observe (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{observation }\end{DoxyParamCaption})}

\begin{DoxyVerb}Process incoming message in preparation for producing a response.

This includes remembering the past history of the conversation.
\end{DoxyVerb}
 

Definition at line 1559 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1559     \textcolor{keyword}{def }observe(self, observation):
1560         \textcolor{stringliteral}{"""}
1561 \textcolor{stringliteral}{        Process incoming message in preparation for producing a response.}
1562 \textcolor{stringliteral}{}
1563 \textcolor{stringliteral}{        This includes remembering the past history of the conversation.}
1564 \textcolor{stringliteral}{        """}
1565         \textcolor{comment}{# TODO: Migration plan: TorchAgent currently supports being passed}
1566         \textcolor{comment}{# observations as vanilla dicts for legacy interop; eventually we}
1567         \textcolor{comment}{# want to remove this behavior and demand that teachers return Messages}
1568         observation = Message(observation)
1569 
1570         \textcolor{comment}{# Sanity check everything is in order}
1571         self.\_validate\_observe\_invariants()
1572 
1573         \textcolor{keywordflow}{if} observation.get(\textcolor{stringliteral}{'episode\_done'}):
1574             self.\_\_expecting\_clear\_history = \textcolor{keyword}{True}
1575         \textcolor{keywordflow}{elif} \textcolor{stringliteral}{'labels'} \textcolor{keywordflow}{in} observation \textcolor{keywordflow}{or} \textcolor{stringliteral}{'eval\_labels'} \textcolor{keywordflow}{in} observation:
1576             \textcolor{comment}{# make sure we note that we're expecting a reply in the future}
1577             self.\_\_expecting\_to\_reply = \textcolor{keyword}{True}
1578 
1579         self.observation = observation
1580         \textcolor{comment}{# update the history using the observation}
1581         self.history.update\_history(observation)
1582         \textcolor{keywordflow}{return} self.vectorize(
1583             observation,
1584             self.history,
1585             text\_truncate=self.text\_truncate,
1586             label\_truncate=self.label\_truncate,
1587         )
1588 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9c622b8ed5a811841f30fe98cc297cde}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9c622b8ed5a811841f30fe98cc297cde}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!optim\+\_\+opts@{optim\+\_\+opts}}
\index{optim\+\_\+opts@{optim\+\_\+opts}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{optim\+\_\+opts()}{optim\_opts()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+optim\+\_\+opts (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Fetch optimizer selection.

By default, collects everything in torch.optim, as well as importing:
- qhm / qhmadam if installed from github.com/facebookresearch/qhoptim

Override this (and probably call super()) to add your own optimizers.
\end{DoxyVerb}
 

Definition at line 334 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
334     \textcolor{keyword}{def }optim\_opts(self):
335         \textcolor{stringliteral}{"""}
336 \textcolor{stringliteral}{        Fetch optimizer selection.}
337 \textcolor{stringliteral}{}
338 \textcolor{stringliteral}{        By default, collects everything in torch.optim, as well as importing:}
339 \textcolor{stringliteral}{        - qhm / qhmadam if installed from github.com/facebookresearch/qhoptim}
340 \textcolor{stringliteral}{}
341 \textcolor{stringliteral}{        Override this (and probably call super()) to add your own optimizers.}
342 \textcolor{stringliteral}{        """}
343         \textcolor{comment}{# first pull torch.optim in}
344         optims = \{
345             k.lower(): v
346             \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} optim.\_\_dict\_\_.items()
347             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} k.startswith(\textcolor{stringliteral}{'\_\_'}) \textcolor{keywordflow}{and} k[0].isupper()
348         \}
349         \textcolor{keywordflow}{try}:
350             \textcolor{keyword}{import} apex.optimizers.fused\_adam \textcolor{keyword}{as} fused\_adam
351 
352             optims[\textcolor{stringliteral}{'fused\_adam'}] = fused\_adam.FusedAdam
353         \textcolor{keywordflow}{except} ImportError:
354             \textcolor{keywordflow}{pass}
355 
356         \textcolor{keywordflow}{try}:
357             \textcolor{comment}{# https://openreview.net/pdf?id=S1fUpoR5FQ}
358             \textcolor{keyword}{from} qhoptim.pyt \textcolor{keyword}{import} QHM, QHAdam
359 
360             optims[\textcolor{stringliteral}{'qhm'}] = QHM
361             optims[\textcolor{stringliteral}{'qhadam'}] = QHAdam
362         \textcolor{keywordflow}{except} ImportError:
363             \textcolor{comment}{# no QHM installed}
364             \textcolor{keywordflow}{pass}
365 
366         \textcolor{keywordflow}{return} optims
367 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a02beaaedfa30463f9d0a97ea590b516f}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a02beaaedfa30463f9d0a97ea590b516f}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!receive\+\_\+metrics@{receive\+\_\+metrics}}
\index{receive\+\_\+metrics@{receive\+\_\+metrics}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{receive\+\_\+metrics()}{receive\_metrics()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+receive\+\_\+metrics (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{metrics\+\_\+dict }\end{DoxyParamCaption})}

\begin{DoxyVerb}Use the metrics to decide when to adjust LR schedule.

This uses the loss as the validation metric if present, if not this
function does nothing. Note that the model must be reporting loss for
this to work.

Override this to override the behavior.
\end{DoxyVerb}
 

Definition at line 1044 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1044     \textcolor{keyword}{def }receive\_metrics(self, metrics\_dict):
1045         \textcolor{stringliteral}{"""}
1046 \textcolor{stringliteral}{        Use the metrics to decide when to adjust LR schedule.}
1047 \textcolor{stringliteral}{}
1048 \textcolor{stringliteral}{        This uses the loss as the validation metric if present, if not this}
1049 \textcolor{stringliteral}{        function does nothing. Note that the model must be reporting loss for}
1050 \textcolor{stringliteral}{        this to work.}
1051 \textcolor{stringliteral}{}
1052 \textcolor{stringliteral}{        Override this to override the behavior.}
1053 \textcolor{stringliteral}{        """}
1054         \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} hasattr(self, \textcolor{stringliteral}{'scheduler'}) \textcolor{keywordflow}{or} self.scheduler \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1055             \textcolor{keywordflow}{return}
1056 
1057         \textcolor{keywordflow}{if} self.\_is\_lr\_warming\_up():
1058             \textcolor{comment}{# we're not done warming up, so don't start using validation}
1059             \textcolor{comment}{# metrics to adjust schedule}
1060             \textcolor{keywordflow}{return}
1061 
1062         \textcolor{keywordflow}{if} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'none'}:
1063             \textcolor{comment}{# no scheduler, nothing to adjust here}
1064             \textcolor{keywordflow}{pass}
1065         \textcolor{keywordflow}{elif} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'reduceonplateau'}:
1066             \textcolor{keywordflow}{if} \textcolor{stringliteral}{'loss'} \textcolor{keywordflow}{not} \textcolor{keywordflow}{in} metrics\_dict:
1067                 \textcolor{comment}{# nothing to step on, just skip}
1068                 \hyperlink{namespaceparlai_1_1utils_1_1misc_a884a3aefa90581f53bc592fa6a78dc43}{warn\_once}(\textcolor{stringliteral}{"LR scheduler expected to see loss metric, but didn't."})
1069                 \textcolor{keywordflow}{return}
1070             self.scheduler.step(metrics\_dict[\textcolor{stringliteral}{'loss'}])
1071         \textcolor{keywordflow}{elif} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'fixed'}:
1072             self.scheduler.step()
1073         \textcolor{keywordflow}{elif} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'invsqrt'}:
1074             \textcolor{comment}{# this is a training step lr scheduler, nothing to adjust in validation}
1075             \textcolor{keywordflow}{pass}
1076         \textcolor{keywordflow}{else}:
1077             \textcolor{keywordflow}{raise} ValueError(
1078                 \textcolor{stringliteral}{"Don't know how to work with lr scheduler '\{\}'"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(
1079                     self.opt[\textcolor{stringliteral}{'lr\_scheduler'}]
1080                 )
1081             )
1082 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac694770cd4022eb047bf6fbb8f46035c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac694770cd4022eb047bf6fbb8f46035c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!report@{report}}
\index{report@{report}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{report()}{report()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+report (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Report metrics.

Report includes learning rate and number of training updates.
\end{DoxyVerb}
 

Definition at line 984 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
984     \textcolor{keyword}{def }\hyperlink{namespaceprojects_1_1convai2_1_1eval__f1_a01a47b9c08dad189837a51f085defc45}{report}(self):
985         \textcolor{stringliteral}{"""}
986 \textcolor{stringliteral}{        Report metrics.}
987 \textcolor{stringliteral}{}
988 \textcolor{stringliteral}{        Report includes learning rate and number of training updates.}
989 \textcolor{stringliteral}{        """}
990         metrics = \{\}
991         \textcolor{comment}{# only report LR if we have a scheduler}
992         \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'scheduler'}) \textcolor{keywordflow}{and} self.scheduler \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
993             current\_lr = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.optimizer.param\_groups[0][\textcolor{stringliteral}{'lr'}], 4)
994             metrics[\textcolor{stringliteral}{'lr'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(current\_lr, 4)
995         metrics[\textcolor{stringliteral}{'total\_train\_updates'}] = self.\_number\_training\_updates
996 
997         steps = self.metrics[\textcolor{stringliteral}{'updates'}]
998         \textcolor{keywordflow}{if} steps > 0 \textcolor{keywordflow}{and} self.opt.get(\textcolor{stringliteral}{'gradient\_clip'}, -1) > 0:
999             metrics[\textcolor{stringliteral}{'gnorm'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.metrics[\textcolor{stringliteral}{'gnorm'}] / steps, 4)
1000             metrics[\textcolor{stringliteral}{'clip'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.metrics[\textcolor{stringliteral}{'clip'}] / steps, 2)
1001 
1002         \textcolor{keywordflow}{if} self.use\_cuda:
1003             metrics[\textcolor{stringliteral}{'gpu\_mem\_percent'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.\_gpu\_usage(), sigfigs=3)
1004 
1005         \textcolor{keywordflow}{return} metrics
1006 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6f568650dd8e245a274671680ebb7587}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6f568650dd8e245a274671680ebb7587}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!reset@{reset}}
\index{reset@{reset}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{reset()}{reset()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+reset (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Clear internal states.
\end{DoxyVerb}
 

Definition at line 1777 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1777     \textcolor{keyword}{def }reset(self):
1778         \textcolor{stringliteral}{"""}
1779 \textcolor{stringliteral}{        Clear internal states.}
1780 \textcolor{stringliteral}{        """}
1781         \textcolor{comment}{# assumption violation trackers}
1782         self.\_\_expecting\_clear\_history = \textcolor{keyword}{False}
1783         self.\_\_expecting\_to\_reply = \textcolor{keyword}{False}
1784 
1785         self.observation = \textcolor{keywordtype}{None}
1786         self.history.reset()
1787         self.reset\_metrics()
1788 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a03e18955cfd44dd019d0847bc7a46893}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a03e18955cfd44dd019d0847bc7a46893}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!reset\+\_\+metrics@{reset\+\_\+metrics}}
\index{reset\+\_\+metrics@{reset\+\_\+metrics}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{reset\+\_\+metrics()}{reset\_metrics()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+reset\+\_\+metrics (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reset all TorchAgentMetrics.
\end{DoxyVerb}
 

Definition at line 1789 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1789     \textcolor{keyword}{def }reset\_metrics(self):
1790         \textcolor{stringliteral}{"""}
1791 \textcolor{stringliteral}{        Reset all TorchAgentMetrics.}
1792 \textcolor{stringliteral}{        """}
1793         super().reset\_metrics()
1794         self.metrics[\textcolor{stringliteral}{'gnorm'}] = 0.0
1795         self.metrics[\textcolor{stringliteral}{'clip'}] = 0.0
1796         self.metrics[\textcolor{stringliteral}{'updates'}] = 0
1797 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adac7ee3db855786e8414e9f35fcb6e46}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adac7ee3db855786e8414e9f35fcb6e46}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!save@{save}}
\index{save@{save}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{save()}{save()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+save (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{path = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Save model parameters to path (or default to model_file arg).

Please try to refrain from overriding this function, and instead override
`state_dict(self)` for more specific saving.
\end{DoxyVerb}
 

Definition at line 1722 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1722     \textcolor{keyword}{def }save(self, path=None):
1723         \textcolor{stringliteral}{"""}
1724 \textcolor{stringliteral}{        Save model parameters to path (or default to model\_file arg).}
1725 \textcolor{stringliteral}{}
1726 \textcolor{stringliteral}{        Please try to refrain from overriding this function, and instead override}
1727 \textcolor{stringliteral}{        `state\_dict(self)` for more specific saving.}
1728 \textcolor{stringliteral}{        """}
1729         path = self.opt.get(\textcolor{stringliteral}{'model\_file'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{if} path \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} path
1730 
1731         \textcolor{keywordflow}{if} path:
1732             model\_dict\_path = path + \textcolor{stringliteral}{'.dict'}
1733             \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'dict'}) \textcolor{keywordflow}{and} \textcolor{keywordflow}{not} os.path.exists(
1734                 model\_dict\_path
1735             ):  \textcolor{comment}{# force save dictionary}
1736                 \textcolor{comment}{# TODO: Look into possibly overriding opt('dict\_file') with new path}
1737                 self.dict.save(model\_dict\_path, sort=\textcolor{keyword}{False})
1738             states = self.state\_dict()
1739             \textcolor{keywordflow}{if} states:  \textcolor{comment}{# anything found to save?}
1740                 with open(path, \textcolor{stringliteral}{'wb'}) \textcolor{keyword}{as} write:
1741                     torch.save(states, write)
1742 
1743                 \textcolor{comment}{# save opt file}
1744                 with open(path + \textcolor{stringliteral}{'.opt'}, \textcolor{stringliteral}{'w'}, encoding=\textcolor{stringliteral}{'utf-8'}) \textcolor{keyword}{as} handle:
1745                     \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'model\_version'}):
1746                         self.opt[\textcolor{stringliteral}{'model\_version'}] = self.model\_version()
1747                     saved\_opts = deepcopy(self.opt)
1748                     \textcolor{keywordflow}{if} \textcolor{stringliteral}{'interactive\_mode'} \textcolor{keywordflow}{in} saved\_opts:
1749                         \textcolor{comment}{# We do not save the state of interactive mode, it is only decided}
1750                         \textcolor{comment}{# by scripts or command line.}
1751                         del saved\_opts[\textcolor{stringliteral}{'interactive\_mode'}]
1752                     json.dump(saved\_opts, handle, indent=4)
1753                     \textcolor{comment}{# for convenience of working with jq, make sure there's a newline}
1754                     handle.write(\textcolor{stringliteral}{'\(\backslash\)n'})
1755 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a663cb0d6a276495d03aacdb8b9c79fb0}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a663cb0d6a276495d03aacdb8b9c79fb0}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!self\+\_\+observe@{self\+\_\+observe}}
\index{self\+\_\+observe@{self\+\_\+observe}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{self\+\_\+observe()}{self\_observe()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+self\+\_\+observe (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{self\+\_\+message }\end{DoxyParamCaption})}



Definition at line 1589 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1589     \textcolor{keyword}{def }self\_observe(self, self\_message: Message) -> \textcolor{keywordtype}{None}:
1590         \textcolor{stringliteral}{"""}
1591 \textcolor{stringliteral}{        Observe one's own utterance.}
1592 \textcolor{stringliteral}{}
1593 \textcolor{stringliteral}{        This is used so that the agent can incorporate its own response into}
1594 \textcolor{stringliteral}{        the dialogue history after a batch\_act. Failure to implement this will}
1595 \textcolor{stringliteral}{        result in an agent that cannot hear itself speak.}
1596 \textcolor{stringliteral}{}
1597 \textcolor{stringliteral}{        :param self\_message:}
1598 \textcolor{stringliteral}{            The message corresponding to the output from batch\_act.}
1599 \textcolor{stringliteral}{        """}
1600         use\_reply = self.opt.get(\textcolor{stringliteral}{'use\_reply'}, \textcolor{stringliteral}{'label'})
1601 
1602         \textcolor{comment}{# quick check everything is in order}
1603         self.\_validate\_self\_observe\_invariants()
1604 
1605         \textcolor{keyword}{assert} self.observation \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}
1606         \textcolor{keywordflow}{if} self.observation[\textcolor{stringliteral}{'episode\_done'}]:
1607             \textcolor{comment}{# oh this was the last example in the episode. reset the history}
1608             self.history.reset()
1609             \textcolor{comment}{# additionally mark the last observation as invalid}
1610             self.observation = \textcolor{keywordtype}{None}
1611             \textcolor{comment}{# and clear the safety check}
1612             self.\_\_expecting\_clear\_history = \textcolor{keyword}{False}
1613             \textcolor{keywordflow}{return}
1614 
1615         \textcolor{comment}{# We did reply! Safety check is good next round.}
1616         self.\_\_expecting\_to\_reply = \textcolor{keyword}{False}
1617 
1618         \textcolor{comment}{# actually ingest the label}
1619         \textcolor{keywordflow}{if} use\_reply == \textcolor{stringliteral}{'none'}:
1620             \textcolor{comment}{# we're not including our own responses anyway.}
1621             \textcolor{keywordflow}{return}
1622         \textcolor{keywordflow}{elif} use\_reply == \textcolor{stringliteral}{'label'}:
1623             \textcolor{comment}{# first look for the true label}
1624             label\_key = (
1625                 \textcolor{stringliteral}{'labels'}
1626                 \textcolor{keywordflow}{if} \textcolor{stringliteral}{'labels'} \textcolor{keywordflow}{in} self.observation
1627                 \textcolor{keywordflow}{else} \textcolor{stringliteral}{'eval\_labels'}
1628                 \textcolor{keywordflow}{if} \textcolor{stringliteral}{'eval\_labels'} \textcolor{keywordflow}{in} self.observation
1629                 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
1630             )
1631             \textcolor{keywordflow}{if} label\_key \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
1632                 lbls = self.observation[label\_key]
1633                 last\_reply = lbls[0] \textcolor{keywordflow}{if} len(lbls) == 1 \textcolor{keywordflow}{else} self.random.choice(lbls)
1634                 self.history.add\_reply(last\_reply)
1635                 \textcolor{keywordflow}{return}
1636             \textcolor{comment}{# you might expect a hard failure here, but in interactive mode we'll}
1637             \textcolor{comment}{# never get a label}
1638 
1639         \textcolor{comment}{# otherwise, we use the last output the model generated}
1640         \textcolor{keywordflow}{if} self\_message \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
1641             last\_reply = self\_message[\textcolor{stringliteral}{'text'}]
1642             self.history.add\_reply(last\_reply)
1643             \textcolor{keywordflow}{return}
1644 
1645         \textcolor{keywordflow}{raise} RuntimeError(\textcolor{stringliteral}{"Unexpected case in self\_observe."})
1646 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6a7aff29231816a0f3cade9c72409dfc}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6a7aff29231816a0f3cade9c72409dfc}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}}
\index{set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{set\+\_\+interactive\+\_\+mode()}{set\_interactive\_mode()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+set\+\_\+interactive\+\_\+mode (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{mode,  }\item[{}]{shared }\end{DoxyParamCaption})}

\begin{DoxyVerb}Set interactive mode on or off.
\end{DoxyVerb}
 

Definition at line 1860 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1860     \textcolor{keyword}{def }set\_interactive\_mode(self, mode, shared):
1861         \textcolor{stringliteral}{"""}
1862 \textcolor{stringliteral}{        Set interactive mode on or off.}
1863 \textcolor{stringliteral}{        """}
1864         \textcolor{keywordflow}{if} shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{and} mode:
1865             \textcolor{comment}{# Only print in the non-shared version.}
1866             print(\textcolor{stringliteral}{"["} + self.id + \textcolor{stringliteral}{': full interactive mode on.'} + \textcolor{stringliteral}{']'})
1867 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a373f0e276bf7c9d914a4e3363e9c2712}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a373f0e276bf7c9d914a4e3363e9c2712}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!share@{share}}
\index{share@{share}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{share()}{share()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+share (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Share fields from parent as well as useful objects in this class.

Subclasses will likely want to share their model as well.
\end{DoxyVerb}
 

Definition at line 1188 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1188     \textcolor{keyword}{def }share(self):
1189         \textcolor{stringliteral}{"""}
1190 \textcolor{stringliteral}{        Share fields from parent as well as useful objects in this class.}
1191 \textcolor{stringliteral}{}
1192 \textcolor{stringliteral}{        Subclasses will likely want to share their model as well.}
1193 \textcolor{stringliteral}{        """}
1194         shared = super().share()
1195 
1196         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1 \textcolor{keywordflow}{and} isinstance(self.metrics, dict):
1197             \textcolor{comment}{# move metrics and model to shared memory}
1198             self.metrics = SharedTable(self.metrics)
1199             self.model.share\_memory()
1200         shared[\textcolor{stringliteral}{'metrics'}] = self.metrics
1201 
1202         shared[\textcolor{stringliteral}{'dict'}] = self.dict
1203         shared[\textcolor{stringliteral}{'model'}] = self.model
1204         shared[\textcolor{stringliteral}{'criterion'}] = self.criterion
1205         shared[\textcolor{stringliteral}{'opt'}] = self.opt
1206         \textcolor{keywordflow}{return} shared
1207 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!state\+\_\+dict@{state\+\_\+dict}}
\index{state\+\_\+dict@{state\+\_\+dict}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{state\+\_\+dict()}{state\_dict()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+state\+\_\+dict (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Get the state dict for saving.

Override this method for more specific saving.
\end{DoxyVerb}
 

Definition at line 1688 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1688     \textcolor{keyword}{def }state\_dict(self):
1689         \textcolor{stringliteral}{"""}
1690 \textcolor{stringliteral}{        Get the state dict for saving.}
1691 \textcolor{stringliteral}{}
1692 \textcolor{stringliteral}{        Override this method for more specific saving.}
1693 \textcolor{stringliteral}{        """}
1694         states = \{\}
1695         \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'model'}):  \textcolor{comment}{# save model params}
1696             \textcolor{keywordflow}{if} hasattr(self.model, \textcolor{stringliteral}{'module'}):
1697                 \textcolor{comment}{# did we wrap in a DistributedDataParallel}
1698                 states[\textcolor{stringliteral}{'model'}] = self.model.module.state\_dict()
1699             \textcolor{keywordflow}{else}:
1700                 states[\textcolor{stringliteral}{'model'}] = self.model.state\_dict()
1701 
1702         \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'optimizer'}):
1703             \textcolor{comment}{# save optimizer params}
1704             states[\textcolor{stringliteral}{'optimizer'}] = self.optimizer.state\_dict()
1705             states[\textcolor{stringliteral}{'optimizer\_type'}] = self.opt[\textcolor{stringliteral}{'optimizer'}]
1706 
1707         \textcolor{comment}{# lr scheduler}
1708         \textcolor{keywordflow}{if} torch.\_\_version\_\_.startswith(\textcolor{stringliteral}{'0.'}):
1709             \hyperlink{namespaceparlai_1_1utils_1_1misc_a884a3aefa90581f53bc592fa6a78dc43}{warn\_once}(
1710                 \textcolor{stringliteral}{"Must upgrade to Pytorch 1.0 to save the state of your "} \textcolor{stringliteral}{"LR scheduler."}
1711             )
1712         \textcolor{keywordflow}{else}:
1713             states[\textcolor{stringliteral}{'number\_training\_updates'}] = self.\_number\_training\_updates
1714             \textcolor{keywordflow}{if} getattr(self, \textcolor{stringliteral}{'scheduler'}, \textcolor{keywordtype}{None}):
1715                 states[\textcolor{stringliteral}{'lr\_scheduler'}] = self.scheduler.state\_dict()
1716                 states[\textcolor{stringliteral}{'lr\_scheduler\_type'}] = self.opt[\textcolor{stringliteral}{'lr\_scheduler'}]
1717             \textcolor{keywordflow}{if} getattr(self, \textcolor{stringliteral}{'warmup\_scheduler'}, \textcolor{keywordtype}{None}):
1718                 states[\textcolor{stringliteral}{'warmup\_scheduler'}] = self.warmup\_scheduler.state\_dict()
1719 
1720         \textcolor{keywordflow}{return} states
1721 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8ba9d535736c0af100d00c5e7b02b61b}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8ba9d535736c0af100d00c5e7b02b61b}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!train\+\_\+step@{train\+\_\+step}}
\index{train\+\_\+step@{train\+\_\+step}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{train\+\_\+step()}{train\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+train\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}[Abstract] Process one batch with training labels.
\end{DoxyVerb}
 

Definition at line 1847 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1847     \textcolor{keyword}{def }train\_step(self, batch):
1848         \textcolor{stringliteral}{"""}
1849 \textcolor{stringliteral}{        [Abstract] Process one batch with training labels.}
1850 \textcolor{stringliteral}{        """}
1851         \textcolor{keywordflow}{pass}
1852 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7e2c9e180887397daa6229a0f9700b1c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7e2c9e180887397daa6229a0f9700b1c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!update\+\_\+params@{update\+\_\+params}}
\index{update\+\_\+params@{update\+\_\+params}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{update\+\_\+params()}{update\_params()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+update\+\_\+params (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Perform step of optimization.

Handles clipping gradients and adjusting LR schedule if needed.
Gradient accumulation is also performed if agent is called with
--update-freq.

It is recommended (but not forced) that you call this in train_step.
\end{DoxyVerb}
 

Definition at line 1884 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1884     \textcolor{keyword}{def }update\_params(self):
1885         \textcolor{stringliteral}{"""}
1886 \textcolor{stringliteral}{        Perform step of optimization.}
1887 \textcolor{stringliteral}{}
1888 \textcolor{stringliteral}{        Handles clipping gradients and adjusting LR schedule if needed.}
1889 \textcolor{stringliteral}{        Gradient accumulation is also performed if agent is called with}
1890 \textcolor{stringliteral}{        --update-freq.}
1891 \textcolor{stringliteral}{}
1892 \textcolor{stringliteral}{        It is recommended (but not forced) that you call this in train\_step.}
1893 \textcolor{stringliteral}{        """}
1894         update\_freq = self.opt.get(\textcolor{stringliteral}{'update\_freq'}, 1)
1895         \textcolor{keywordflow}{if} update\_freq > 1:
1896             \textcolor{comment}{# we're doing gradient accumulation, so we don't only want to step}
1897             \textcolor{comment}{# every N updates instead}
1898             self.\_number\_grad\_accum = (self.\_number\_grad\_accum + 1) % update\_freq
1899             \textcolor{keywordflow}{if} self.\_number\_grad\_accum != 0:
1900                 \textcolor{keywordflow}{return}
1901 
1902         \textcolor{keywordflow}{if} self.fp16:
1903             \textcolor{comment}{# we've been accumulating grads in fp16 and delaying the fp32 copy update.}
1904             \textcolor{comment}{# finally time to perform the update.}
1905             self.optimizer.update\_master\_grads()
1906 
1907         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'gradient\_clip'}, -1) > 0:
1908             \textcolor{keywordflow}{if} self.fp16:
1909                 grad\_norm = self.optimizer.clip\_master\_grads(self.opt[\textcolor{stringliteral}{'gradient\_clip'}])
1910             \textcolor{keywordflow}{else}:
1911                 grad\_norm = torch.nn.utils.clip\_grad\_norm\_(
1912                     self.model.parameters(), self.opt[\textcolor{stringliteral}{'gradient\_clip'}]
1913                 )
1914             self.metrics[\textcolor{stringliteral}{'gnorm'}] += grad\_norm
1915             self.metrics[\textcolor{stringliteral}{'clip'}] += \hyperlink{namespaceprojects_1_1controllable__dialogue_1_1make__control__dataset_aa2b7207688c641dbc094ab44eca27113}{float}(grad\_norm > self.opt[\textcolor{stringliteral}{'gradient\_clip'}])
1916 
1917         self.metrics[\textcolor{stringliteral}{'updates'}] += 1
1918         self.optimizer.step()
1919 
1920         \textcolor{comment}{# keep track up number of steps, compute warmup factor}
1921         self.\_number\_training\_updates += 1
1922 
1923         \textcolor{comment}{# compute warmup adjustment if needed}
1924         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'warmup\_updates'}, -1) > 0:
1925             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} hasattr(self, \textcolor{stringliteral}{'warmup\_scheduler'}):
1926                 \textcolor{keywordflow}{raise} RuntimeError(\textcolor{stringliteral}{'Looks like you forgot to call build\_lr\_scheduler'})
1927             \textcolor{keywordflow}{if} self.\_is\_lr\_warming\_up():
1928                 self.warmup\_scheduler.step(epoch=self.\_number\_training\_updates)
1929 
1930         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'invsqrt'} \textcolor{keywordflow}{and} \textcolor{keywordflow}{not} self.\_is\_lr\_warming\_up():
1931             \textcolor{comment}{# training step scheduler}
1932             self.scheduler.step(self.\_number\_training\_updates)
1933 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a48bb9b153353a0565ab7253dc1daef99}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a48bb9b153353a0565ab7253dc1daef99}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!vectorize@{vectorize}}
\index{vectorize@{vectorize}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{vectorize()}{vectorize()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+vectorize (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{obs,  }\item[{}]{history,  }\item[{}]{add\+\_\+start = {\ttfamily True},  }\item[{}]{add\+\_\+end = {\ttfamily True},  }\item[{}]{text\+\_\+truncate = {\ttfamily None},  }\item[{}]{label\+\_\+truncate = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Make vectors out of observation fields and store in the observation.

In particular, the 'text' and 'labels'/'eval_labels' fields are
processed and a new field is added to the observation with the suffix
'_vec'.

If you want to use additional fields on your subclass, you can override
this function, call super().vectorize(...) to process the text and
labels, and then process the other fields in your subclass.

Additionally, if you want to override some of these default parameters,
then we recommend using a pattern like:

.. code-block:: python

  def vectorize(self, *args, **kwargs):
      kwargs['add_start'] = False
      return super().vectorize(*args, **kwargs)


:param obs:
    Single observation from observe function.

:param add_start:
    default True, adds the start token to each label.

:param add_end:
    default True, adds the end token to each label.

:param text_truncate:
    default None, if set truncates text vectors to the specified
    length.

:param label_truncate:
    default None, if set truncates label vectors to the specified
    length.

:return:
    the input observation, with 'text_vec', 'label_vec', and
    'cands_vec' fields added.
\end{DoxyVerb}
 

Definition at line 1368 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1368     ):
1369         \textcolor{stringliteral}{"""}
1370 \textcolor{stringliteral}{        Make vectors out of observation fields and store in the observation.}
1371 \textcolor{stringliteral}{}
1372 \textcolor{stringliteral}{        In particular, the 'text' and 'labels'/'eval\_labels' fields are}
1373 \textcolor{stringliteral}{        processed and a new field is added to the observation with the suffix}
1374 \textcolor{stringliteral}{        '\_vec'.}
1375 \textcolor{stringliteral}{}
1376 \textcolor{stringliteral}{        If you want to use additional fields on your subclass, you can override}
1377 \textcolor{stringliteral}{        this function, call super().vectorize(...) to process the text and}
1378 \textcolor{stringliteral}{        labels, and then process the other fields in your subclass.}
1379 \textcolor{stringliteral}{}
1380 \textcolor{stringliteral}{        Additionally, if you want to override some of these default parameters,}
1381 \textcolor{stringliteral}{        then we recommend using a pattern like:}
1382 \textcolor{stringliteral}{}
1383 \textcolor{stringliteral}{        .. code-block:: python}
1384 \textcolor{stringliteral}{}
1385 \textcolor{stringliteral}{          def vectorize(self, *args, **kwargs):}
1386 \textcolor{stringliteral}{              kwargs['add\_start'] = False}
1387 \textcolor{stringliteral}{              return super().vectorize(*args, **kwargs)}
1388 \textcolor{stringliteral}{}
1389 \textcolor{stringliteral}{}
1390 \textcolor{stringliteral}{        :param obs:}
1391 \textcolor{stringliteral}{            Single observation from observe function.}
1392 \textcolor{stringliteral}{}
1393 \textcolor{stringliteral}{        :param add\_start:}
1394 \textcolor{stringliteral}{            default True, adds the start token to each label.}
1395 \textcolor{stringliteral}{}
1396 \textcolor{stringliteral}{        :param add\_end:}
1397 \textcolor{stringliteral}{            default True, adds the end token to each label.}
1398 \textcolor{stringliteral}{}
1399 \textcolor{stringliteral}{        :param text\_truncate:}
1400 \textcolor{stringliteral}{            default None, if set truncates text vectors to the specified}
1401 \textcolor{stringliteral}{            length.}
1402 \textcolor{stringliteral}{}
1403 \textcolor{stringliteral}{        :param label\_truncate:}
1404 \textcolor{stringliteral}{            default None, if set truncates label vectors to the specified}
1405 \textcolor{stringliteral}{            length.}
1406 \textcolor{stringliteral}{}
1407 \textcolor{stringliteral}{        :return:}
1408 \textcolor{stringliteral}{            the input observation, with 'text\_vec', 'label\_vec', and}
1409 \textcolor{stringliteral}{            'cands\_vec' fields added.}
1410 \textcolor{stringliteral}{        """}
1411         self.\_set\_text\_vec(obs, history, text\_truncate)
1412         self.\_set\_label\_vec(obs, add\_start, add\_end, label\_truncate)
1413         self.\_set\_label\_cands\_vec(obs, add\_start, add\_end, label\_truncate)
1414         \textcolor{keywordflow}{return} obs
1415 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a91c163f3e2d39b380095b7083f673b6e}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a91c163f3e2d39b380095b7083f673b6e}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!zero\+\_\+grad@{zero\+\_\+grad}}
\index{zero\+\_\+grad@{zero\+\_\+grad}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{zero\+\_\+grad()}{zero\_grad()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+zero\+\_\+grad (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Zero out optimizer.

It is recommended you call this in train_step. It automatically handles gradient
accumulation if agent is called with --update-freq.
\end{DoxyVerb}
 

Definition at line 1934 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1934     \textcolor{keyword}{def }zero\_grad(self):
1935         \textcolor{stringliteral}{"""}
1936 \textcolor{stringliteral}{        Zero out optimizer.}
1937 \textcolor{stringliteral}{}
1938 \textcolor{stringliteral}{        It is recommended you call this in train\_step. It automatically handles gradient}
1939 \textcolor{stringliteral}{        accumulation if agent is called with --update-freq.}
1940 \textcolor{stringliteral}{        """}
1941         \textcolor{keywordflow}{if} self.\_number\_grad\_accum != 0:
1942             \textcolor{comment}{# if we're accumulating gradients, don't actually zero things out yet.}
1943             \textcolor{keywordflow}{return}
1944 
1945         self.optimizer.zero\_grad()
1946 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a63011fa9bd927de8acc9ffa676caa73a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a63011fa9bd927de8acc9ffa676caa73a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!add\+\_\+person\+\_\+tokens@{add\+\_\+person\+\_\+tokens}}
\index{add\+\_\+person\+\_\+tokens@{add\+\_\+person\+\_\+tokens}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{add\+\_\+person\+\_\+tokens}{add\_person\_tokens}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+add\+\_\+person\+\_\+tokens}



Definition at line 724 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a13d46ae8aed6052679b62c3961a4de62}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a13d46ae8aed6052679b62c3961a4de62}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!criterion@{criterion}}
\index{criterion@{criterion}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{criterion}{criterion}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+criterion}



Definition at line 690 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_abebf29c0bb956bbc5ccc02777d2af3dd}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_abebf29c0bb956bbc5ccc02777d2af3dd}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!dict@{dict}}
\index{dict@{dict}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{dict}{dict}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+dict}



Definition at line 667 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3a80083f0e34d8abc15b50123efec884}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3a80083f0e34d8abc15b50123efec884}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!E\+M\+P\+TY@{E\+M\+P\+TY}}
\index{E\+M\+P\+TY@{E\+M\+P\+TY}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{E\+M\+P\+TY}{EMPTY}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+E\+M\+P\+TY}



Definition at line 700 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a31bb7c8bf380660ee4e3822756563599}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a31bb7c8bf380660ee4e3822756563599}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}}
\index{E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{E\+N\+D\+\_\+\+I\+DX}{END\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+E\+N\+D\+\_\+\+I\+DX}



Definition at line 703 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa6f916e01d876679b529a893ad4f52f6}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa6f916e01d876679b529a893ad4f52f6}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!fp16@{fp16}}
\index{fp16@{fp16}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{fp16}{fp16}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+fp16}



Definition at line 663 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!history@{history}}
\index{history@{history}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{history}{history}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+history}



Definition at line 720 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a15cbb1f743c1d341d914ade47e49071b}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a15cbb1f743c1d341d914ade47e49071b}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!histsz@{histsz}}
\index{histsz@{histsz}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{histsz}{histsz}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+histsz}



Definition at line 712 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4ac66a09c1c164ea08f4b257c61c38a0}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4ac66a09c1c164ea08f4b257c61c38a0}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!id@{id}}
\index{id@{id}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{id}{id}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+id}



Definition at line 697 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab0bd6456c94dfd9afae73b86f05016cf}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab0bd6456c94dfd9afae73b86f05016cf}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!is\+\_\+training@{is\+\_\+training}}
\index{is\+\_\+training@{is\+\_\+training}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{is\+\_\+training}{is\_training}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+is\+\_\+training}



Definition at line 722 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!label\+\_\+truncate@{label\+\_\+truncate}}
\index{label\+\_\+truncate@{label\+\_\+truncate}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{label\+\_\+truncate}{label\_truncate}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+label\+\_\+truncate}



Definition at line 718 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a392ed66573001dfa2846d5042e8fc5a5}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a392ed66573001dfa2846d5042e8fc5a5}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!metrics@{metrics}}
\index{metrics@{metrics}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{metrics}{metrics}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+metrics}



Definition at line 691 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afe40410d2e3b2565ecd27441266011fc}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afe40410d2e3b2565ecd27441266011fc}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!model@{model}}
\index{model@{model}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{model}{model}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+model}



Definition at line 689 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a95cedd561757c9fc10dbf3a956e7f912}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a95cedd561757c9fc10dbf3a956e7f912}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}}
\index{N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{N\+U\+L\+L\+\_\+\+I\+DX}{NULL\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+N\+U\+L\+L\+\_\+\+I\+DX}



Definition at line 701 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!observation@{observation}}
\index{observation@{observation}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{observation}{observation}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+observation}



Definition at line 1579 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!opt@{opt}}
\index{opt@{opt}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{opt}{opt}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+opt}



Definition at line 687 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9533344de40049bf13209739bc92199d}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9533344de40049bf13209739bc92199d}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!optimizer@{optimizer}}
\index{optimizer@{optimizer}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{optimizer}{optimizer}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+optimizer}



Definition at line 844 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a292c402279f706390ffed9a7af868abf}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a292c402279f706390ffed9a7af868abf}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!P1\+\_\+\+T\+O\+K\+EN@{P1\+\_\+\+T\+O\+K\+EN}}
\index{P1\+\_\+\+T\+O\+K\+EN@{P1\+\_\+\+T\+O\+K\+EN}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{P1\+\_\+\+T\+O\+K\+EN}{P1\_TOKEN}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+P1\+\_\+\+T\+O\+K\+EN\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 330 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a81b5bf5acfa70764e3601c14a8afae85}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a81b5bf5acfa70764e3601c14a8afae85}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!P2\+\_\+\+T\+O\+K\+EN@{P2\+\_\+\+T\+O\+K\+EN}}
\index{P2\+\_\+\+T\+O\+K\+EN@{P2\+\_\+\+T\+O\+K\+EN}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{P2\+\_\+\+T\+O\+K\+EN}{P2\_TOKEN}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+P2\+\_\+\+T\+O\+K\+EN\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 331 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a805a9e47552d54d56f5b232ab4d5121f}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a805a9e47552d54d56f5b232ab4d5121f}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!proj\+\_\+rp@{proj\+\_\+rp}}
\index{proj\+\_\+rp@{proj\+\_\+rp}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{proj\+\_\+rp}{proj\_rp}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+proj\+\_\+rp}



Definition at line 1145 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a1ca476189900643fab04d1ac0ebfc719}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a1ca476189900643fab04d1ac0ebfc719}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!random@{random}}
\index{random@{random}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{random}{random}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+random}



Definition at line 710 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6355b9b0c0ccb24ffe1b5e3d89903cc3}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6355b9b0c0ccb24ffe1b5e3d89903cc3}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!rank\+\_\+candidates@{rank\+\_\+candidates}}
\index{rank\+\_\+candidates@{rank\+\_\+candidates}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{rank\+\_\+candidates}{rank\_candidates}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+rank\+\_\+candidates}



Definition at line 723 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0affe6b199275c182a27c9aa07393347}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0affe6b199275c182a27c9aa07393347}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!scheduler@{scheduler}}
\index{scheduler@{scheduler}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{scheduler}{scheduler}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+scheduler}



Definition at line 924 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a2018afae9938937f80b61475314012cd}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a2018afae9938937f80b61475314012cd}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!S\+T\+A\+R\+T\+\_\+\+I\+DX@{S\+T\+A\+R\+T\+\_\+\+I\+DX}}
\index{S\+T\+A\+R\+T\+\_\+\+I\+DX@{S\+T\+A\+R\+T\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{S\+T\+A\+R\+T\+\_\+\+I\+DX}{START\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+S\+T\+A\+R\+T\+\_\+\+I\+DX}



Definition at line 702 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!text\+\_\+truncate@{text\+\_\+truncate}}
\index{text\+\_\+truncate@{text\+\_\+truncate}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{text\+\_\+truncate}{text\_truncate}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+text\+\_\+truncate}



Definition at line 716 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3ae27e9fe68d255a960bcb5180f48a65}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3ae27e9fe68d255a960bcb5180f48a65}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!truncate@{truncate}}
\index{truncate@{truncate}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{truncate}{truncate}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+truncate}



Definition at line 714 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a10b8d2605e619d5d3dc9f67777cb190a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a10b8d2605e619d5d3dc9f67777cb190a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!use\+\_\+cuda@{use\+\_\+cuda}}
\index{use\+\_\+cuda@{use\+\_\+cuda}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{use\+\_\+cuda}{use\_cuda}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+use\+\_\+cuda}



Definition at line 656 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a54d8632c546ab621c93c34f13c964726}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a54d8632c546ab621c93c34f13c964726}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!warmup\+\_\+scheduler@{warmup\+\_\+scheduler}}
\index{warmup\+\_\+scheduler@{warmup\+\_\+scheduler}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{warmup\+\_\+scheduler}{warmup\_scheduler}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+warmup\+\_\+scheduler}



Definition at line 916 of file torch\+\_\+agent.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/core/\hyperlink{torch__agent_8py}{torch\+\_\+agent.\+py}\end{DoxyCompactItemize}
