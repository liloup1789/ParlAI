\hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent}{}\section{parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent Class Reference}
\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent}\index{parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent@{parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent}}


Inheritance diagram for parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d0/d92/classparlai_1_1core_1_1torch__agent_1_1TorchAgent__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=318pt]{d2/d85/classparlai_1_1core_1_1torch__agent_1_1TorchAgent__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9c622b8ed5a811841f30fe98cc297cde}{optim\+\_\+opts} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0bd9118252c602bb9d5a596ecae16717}{history\+\_\+class} (cls)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4a72bdd07d2cb5ce402d0058140cad0d}{add\+\_\+cmdline\+\_\+args} (cls, argparser)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ad0a00ada1fcd5b7ceec27b1a6cbdc281}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}{opt}, shared=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab22f61f153b522f429210c61eed2d5af}{build\+\_\+history} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a233316f9ec2805dd6a08fbf07f3a078a}{build\+\_\+dictionary} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9a21fa33fa5b2b928024fbc67826f233}{build\+\_\+model} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3784f1ddaa6ffad009716910f3f36dd4}{init\+\_\+optim} (self, params, optim\+\_\+states=None, saved\+\_\+optim\+\_\+type=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa51ac42dc34e3d2281a01cba78a96151}{build\+\_\+lr\+\_\+scheduler} (self, states=None, hard\+\_\+reset=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac694770cd4022eb047bf6fbb8f46035c}{report} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a02beaaedfa30463f9d0a97ea590b516f}{receive\+\_\+metrics} (self, metrics\+\_\+dict)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a373f0e276bf7c9d914a4e3363e9c2712}{share} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a48bb9b153353a0565ab7253dc1daef99}{vectorize} (self, obs, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}{history}, add\+\_\+start=True, add\+\_\+end=True, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}{text\+\_\+truncate}=None, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}{label\+\_\+truncate}=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afa491bf2384b017711ad722b5341b405}{is\+\_\+valid} (self, obs)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4c5824776df0c6cf995984a5e7a3f433}{batchify} (self, obs\+\_\+batch, sort=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aba56b961d929e5c5b5da9cf8bd331502}{match\+\_\+batch} (self, batch\+\_\+reply, valid\+\_\+inds, output=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a32921aa09a682ee752d4822a5f5ebbb4}{last\+\_\+reply} (self, use\+\_\+reply=\textquotesingle{}label\textquotesingle{})
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a87b18f0d6ab11be3c49375af072d0d33}{observe} (self, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}{observation})
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}{state\+\_\+dict} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adac7ee3db855786e8414e9f35fcb6e46}{save} (self, path=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dcfca62a677f8de97f09ce993258f84}{load\+\_\+state\+\_\+dict} (self, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}{state\+\_\+dict})
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_af626fc7d32fc9b0dfeec167a52353baf}{load} (self, path)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6f568650dd8e245a274671680ebb7587}{reset} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a03e18955cfd44dd019d0847bc7a46893}{reset\+\_\+metrics} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a51174dfa508970e3392246b02d0d94b5}{act} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7754a74d6c87590f46e71ec486c285a8}{batch\+\_\+act} (self, observations)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8ba9d535736c0af100d00c5e7b02b61b}{train\+\_\+step} (self, batch)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a18de0a52aeec4ef721aedbdd6ac06cad}{eval\+\_\+step} (self, batch)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6a7aff29231816a0f3cade9c72409dfc}{set\+\_\+interactive\+\_\+mode} (self, mode, shared)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8df662b1258ec67752b4fc0ad45733f9}{backward} (self, loss)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7e2c9e180887397daa6229a0f9700b1c}{update\+\_\+params} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a91c163f3e2d39b380095b7083f673b6e}{zero\+\_\+grad} (self)
\end{DoxyCompactItemize}
\subsection*{Static Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aea8849fa69a3f5dbd3216c8b06f180ea}{dictionary\+\_\+class} ()
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a10b8d2605e619d5d3dc9f67777cb190a}{use\+\_\+cuda}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa6f916e01d876679b529a893ad4f52f6}{fp16}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dd17721e788aafd51cd5af7bf7fc967}{replies}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_abebf29c0bb956bbc5ccc02777d2af3dd}{dict}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a392ed66573001dfa2846d5042e8fc5a5}{metrics}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}{opt}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afe40410d2e3b2565ecd27441266011fc}{model}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a13d46ae8aed6052679b62c3961a4de62}{criterion}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4ac66a09c1c164ea08f4b257c61c38a0}{id}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3a80083f0e34d8abc15b50123efec884}{E\+M\+P\+TY}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a95cedd561757c9fc10dbf3a956e7f912}{N\+U\+L\+L\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a2018afae9938937f80b61475314012cd}{S\+T\+A\+R\+T\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a31bb7c8bf380660ee4e3822756563599}{E\+N\+D\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a1ca476189900643fab04d1ac0ebfc719}{random}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae67e7dc97dff3c46522712945ca23f50}{batch\+\_\+idx}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a15cbb1f743c1d341d914ade47e49071b}{histsz}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3ae27e9fe68d255a960bcb5180f48a65}{truncate}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}{text\+\_\+truncate}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}{label\+\_\+truncate}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}{history}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab0bd6456c94dfd9afae73b86f05016cf}{is\+\_\+training}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6355b9b0c0ccb24ffe1b5e3d89903cc3}{rank\+\_\+candidates}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a63011fa9bd927de8acc9ffa676caa73a}{add\+\_\+person\+\_\+tokens}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9533344de40049bf13209739bc92199d}{optimizer}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a54d8632c546ab621c93c34f13c964726}{warmup\+\_\+scheduler}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0affe6b199275c182a27c9aa07393347}{scheduler}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a805a9e47552d54d56f5b232ab4d5121f}{proj\+\_\+rp}
\item 
\hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}{observation}
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
string \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac946030b54cc854162e8bc6b7aad7272}{P1\+\_\+\+T\+O\+K\+EN} = \textquotesingle{}\+\_\+\+\_\+p1\+\_\+\+\_\+\textquotesingle{}
\item 
string \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_af6e16e0532e71b06328e078cb3c9324c}{P2\+\_\+\+T\+O\+K\+EN} = \textquotesingle{}\+\_\+\+\_\+p2\+\_\+\+\_\+\textquotesingle{}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}A provided abstract base agent for any model that wants to use Torch.

Exists to make it easier to implement a new agent.
Not necessary, but reduces duplicated code.

Many methods are intended to be either used as is when the default is
acceptable, or to be overriden and called with super(), with the extra
functionality added to the initial result. See the method comment for
recommended behavior.

This agent serves as a common framework for all ParlAI models which want
to use PyTorch.
\end{DoxyVerb}
 

Definition at line 334 of file torch\+\_\+agent.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ad0a00ada1fcd5b7ceec27b1a6cbdc281}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ad0a00ada1fcd5b7ceec27b1a6cbdc281}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{opt,  }\item[{}]{shared = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Initialize agent.
\end{DoxyVerb}
 

Definition at line 664 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
664     \textcolor{keyword}{def }\_\_init\_\_(self, opt, shared=None):
665         \textcolor{stringliteral}{"""}
666 \textcolor{stringliteral}{        Initialize agent.}
667 \textcolor{stringliteral}{        """}
668         super().\_\_init\_\_(opt, shared)
669         opt = self.opt
670 
671         \textcolor{comment}{# check for cuda}
672         self.use\_cuda = \textcolor{keywordflow}{not} opt[\textcolor{stringliteral}{'no\_cuda'}] \textcolor{keywordflow}{and} torch.cuda.is\_available()
673         \textcolor{keywordflow}{if} self.use\_cuda:
674             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} shared:
675                 print(\textcolor{stringliteral}{'[ Using CUDA ]'})
676             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} shared \textcolor{keywordflow}{and} opt[\textcolor{stringliteral}{'gpu'}] != -1:
677                 torch.cuda.set\_device(opt[\textcolor{stringliteral}{'gpu'}])
678         \textcolor{comment}{# indicate whether using fp16}
679         self.fp16 = self.use\_cuda \textcolor{keywordflow}{and} self.opt.get(\textcolor{stringliteral}{'fp16'}, \textcolor{keyword}{False})
680 
681         \textcolor{keywordflow}{if} shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
682             \textcolor{comment}{# intitialize any important structures from scratch}
683             self.replies = \{\}  \textcolor{comment}{# past replies}
684             self.\_replies\_are\_shared = \textcolor{keyword}{False}
685             self.dict = self.build\_dictionary()
686 
687             \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'fp16'}):
688                 \textcolor{comment}{# Volta cores revert to FP32 hardware if tensors are not multiples}
689                 \textcolor{comment}{# of 8 in all dimensions. This INCLUDES the embeddings layer! As}
690                 \textcolor{comment}{# such, we need some extra magic to ensure the dictionary is padded}
691                 \textcolor{comment}{# with extra tokens to make it a multiple of 8.}
692                 \textcolor{keywordflow}{if} len(self.dict) % 8 != 0:
693                     \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(8 - len(self.dict) % 8):
694                         self.dict[\textcolor{stringliteral}{'\_\_FP16\_PAD\_\{\}\_\_'}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(i)] = 1
695 
696             self.metrics = \{\}
697             \textcolor{comment}{# gradient norms}
698             self.metrics[\textcolor{stringliteral}{'gnorm'}] = 0.0
699             \textcolor{comment}{# gradient clipping rate}
700             self.metrics[\textcolor{stringliteral}{'clip'}] = 0.0
701             \textcolor{comment}{# number of calls to optimizer.step()}
702             self.metrics[\textcolor{stringliteral}{'updates'}] = 0
703         \textcolor{keywordflow}{else}:
704             \textcolor{comment}{# copy initialized data from shared table}
705             self.opt = shared[\textcolor{stringliteral}{'opt'}]
706             self.dict = shared[\textcolor{stringliteral}{'dict'}]
707             self.model = shared[\textcolor{stringliteral}{'model'}]
708             self.criterion = shared[\textcolor{stringliteral}{'criterion'}]
709             self.metrics = shared[\textcolor{stringliteral}{'metrics'}]
710             \textcolor{keywordflow}{if} self.opt[\textcolor{stringliteral}{'batchsize'}] == 1 \textcolor{keywordflow}{or} self.opt[\textcolor{stringliteral}{'interactive\_mode'}]:
711                 \textcolor{comment}{# if we're not using batching (e.g. mturk), then replies really need}
712                 \textcolor{comment}{# to stay separated}
713                 self.replies = \{\}
714                 self.\_replies\_are\_shared = \textcolor{keyword}{False}
715             \textcolor{keywordflow}{else}:
716                 self.replies = shared[\textcolor{stringliteral}{'replies'}]
717                 self.\_replies\_are\_shared = \textcolor{keyword}{True}
718 
719         \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1:
720             torch.set\_num\_threads(1)
721 
722         \textcolor{comment}{# Default to the class name, sans "Agent". child can override}
723         self.id = \hyperlink{namespaceparlai_1_1agents_1_1tfidf__retriever_1_1build__tfidf_ad5dfae268e23f506da084a9efb72f619}{type}(self).\_\_name\_\_.replace(\textcolor{stringliteral}{"Agent"}, \textcolor{stringliteral}{""})
724 
725         \textcolor{comment}{# now set up any fields that all instances may need}
726         self.EMPTY = torch.LongTensor([])
727         self.NULL\_IDX = self.dict[self.dict.null\_token]
728         self.START\_IDX = self.dict[self.dict.start\_token]
729         self.END\_IDX = self.dict[self.dict.end\_token]
730 
731         \textcolor{comment}{# for gradient acumulation}
732         self.\_number\_grad\_accum = 0
733         \textcolor{comment}{# for the LR scheduler}
734         self.\_number\_training\_updates = 0
735         \textcolor{comment}{# fixed random seed}
736         self.random = random.Random(42)
737         \textcolor{comment}{# which row in the batch this instance is}
738         self.batch\_idx = shared \textcolor{keywordflow}{and} shared.get(\textcolor{stringliteral}{'batchindex'}) \textcolor{keywordflow}{or} 0
739         \textcolor{comment}{# can remember as few as zero utterances if desired}
740         self.histsz = opt[\textcolor{stringliteral}{'history\_size'}]
741         \textcolor{comment}{# truncate == 0 might give funny behavior}
742         self.truncate = opt[\textcolor{stringliteral}{'truncate'}] \textcolor{keywordflow}{if} opt[\textcolor{stringliteral}{'truncate'}] >= 0 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
743         text\_truncate = opt.get(\textcolor{stringliteral}{'text\_truncate'}) \textcolor{keywordflow}{or} opt[\textcolor{stringliteral}{'truncate'}]
744         self.text\_truncate = text\_truncate \textcolor{keywordflow}{if} text\_truncate >= 0 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
745         label\_truncate = opt.get(\textcolor{stringliteral}{'label\_truncate'}) \textcolor{keywordflow}{or} opt[\textcolor{stringliteral}{'truncate'}]
746         self.label\_truncate = label\_truncate \textcolor{keywordflow}{if} label\_truncate >= 0 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
747         \textcolor{comment}{# stores up to hist\_utt past observations within current dialog}
748         self.history = self.build\_history()
749 
750         self.is\_training = \textcolor{keyword}{False}  \textcolor{comment}{# track whether model is training}
751         self.rank\_candidates = opt[\textcolor{stringliteral}{'rank\_candidates'}]
752         self.add\_person\_tokens = opt.get(\textcolor{stringliteral}{'person\_tokens'}, \textcolor{keyword}{False})
753         \textcolor{comment}{# set interactive mode or not according to options.}
754         self.set\_interactive\_mode(opt[\textcolor{stringliteral}{'interactive\_mode'}], shared)
755 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a51174dfa508970e3392246b02d0d94b5}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a51174dfa508970e3392246b02d0d94b5}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!act@{act}}
\index{act@{act}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{act()}{act()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+act (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Call batch_act with the singleton batch.
\end{DoxyVerb}
 

Definition at line 1751 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1751     \textcolor{keyword}{def }act(self):
1752         \textcolor{stringliteral}{"""}
1753 \textcolor{stringliteral}{        Call batch\_act with the singleton batch.}
1754 \textcolor{stringliteral}{        """}
1755         \textcolor{keywordflow}{if} self.\_replies\_are\_shared:
1756             \textcolor{keywordflow}{raise} RuntimeError(
1757                 \textcolor{stringliteral}{'act() will misbehave in batching mode. Set batchsize to 1, or '}
1758                 \textcolor{stringliteral}{'--interactive-mode true'}
1759             )
1760         \textcolor{keywordflow}{return} self.batch\_act([self.observation])[0]
1761 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4a72bdd07d2cb5ce402d0058140cad0d}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4a72bdd07d2cb5ce402d0058140cad0d}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}}
\index{add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{add\+\_\+cmdline\+\_\+args()}{add\_cmdline\_args()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+add\+\_\+cmdline\+\_\+args (\begin{DoxyParamCaption}\item[{}]{cls,  }\item[{}]{argparser }\end{DoxyParamCaption})}

\begin{DoxyVerb}Add the default commandline args we expect most agents to want.
\end{DoxyVerb}
 

Definition at line 407 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
407     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(cls, argparser):
408         \textcolor{stringliteral}{"""}
409 \textcolor{stringliteral}{        Add the default commandline args we expect most agents to want.}
410 \textcolor{stringliteral}{        """}
411         agent = argparser.add\_argument\_group(\textcolor{stringliteral}{'TorchAgent Arguments'})
412         agent.add\_argument(
413             \textcolor{stringliteral}{'-i'},
414             \textcolor{stringliteral}{'--interactive-mode'},
415             type=\textcolor{stringliteral}{'bool'},
416             default=\textcolor{keyword}{False},
417             help=\textcolor{stringliteral}{'Whether in full interactive mode or not,  which means generating text or'}
418             \textcolor{stringliteral}{' retrieving from a full set of candidates, which is necessary to actually'}
419             \textcolor{stringliteral}{' do full dialogue. However, during training or quick validation (e.g. PPL for'}
420             \textcolor{stringliteral}{' generation or ranking a few candidates for ranking models) you might want these'}
421             \textcolor{stringliteral}{' set to off.'}
422             \textcolor{stringliteral}{' Typically, scripts can set their preferred default behavior at the start,'}
423             \textcolor{stringliteral}{' e.g. eval scripts.'},
424         )
425         \textcolor{comment}{# pretrained embedding arguments}
426         agent.add\_argument(
427             \textcolor{stringliteral}{'-emb'},
428             \textcolor{stringliteral}{'--embedding-type'},
429             default=\textcolor{stringliteral}{'random'},
430             choices=[
431                 \textcolor{stringliteral}{'random'},
432                 \textcolor{stringliteral}{'glove'},
433                 \textcolor{stringliteral}{'glove-fixed'},
434                 \textcolor{stringliteral}{'glove-twitter-fixed'},
435                 \textcolor{stringliteral}{'fasttext'},
436                 \textcolor{stringliteral}{'fasttext-fixed'},
437                 \textcolor{stringliteral}{'fasttext\_cc'},
438                 \textcolor{stringliteral}{'fasttext\_cc-fixed'},
439             ],
440             help=\textcolor{stringliteral}{'Choose between different strategies for initializing word '}
441             \textcolor{stringliteral}{'embeddings. Default is random, but can also preinitialize '}
442             \textcolor{stringliteral}{'from Glove or Fasttext. Preinitialized embeddings can also '}
443             \textcolor{stringliteral}{'be fixed so they are not updated during training.'},
444         )
445         agent.add\_argument(
446             \textcolor{stringliteral}{'-embp'},
447             \textcolor{stringliteral}{'--embedding-projection'},
448             default=\textcolor{stringliteral}{'random'},
449             help=\textcolor{stringliteral}{'If pretrained embeddings have a different dimensionality '}
450             \textcolor{stringliteral}{'than your embedding size, strategy for projecting to the '}
451             \textcolor{stringliteral}{'correct size. If the dimensions are the same, this is '}
452             \textcolor{stringliteral}{'ignored unless you append "-force" to your choice.'},
453         )
454         agent.add\_argument(
455             \textcolor{stringliteral}{'--fp16'}, type=\textcolor{stringliteral}{'bool'}, default=\textcolor{keyword}{False}, help=\textcolor{stringliteral}{'Use fp16 computations.'}
456         )
457         \textcolor{comment}{# optimizer arguments}
458         optim\_group = agent.add\_argument\_group(\textcolor{stringliteral}{'Optimizer Arguments'})
459         optim\_group.add\_argument(
460             \textcolor{stringliteral}{'-opt'},
461             \textcolor{stringliteral}{'--optimizer'},
462             default=\textcolor{stringliteral}{'sgd'},
463             choices=cls.optim\_opts(),
464             help=\textcolor{stringliteral}{'Choose between pytorch optimizers. Any member of torch.optim'}
465             \textcolor{stringliteral}{' should be valid.'},
466         )
467         optim\_group.add\_argument(
468             \textcolor{stringliteral}{'-lr'}, \textcolor{stringliteral}{'--learningrate'}, type=float, default=1, help=\textcolor{stringliteral}{'Learning rate'}
469         )
470         optim\_group.add\_argument(
471             \textcolor{stringliteral}{'-clip'},
472             \textcolor{stringliteral}{'--gradient-clip'},
473             type=float,
474             default=0.1,
475             help=\textcolor{stringliteral}{'gradient clipping using l2 norm'},
476         )
477         optim\_group.add\_argument(
478             \textcolor{stringliteral}{'--adam-eps'},
479             type=float,
480             default=1e-8,
481             hidden=\textcolor{keyword}{True},
482             help=\textcolor{stringliteral}{'Epsilon value for Adam optimizers. Set to 1e-6 if your '}
483             \textcolor{stringliteral}{'large model has stability issues, but prefer the default.'},
484         )
485         optim\_group.add\_argument(
486             \textcolor{stringliteral}{'-mom'},
487             \textcolor{stringliteral}{'--momentum'},
488             default=0,
489             type=float,
490             help=\textcolor{stringliteral}{'if applicable, momentum value for optimizer.'},
491         )
492         optim\_group.add\_argument(
493             \textcolor{stringliteral}{'--nesterov'},
494             default=\textcolor{keyword}{True},
495             type=\textcolor{stringliteral}{'bool'},
496             help=\textcolor{stringliteral}{'if applicable, whether to use nesterov momentum.'},
497         )
498         optim\_group.add\_argument(
499             \textcolor{stringliteral}{'-nu'},
500             \textcolor{stringliteral}{'--nus'},
501             default=\textcolor{stringliteral}{'0.7'},
502             type=\textcolor{stringliteral}{'floats'},
503             help=\textcolor{stringliteral}{'if applicable, nu value(s) for optimizer. can use a single '}
504             \textcolor{stringliteral}{'value like 0.7 or a comma-separated tuple like 0.7,1.0'},
505         )
506         optim\_group.add\_argument(
507             \textcolor{stringliteral}{'-beta'},
508             \textcolor{stringliteral}{'--betas'},
509             default=\textcolor{stringliteral}{'0.9,0.999'},
510             type=\textcolor{stringliteral}{'floats'},
511             help=\textcolor{stringliteral}{'if applicable, beta value(s) for optimizer. can use a single '}
512             \textcolor{stringliteral}{'value like 0.9 or a comma-separated tuple like 0.9,0.999'},
513         )
514         optim\_group.add\_argument(
515             \textcolor{stringliteral}{'-wdecay'},
516             \textcolor{stringliteral}{'--weight-decay'},
517             type=float,
518             default=\textcolor{keywordtype}{None},
519             help=\textcolor{stringliteral}{'Weight decay on the weights.'},
520         )
521 
522         \textcolor{comment}{# lr scheduler}
523         lr\_group = agent.add\_argument\_group(\textcolor{stringliteral}{'Learning Rate Scheduler'})
524         lr\_group.add\_argument(
525             \textcolor{stringliteral}{'--lr-scheduler'},
526             type=str,
527             default=\textcolor{stringliteral}{'reduceonplateau'},
528             choices=[\textcolor{stringliteral}{'reduceonplateau'}, \textcolor{stringliteral}{'none'}, \textcolor{stringliteral}{'fixed'}, \textcolor{stringliteral}{'invsqrt'}],
529             help=\textcolor{stringliteral}{'Learning rate scheduler.'},
530         )
531         lr\_group.add\_argument(
532             \textcolor{stringliteral}{'--lr-scheduler-patience'},
533             type=int,
534             default=3,
535             help=\textcolor{stringliteral}{'LR scheduler patience. In number of validation runs. If using '}
536             \textcolor{stringliteral}{'fixed scheduler, LR is decayed every <patience> validations.'},
537         )
538         lr\_group.add\_argument(
539             \textcolor{stringliteral}{'--lr-scheduler-decay'},
540             type=float,
541             default=0.5,
542             help=\textcolor{stringliteral}{'Decay factor for LR scheduler, or how much LR is multiplied by '}
543             \textcolor{stringliteral}{'when it is lowered.'},
544         )
545         lr\_group.add\_argument(
546             \textcolor{stringliteral}{'--warmup-updates'},
547             type=int,
548             default=-1,
549             hidden=\textcolor{keyword}{True},
550             help=\textcolor{stringliteral}{'Learning rate warmup period, in number of SGD updates. '}
551             \textcolor{stringliteral}{'Linearly scales up LR over period. Only enabled if > 0.'},
552         )
553         lr\_group.add\_argument(
554             \textcolor{stringliteral}{'--warmup-rate'},
555             type=float,
556             default=1e-4,
557             hidden=\textcolor{keyword}{True},
558             help=\textcolor{stringliteral}{'Warmup learning rate *multiplier*. Initial LR is multiplied by '}
559             \textcolor{stringliteral}{'this value. Linearly adjusted up to 1.0 across --warmup-updates '}
560             \textcolor{stringliteral}{'steps.'},
561         )
562         lr\_group.add\_argument(
563             \textcolor{stringliteral}{'--update-freq'},
564             type=int,
565             default=1,
566             hidden=\textcolor{keyword}{True},
567             help=\textcolor{stringliteral}{'Accumulate gradients N times before performing an optimizer.step().'},
568         )
569 
570         \textcolor{comment}{# preprocessing arguments}
571         agent.add\_argument(
572             \textcolor{stringliteral}{'-rc'},
573             \textcolor{stringliteral}{'--rank-candidates'},
574             type=\textcolor{stringliteral}{'bool'},
575             default=\textcolor{keyword}{False},
576             help=\textcolor{stringliteral}{'Whether the model should parse candidates for ranking.'},
577         )
578         agent.add\_argument(
579             \textcolor{stringliteral}{'-tr'},
580             \textcolor{stringliteral}{'--truncate'},
581             default=-1,
582             type=int,
583             help=\textcolor{stringliteral}{'Truncate input lengths to increase speed / use less memory.'},
584         )
585         agent.add\_argument(
586             \textcolor{stringliteral}{'--text-truncate'},
587             type=int,
588             help=\textcolor{stringliteral}{'Text input truncation length: if not specified, this will '}
589             \textcolor{stringliteral}{'default to `truncate`'},
590         )
591         agent.add\_argument(
592             \textcolor{stringliteral}{'--label-truncate'},
593             type=int,
594             help=\textcolor{stringliteral}{'Label truncation length: if not specified, this will default '}
595             \textcolor{stringliteral}{'to `truncate`'},
596         )
597         agent.add\_argument(
598             \textcolor{stringliteral}{'-histsz'},
599             \textcolor{stringliteral}{'--history-size'},
600             default=-1,
601             type=int,
602             help=\textcolor{stringliteral}{'Number of past dialog utterances to remember.'},
603         )
604         agent.add\_argument(
605             \textcolor{stringliteral}{'-pt'},
606             \textcolor{stringliteral}{'--person-tokens'},
607             type=\textcolor{stringliteral}{'bool'},
608             default=\textcolor{keyword}{False},
609             help=\textcolor{stringliteral}{'add person tokens to history. adds \_\_p1\_\_ in front of input '}
610             \textcolor{stringliteral}{'text and \_\_p2\_\_ in front of past labels when available or '}
611             \textcolor{stringliteral}{'past utterances generated by the model. these are added to '}
612             \textcolor{stringliteral}{'the dictionary during initialization.'},
613         )
614         agent.add\_argument(
615             \textcolor{stringliteral}{'--split-lines'},
616             type=\textcolor{stringliteral}{'bool'},
617             default=\textcolor{keyword}{False},
618             help=\textcolor{stringliteral}{'split the dialogue history on newlines and save in separate '}
619             \textcolor{stringliteral}{'vectors'},
620         )
621         agent.add\_argument(
622             \textcolor{stringliteral}{'--use-reply'},
623             default=\textcolor{stringliteral}{'label'},
624             hidden=\textcolor{keyword}{True},
625             choices=[\textcolor{stringliteral}{'label'}, \textcolor{stringliteral}{'model'}, \textcolor{stringliteral}{'none'}],
626             help=\textcolor{stringliteral}{'Which previous replies to use as history. If label, use '}
627             \textcolor{stringliteral}{'gold dataset replies. If model, use model\(\backslash\)'s own replies. '}
628             \textcolor{stringliteral}{'If none, do not track replies in history.'},
629         )
630         agent.add\_argument(
631             \textcolor{stringliteral}{'--add-p1-after-newln'},
632             type=\textcolor{stringliteral}{'bool'},
633             default=\textcolor{keyword}{False},
634             hidden=\textcolor{keyword}{True},
635             help=\textcolor{stringliteral}{'Add the other speaker token before the last newline in the '}
636             \textcolor{stringliteral}{'input instead of at the beginning of the input. this is '}
637             \textcolor{stringliteral}{'useful for tasks that include some kind of context before '}
638             \textcolor{stringliteral}{'the actual utterance (e.g. squad, babi, personachat).'},
639         )
640         agent.add\_argument(
641             \textcolor{stringliteral}{'--delimiter'},
642             type=str,
643             default=\textcolor{stringliteral}{'\(\backslash\)n'},
644             help=\textcolor{stringliteral}{'Join history lines with this token, defaults to newline'},
645         )
646         \textcolor{comment}{# GPU arguments}
647         \textcolor{comment}{# these gpu options are all mutually exclusive, and should error if the}
648         \textcolor{comment}{# user tries to present multiple of them}
649         gpugroup = agent.add\_mutually\_exclusive\_group()
650         gpugroup.add\_argument(
651             \textcolor{stringliteral}{'-gpu'}, \textcolor{stringliteral}{'--gpu'}, type=int, default=-1, help=\textcolor{stringliteral}{'which GPU to use'}
652         )
653         gpugroup.add\_argument(
654             \textcolor{stringliteral}{'--no-cuda'},
655             default=\textcolor{keyword}{False},
656             action=\textcolor{stringliteral}{'store\_true'},
657             dest=\textcolor{stringliteral}{'no\_cuda'},
658             help=\textcolor{stringliteral}{'disable GPUs even if available. otherwise, will use GPUs if '}
659             \textcolor{stringliteral}{'available on the device.'},
660         )
661 
662         cls.dictionary\_class().\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(argparser)
663 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8df662b1258ec67752b4fc0ad45733f9}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8df662b1258ec67752b4fc0ad45733f9}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!backward@{backward}}
\index{backward@{backward}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{backward()}{backward()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+backward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{loss }\end{DoxyParamCaption})}

\begin{DoxyVerb}Perform a backward pass.

It is recommended you use this instead of loss.backward(), for integration with
distributed training and FP16 training.
\end{DoxyVerb}
 

Definition at line 1825 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1825     \textcolor{keyword}{def }backward(self, loss):
1826         \textcolor{stringliteral}{"""}
1827 \textcolor{stringliteral}{        Perform a backward pass.}
1828 \textcolor{stringliteral}{}
1829 \textcolor{stringliteral}{        It is recommended you use this instead of loss.backward(), for integration with}
1830 \textcolor{stringliteral}{        distributed training and FP16 training.}
1831 \textcolor{stringliteral}{        """}
1832         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'update\_freq'}, 1) > 1:
1833             \textcolor{comment}{# gradient accumulation, but still need to average across the minibatches}
1834             loss = loss / self.opt[\textcolor{stringliteral}{'update\_freq'}]
1835 
1836         \textcolor{keywordflow}{if} self.fp16:
1837             self.optimizer.backward(loss, update\_master\_grads=\textcolor{keyword}{False})
1838         \textcolor{keywordflow}{else}:
1839             loss.backward()
1840 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7754a74d6c87590f46e71ec486c285a8}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7754a74d6c87590f46e71ec486c285a8}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!batch\+\_\+act@{batch\+\_\+act}}
\index{batch\+\_\+act@{batch\+\_\+act}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{batch\+\_\+act()}{batch\_act()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+batch\+\_\+act (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{observations }\end{DoxyParamCaption})}

\begin{DoxyVerb}Process a batch of observations (batchsize list of message dicts).

These observations have been preprocessed by the observe method.

Subclasses can override this for special functionality, but if the
default behaviors are fine then just override the ``train_step`` and
``eval_step`` methods instead. The former is called when labels are
present in the observations batch; otherwise, the latter is called.
\end{DoxyVerb}
 

Definition at line 1762 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1762     \textcolor{keyword}{def }batch\_act(self, observations):
1763         \textcolor{stringliteral}{"""}
1764 \textcolor{stringliteral}{        Process a batch of observations (batchsize list of message dicts).}
1765 \textcolor{stringliteral}{}
1766 \textcolor{stringliteral}{        These observations have been preprocessed by the observe method.}
1767 \textcolor{stringliteral}{}
1768 \textcolor{stringliteral}{        Subclasses can override this for special functionality, but if the}
1769 \textcolor{stringliteral}{        default behaviors are fine then just override the ``train\_step`` and}
1770 \textcolor{stringliteral}{        ``eval\_step`` methods instead. The former is called when labels are}
1771 \textcolor{stringliteral}{        present in the observations batch; otherwise, the latter is called.}
1772 \textcolor{stringliteral}{        """}
1773         batch\_size = len(observations)
1774         \textcolor{comment}{# initialize a list of replies with this agent's id}
1775         batch\_reply = [
1776             Message(\{\textcolor{stringliteral}{'id'}: self.getID(), \textcolor{stringliteral}{'episode\_done'}: \textcolor{keyword}{False}\})
1777             \textcolor{keywordflow}{for} \_ \textcolor{keywordflow}{in} range(batch\_size)
1778         ]
1779 
1780         \textcolor{comment}{# check if there are any labels available, if so we will train on them}
1781         self.is\_training = any(\textcolor{stringliteral}{'labels'} \textcolor{keywordflow}{in} obs \textcolor{keywordflow}{for} obs \textcolor{keywordflow}{in} observations)
1782 
1783         \textcolor{comment}{# create a batch from the vectors}
1784         batch = self.batchify(observations)
1785 
1786         \textcolor{keywordflow}{if} self.is\_training:
1787             output = self.train\_step(batch)
1788         \textcolor{keywordflow}{else}:
1789             with torch.no\_grad():
1790                 \textcolor{comment}{# save memory and compute by disabling autograd.}
1791                 \textcolor{comment}{# use `with torch.enable\_grad()` to gain back graidients.}
1792                 output = self.eval\_step(batch)
1793 
1794         \textcolor{keywordflow}{if} output \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1795             self.replies[\textcolor{stringliteral}{'batch\_reply'}] = \textcolor{keywordtype}{None}
1796             \textcolor{keywordflow}{return} batch\_reply
1797 
1798         self.match\_batch(batch\_reply, batch.valid\_indices, output)
1799         self.replies[\textcolor{stringliteral}{'batch\_reply'}] = batch\_reply
1800 
1801         \textcolor{keywordflow}{return} batch\_reply
1802 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4c5824776df0c6cf995984a5e7a3f433}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4c5824776df0c6cf995984a5e7a3f433}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!batchify@{batchify}}
\index{batchify@{batchify}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{batchify()}{batchify()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+batchify (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{obs\+\_\+batch,  }\item[{}]{sort = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create a batch of valid observations from an unchecked batch.

A valid observation is one that passes the lambda provided to the
function, which defaults to checking if the preprocessed 'text_vec'
field is present which would have been set by this agent's 'vectorize'
function.

Returns a namedtuple Batch. See original definition above for in-depth
explanation of each field.

If you want to include additonal fields in the batch, you can subclass
this function and return your own "Batch" namedtuple: copy the Batch
namedtuple at the top of this class, and then add whatever additional
fields that you want to be able to access. You can then call
super().batchify(...) to set up the original fields and then set up the
additional fields in your subclass and return that batch instead.

:param obs_batch:
    List of vectorized observations

:param sort:
    Default False, orders the observations by length of vectors. Set to
    true when using torch.nn.utils.rnn.pack_padded_sequence.  Uses the text
    vectors if available, otherwise uses the label vectors if available.
\end{DoxyVerb}
 

Definition at line 1447 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1447     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1utils_aca22dd97c5b6dcda2a7479c1cb22ef1e}{batchify}(self, obs\_batch, sort=False):
1448         \textcolor{stringliteral}{"""}
1449 \textcolor{stringliteral}{        Create a batch of valid observations from an unchecked batch.}
1450 \textcolor{stringliteral}{}
1451 \textcolor{stringliteral}{        A valid observation is one that passes the lambda provided to the}
1452 \textcolor{stringliteral}{        function, which defaults to checking if the preprocessed 'text\_vec'}
1453 \textcolor{stringliteral}{        field is present which would have been set by this agent's 'vectorize'}
1454 \textcolor{stringliteral}{        function.}
1455 \textcolor{stringliteral}{}
1456 \textcolor{stringliteral}{        Returns a namedtuple Batch. See original definition above for in-depth}
1457 \textcolor{stringliteral}{        explanation of each field.}
1458 \textcolor{stringliteral}{}
1459 \textcolor{stringliteral}{        If you want to include additonal fields in the batch, you can subclass}
1460 \textcolor{stringliteral}{        this function and return your own "Batch" namedtuple: copy the Batch}
1461 \textcolor{stringliteral}{        namedtuple at the top of this class, and then add whatever additional}
1462 \textcolor{stringliteral}{        fields that you want to be able to access. You can then call}
1463 \textcolor{stringliteral}{        super().batchify(...) to set up the original fields and then set up the}
1464 \textcolor{stringliteral}{        additional fields in your subclass and return that batch instead.}
1465 \textcolor{stringliteral}{}
1466 \textcolor{stringliteral}{        :param obs\_batch:}
1467 \textcolor{stringliteral}{            List of vectorized observations}
1468 \textcolor{stringliteral}{}
1469 \textcolor{stringliteral}{        :param sort:}
1470 \textcolor{stringliteral}{            Default False, orders the observations by length of vectors. Set to}
1471 \textcolor{stringliteral}{            true when using torch.nn.utils.rnn.pack\_padded\_sequence.  Uses the text}
1472 \textcolor{stringliteral}{            vectors if available, otherwise uses the label vectors if available.}
1473 \textcolor{stringliteral}{        """}
1474         \textcolor{keywordflow}{if} len(obs\_batch) == 0:
1475             \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a74cfde390a2b9861179ac0fcd59da28c}{Batch}()
1476 
1477         valid\_obs = [(i, ex) \textcolor{keywordflow}{for} i, ex \textcolor{keywordflow}{in} enumerate(obs\_batch) \textcolor{keywordflow}{if} self.is\_valid(ex)]
1478 
1479         \textcolor{keywordflow}{if} len(valid\_obs) == 0:
1480             \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a74cfde390a2b9861179ac0fcd59da28c}{Batch}()
1481 
1482         valid\_inds, exs = zip(*valid\_obs)
1483 
1484         \textcolor{comment}{# TEXT}
1485         xs, x\_lens = \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}
1486         \textcolor{keywordflow}{if} any(ex.get(\textcolor{stringliteral}{'text\_vec'}) \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None} \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs):
1487             \_xs = [ex.get(\textcolor{stringliteral}{'text\_vec'}, self.EMPTY) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1488             xs, x\_lens = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_adb5a414ae439f14c54e8c760b91cc4c8}{padded\_tensor}(
1489                 \_xs, self.NULL\_IDX, self.use\_cuda, fp16friendly=self.opt.get(\textcolor{stringliteral}{'fp16'})
1490             )
1491             \textcolor{keywordflow}{if} sort:
1492                 sort = \textcolor{keyword}{False}  \textcolor{comment}{# now we won't sort on labels}
1493                 xs, x\_lens, valid\_inds, exs = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_a1521e559b740f741ebb47b8755202bb2}{argsort}(
1494                     x\_lens, xs, x\_lens, valid\_inds, exs, descending=\textcolor{keyword}{True}
1495                 )
1496 
1497         \textcolor{comment}{# LABELS}
1498         labels\_avail = any(\textcolor{stringliteral}{'labels\_vec'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs)
1499         some\_labels\_avail = labels\_avail \textcolor{keywordflow}{or} any(\textcolor{stringliteral}{'eval\_labels\_vec'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs)
1500 
1501         ys, y\_lens, labels = \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}
1502         \textcolor{keywordflow}{if} some\_labels\_avail:
1503             field = \textcolor{stringliteral}{'labels'} \textcolor{keywordflow}{if} labels\_avail \textcolor{keywordflow}{else} \textcolor{stringliteral}{'eval\_labels'}
1504 
1505             label\_vecs = [ex.get(field + \textcolor{stringliteral}{'\_vec'}, self.EMPTY) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1506             labels = [ex.get(field + \textcolor{stringliteral}{'\_choice'}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1507             y\_lens = [y.shape[0] \textcolor{keywordflow}{for} y \textcolor{keywordflow}{in} label\_vecs]
1508 
1509             ys, y\_lens = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_adb5a414ae439f14c54e8c760b91cc4c8}{padded\_tensor}(
1510                 label\_vecs,
1511                 self.NULL\_IDX,
1512                 self.use\_cuda,
1513                 fp16friendly=self.opt.get(\textcolor{stringliteral}{'fp16'}),
1514             )
1515             \textcolor{keywordflow}{if} sort \textcolor{keywordflow}{and} xs \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1516                 ys, valid\_inds, label\_vecs, labels, y\_lens = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_a1521e559b740f741ebb47b8755202bb2}{argsort}(
1517                     y\_lens, ys, valid\_inds, label\_vecs, labels, y\_lens, descending=\textcolor{keyword}{True}
1518                 )
1519 
1520         \textcolor{comment}{# LABEL\_CANDIDATES}
1521         cands, cand\_vecs = \textcolor{keywordtype}{None}, \textcolor{keywordtype}{None}
1522         \textcolor{keywordflow}{if} any(\textcolor{stringliteral}{'label\_candidates\_vecs'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs):
1523             cands = [ex.get(\textcolor{stringliteral}{'label\_candidates'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1524             cand\_vecs = [ex.get(\textcolor{stringliteral}{'label\_candidates\_vecs'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1525 
1526         \textcolor{comment}{# IMAGE}
1527         imgs = \textcolor{keywordtype}{None}
1528         \textcolor{keywordflow}{if} any(\textcolor{stringliteral}{'image'} \textcolor{keywordflow}{in} ex \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs):
1529             imgs = [ex.get(\textcolor{stringliteral}{'image'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{for} ex \textcolor{keywordflow}{in} exs]
1530 
1531         \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a74cfde390a2b9861179ac0fcd59da28c}{Batch}(
1532             text\_vec=xs,
1533             text\_lengths=x\_lens,
1534             label\_vec=ys,
1535             label\_lengths=y\_lens,
1536             labels=labels,
1537             valid\_indices=valid\_inds,
1538             candidates=cands,
1539             candidate\_vecs=cand\_vecs,
1540             image=imgs,
1541             observations=exs,
1542         )
1543 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a233316f9ec2805dd6a08fbf07f3a078a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a233316f9ec2805dd6a08fbf07f3a078a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+dictionary@{build\+\_\+dictionary}}
\index{build\+\_\+dictionary@{build\+\_\+dictionary}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+dictionary()}{build\_dictionary()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+dictionary (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return the constructed dictionary, which will be set to self.dict.

If you need to add additional tokens to the dictionary, this is likely the right
place to do it.
\end{DoxyVerb}
 

Definition at line 769 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
769     \textcolor{keyword}{def }build\_dictionary(self):
770         \textcolor{stringliteral}{"""}
771 \textcolor{stringliteral}{        Return the constructed dictionary, which will be set to self.dict.}
772 \textcolor{stringliteral}{}
773 \textcolor{stringliteral}{        If you need to add additional tokens to the dictionary, this is likely the right}
774 \textcolor{stringliteral}{        place to do it.}
775 \textcolor{stringliteral}{        """}
776         d = self.dictionary\_class()(self.opt)
777         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'person\_tokens'}):
778             d[self.P1\_TOKEN] = 999\_999\_999
779             d[self.P2\_TOKEN] = 999\_999\_998
780         \textcolor{keywordflow}{return} d
781 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab22f61f153b522f429210c61eed2d5af}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab22f61f153b522f429210c61eed2d5af}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+history@{build\+\_\+history}}
\index{build\+\_\+history@{build\+\_\+history}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+history()}{build\_history()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+history (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return the constructed history object.
\end{DoxyVerb}
 

Definition at line 756 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
756     \textcolor{keyword}{def }build\_history(self):
757         \textcolor{stringliteral}{"""}
758 \textcolor{stringliteral}{        Return the constructed history object.}
759 \textcolor{stringliteral}{        """}
760         \textcolor{keywordflow}{return} self.history\_class()(
761             self.opt,
762             maxlen=self.text\_truncate,
763             size=self.histsz,
764             p1\_token=self.P1\_TOKEN,
765             p2\_token=self.P2\_TOKEN,
766             dict\_agent=self.dict,
767         )
768 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa51ac42dc34e3d2281a01cba78a96151}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa51ac42dc34e3d2281a01cba78a96151}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+lr\+\_\+scheduler@{build\+\_\+lr\+\_\+scheduler}}
\index{build\+\_\+lr\+\_\+scheduler@{build\+\_\+lr\+\_\+scheduler}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+lr\+\_\+scheduler()}{build\_lr\_scheduler()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+lr\+\_\+scheduler (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{states = {\ttfamily None},  }\item[{}]{hard\+\_\+reset = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Create the learning rate scheduler, and assign it to self.scheduler.

This scheduler will be updated upon a call to receive_metrics.
May also create self.warmup_scheduler, if appropriate.

:param state_dict states: Possible state_dict provided by model
    checkpoint, for restoring LR state

:param bool hard_reset: If true, the LR scheduler should ignore the
    state dictionary.
\end{DoxyVerb}
 

Definition at line 912 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
912     \textcolor{keyword}{def }build\_lr\_scheduler(self, states=None, hard\_reset=False):
913         \textcolor{stringliteral}{"""}
914 \textcolor{stringliteral}{        Create the learning rate scheduler, and assign it to self.scheduler.}
915 \textcolor{stringliteral}{}
916 \textcolor{stringliteral}{        This scheduler will be updated upon a call to receive\_metrics.}
917 \textcolor{stringliteral}{        May also create self.warmup\_scheduler, if appropriate.}
918 \textcolor{stringliteral}{}
919 \textcolor{stringliteral}{        :param state\_dict states: Possible state\_dict provided by model}
920 \textcolor{stringliteral}{            checkpoint, for restoring LR state}
921 \textcolor{stringliteral}{}
922 \textcolor{stringliteral}{        :param bool hard\_reset: If true, the LR scheduler should ignore the}
923 \textcolor{stringliteral}{            state dictionary.}
924 \textcolor{stringliteral}{        """}
925         \textcolor{comment}{# first make sure there are no null pointers}
926         \textcolor{keywordflow}{if} states \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
927             states = \{\}
928         optimizer = self.optimizer
929         \textcolor{keywordflow}{if} self.fp16:
930             \textcolor{comment}{# lr schedulers don't work with apex, they expect the "real" optimizer}
931             optimizer = optimizer.optimizer
932 
933         warmup\_updates = self.opt.get(\textcolor{stringliteral}{'warmup\_updates'}, -1)
934         updates\_so\_far = states.get(\textcolor{stringliteral}{'number\_training\_updates'}, 0)
935         \textcolor{keywordflow}{if} warmup\_updates > 0 \textcolor{keywordflow}{and} (updates\_so\_far < warmup\_updates \textcolor{keywordflow}{or} hard\_reset):
936 
937             \textcolor{keyword}{def }\_warmup\_lr(step):
938                 start = self.opt[\textcolor{stringliteral}{'warmup\_rate'}]
939                 end = 1.0
940                 progress = min(1.0, step / self.opt[\textcolor{stringliteral}{'warmup\_updates'}])
941                 lr\_mult = start + (end - start) * progress
942                 \textcolor{keywordflow}{return} lr\_mult
943 
944             self.warmup\_scheduler = optim.lr\_scheduler.LambdaLR(optimizer, \_warmup\_lr)
945         \textcolor{keywordflow}{else}:
946             self.warmup\_scheduler = \textcolor{keywordtype}{None}
947 
948         patience = self.opt.get(\textcolor{stringliteral}{'lr\_scheduler\_patience'}, 3)
949         decay = self.opt.get(\textcolor{stringliteral}{'lr\_scheduler\_decay'}, 0.5)
950 
951         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'none'}:
952             self.scheduler = \textcolor{keywordtype}{None}
953         \textcolor{keywordflow}{elif} decay == 1.0:
954             \hyperlink{namespaceparlai_1_1utils_1_1misc_acf146e70ea7f6867969a7c2b545d4b4b}{warn\_once}(
955                 \textcolor{stringliteral}{"Your LR decay is set to 1.0. Assuming you meant you wanted "}
956                 \textcolor{stringliteral}{"to disable learning rate scheduling. Adjust --lr-scheduler-decay "}
957                 \textcolor{stringliteral}{"if this is not correct."}
958             )
959             self.scheduler = \textcolor{keywordtype}{None}
960         \textcolor{keywordflow}{elif} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'reduceonplateau'}:
961             self.scheduler = optim.lr\_scheduler.ReduceLROnPlateau(
962                 optimizer, \textcolor{stringliteral}{'min'}, factor=decay, patience=patience, verbose=\textcolor{keyword}{True}
963             )
964         \textcolor{keywordflow}{elif} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'fixed'}:
965             self.scheduler = optim.lr\_scheduler.StepLR(optimizer, patience, gamma=decay)
966         \textcolor{keywordflow}{elif} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'invsqrt'}:
967             \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'warmup\_updates'}, -1) <= 0:
968                 \textcolor{keywordflow}{raise} ValueError(
969                     \textcolor{stringliteral}{'--lr-scheduler invsqrt requires setting --warmup-updates'}
970                 )
971             warmup\_updates = self.opt[\textcolor{stringliteral}{'warmup\_updates'}]
972             decay\_factor = np.sqrt(max(1, warmup\_updates))
973 
974             \textcolor{keyword}{def }\_invsqrt\_lr(step):
975                 \textcolor{keywordflow}{return} decay\_factor / np.sqrt(max(1, step))
976 
977             self.scheduler = optim.lr\_scheduler.LambdaLR(optimizer, \_invsqrt\_lr)
978         \textcolor{keywordflow}{else}:
979             \textcolor{keywordflow}{raise} ValueError(
980                 \textcolor{stringliteral}{"Don't know what to do with lr\_scheduler '\{\}'"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(
981                     self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'})
982                 )
983             )
984 
985         \textcolor{comment}{# time to load LR state from the checkpoint, if possible.}
986         \textcolor{keywordflow}{if} (
987             \textcolor{comment}{# there is already an old LR scheduler saved on disk}
988             states
989             \textcolor{keywordflow}{and}
990             \textcolor{comment}{# and the old LR scheduler is different}
991             states.get(\textcolor{stringliteral}{'lr\_scheduler\_type'}) != self.opt[\textcolor{stringliteral}{'lr\_scheduler'}]
992             \textcolor{keywordflow}{and}
993             \textcolor{comment}{# and we're not already using a fresh scheduler}
994             \textcolor{keywordflow}{not} hard\_reset
995         ):
996             \textcolor{comment}{# the LR scheduler changed, start things fresh}
997             \hyperlink{namespaceparlai_1_1utils_1_1misc_acf146e70ea7f6867969a7c2b545d4b4b}{warn\_once}(\textcolor{stringliteral}{"LR scheduler is different from saved. Starting fresh!"})
998             hard\_reset = \textcolor{keyword}{True}
999 
1000         \textcolor{keywordflow}{if} hard\_reset:
1001             \textcolor{comment}{# We're not going to use the LR schedule, let's just exit}
1002             \textcolor{keywordflow}{return}
1003 
1004         \textcolor{comment}{# do the actual loading (if possible)}
1005         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'number\_training\_updates'} \textcolor{keywordflow}{in} states:
1006             self.\_number\_training\_updates = states[\textcolor{stringliteral}{'number\_training\_updates'}]
1007         \textcolor{keywordflow}{if} self.scheduler \textcolor{keywordflow}{and} \textcolor{stringliteral}{'lr\_scheduler'} \textcolor{keywordflow}{in} states:
1008             self.scheduler.load\_state\_dict(states[\textcolor{stringliteral}{'lr\_scheduler'}])
1009         \textcolor{keywordflow}{if} states.get(\textcolor{stringliteral}{'warmup\_scheduler'}) \textcolor{keywordflow}{and} getattr(self, \textcolor{stringliteral}{'warmup\_scheduler'}, \textcolor{keywordtype}{None}):
1010             self.warmup\_scheduler.load\_state\_dict(states[\textcolor{stringliteral}{'warmup\_scheduler'}])
1011 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9a21fa33fa5b2b928024fbc67826f233}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9a21fa33fa5b2b928024fbc67826f233}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!build\+\_\+model@{build\+\_\+model}}
\index{build\+\_\+model@{build\+\_\+model}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+model()}{build\_model()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+build\+\_\+model (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Construct the model and return it.
\end{DoxyVerb}
 

Definition at line 821 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
821     \textcolor{keyword}{def }build\_model(self):
822         \textcolor{stringliteral}{"""}
823 \textcolor{stringliteral}{        Construct the model and return it.}
824 \textcolor{stringliteral}{        """}
825         \textcolor{keywordflow}{raise} NotImplementedError(\textcolor{stringliteral}{'not implemented for this class'})
826 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aea8849fa69a3f5dbd3216c8b06f180ea}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aea8849fa69a3f5dbd3216c8b06f180ea}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!dictionary\+\_\+class@{dictionary\+\_\+class}}
\index{dictionary\+\_\+class@{dictionary\+\_\+class}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{dictionary\+\_\+class()}{dictionary\_class()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+dictionary\+\_\+class (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}

\begin{DoxyVerb}Return the dictionary class that this agent expects to use.

Can be overriden if a more complex dictionary is required.
\end{DoxyVerb}
 

Definition at line 389 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
389     \textcolor{keyword}{def }dictionary\_class():
390         \textcolor{stringliteral}{"""}
391 \textcolor{stringliteral}{        Return the dictionary class that this agent expects to use.}
392 \textcolor{stringliteral}{}
393 \textcolor{stringliteral}{        Can be overriden if a more complex dictionary is required.}
394 \textcolor{stringliteral}{        """}
395         \textcolor{keywordflow}{return} DictionaryAgent
396 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a18de0a52aeec4ef721aedbdd6ac06cad}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a18de0a52aeec4ef721aedbdd6ac06cad}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!eval\+\_\+step@{eval\+\_\+step}}
\index{eval\+\_\+step@{eval\+\_\+step}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{eval\+\_\+step()}{eval\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+eval\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}[Abstract] Process one batch but do not train on it.
\end{DoxyVerb}
 

Definition at line 1811 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1811     \textcolor{keyword}{def }eval\_step(self, batch):
1812         \textcolor{stringliteral}{"""}
1813 \textcolor{stringliteral}{        [Abstract] Process one batch but do not train on it.}
1814 \textcolor{stringliteral}{        """}
1815         \textcolor{keywordflow}{pass}
1816 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0bd9118252c602bb9d5a596ecae16717}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0bd9118252c602bb9d5a596ecae16717}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!history\+\_\+class@{history\+\_\+class}}
\index{history\+\_\+class@{history\+\_\+class}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{history\+\_\+class()}{history\_class()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+history\+\_\+class (\begin{DoxyParamCaption}\item[{}]{cls }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return the history class that this agent expects to use.

Can be overriden if a more complex history is required.
\end{DoxyVerb}
 

Definition at line 398 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
398     \textcolor{keyword}{def }history\_class(cls):
399         \textcolor{stringliteral}{"""}
400 \textcolor{stringliteral}{        Return the history class that this agent expects to use.}
401 \textcolor{stringliteral}{}
402 \textcolor{stringliteral}{        Can be overriden if a more complex history is required.}
403 \textcolor{stringliteral}{        """}
404         \textcolor{keywordflow}{return} History
405 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3784f1ddaa6ffad009716910f3f36dd4}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3784f1ddaa6ffad009716910f3f36dd4}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!init\+\_\+optim@{init\+\_\+optim}}
\index{init\+\_\+optim@{init\+\_\+optim}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{init\+\_\+optim()}{init\_optim()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+init\+\_\+optim (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{params,  }\item[{}]{optim\+\_\+states = {\ttfamily None},  }\item[{}]{saved\+\_\+optim\+\_\+type = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Initialize optimizer with model parameters.

:param params:
    parameters from the model

:param optim_states:
    optional argument providing states of optimizer to load

:param saved_optim_type:
    type of optimizer being loaded, if changed will skip loading
    optimizer states
\end{DoxyVerb}
 

Definition at line 827 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
827     \textcolor{keyword}{def }init\_optim(self, params, optim\_states=None, saved\_optim\_type=None):
828         \textcolor{stringliteral}{"""}
829 \textcolor{stringliteral}{        Initialize optimizer with model parameters.}
830 \textcolor{stringliteral}{}
831 \textcolor{stringliteral}{        :param params:}
832 \textcolor{stringliteral}{            parameters from the model}
833 \textcolor{stringliteral}{}
834 \textcolor{stringliteral}{        :param optim\_states:}
835 \textcolor{stringliteral}{            optional argument providing states of optimizer to load}
836 \textcolor{stringliteral}{}
837 \textcolor{stringliteral}{        :param saved\_optim\_type:}
838 \textcolor{stringliteral}{            type of optimizer being loaded, if changed will skip loading}
839 \textcolor{stringliteral}{            optimizer states}
840 \textcolor{stringliteral}{        """}
841         opt = self.opt
842 
843         \textcolor{comment}{# set up optimizer args}
844         lr = opt[\textcolor{stringliteral}{'learningrate'}]
845         kwargs = \{\textcolor{stringliteral}{'lr'}: lr\}
846         \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'weight\_decay'}):
847             kwargs[\textcolor{stringliteral}{'weight\_decay'}] = opt[\textcolor{stringliteral}{'weight\_decay'}]
848         \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'momentum'}) > 0 \textcolor{keywordflow}{and} opt[\textcolor{stringliteral}{'optimizer'}] \textcolor{keywordflow}{in} [\textcolor{stringliteral}{'sgd'}, \textcolor{stringliteral}{'rmsprop'}, \textcolor{stringliteral}{'qhm'}]:
849             \textcolor{comment}{# turn on momentum for optimizers that use it}
850             kwargs[\textcolor{stringliteral}{'momentum'}] = opt[\textcolor{stringliteral}{'momentum'}]
851             \textcolor{keywordflow}{if} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'sgd'} \textcolor{keywordflow}{and} opt.get(\textcolor{stringliteral}{'nesterov'}, \textcolor{keyword}{True}):
852                 \textcolor{comment}{# for sgd, maybe nesterov}
853                 kwargs[\textcolor{stringliteral}{'nesterov'}] = opt.get(\textcolor{stringliteral}{'nesterov'}, \textcolor{keyword}{True})
854             \textcolor{keywordflow}{elif} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'qhm'}:
855                 \textcolor{comment}{# qhm needs a nu}
856                 kwargs[\textcolor{stringliteral}{'nu'}] = opt.get(\textcolor{stringliteral}{'nus'}, (0.7,))[0]
857         \textcolor{keywordflow}{elif} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'adam'}:
858             \textcolor{comment}{# turn on amsgrad for adam}
859             \textcolor{comment}{# amsgrad paper: https://openreview.net/forum?id=ryQu7f-RZ}
860             kwargs[\textcolor{stringliteral}{'amsgrad'}] = \textcolor{keyword}{True}
861         \textcolor{keywordflow}{elif} opt[\textcolor{stringliteral}{'optimizer'}] == \textcolor{stringliteral}{'qhadam'}:
862             \textcolor{comment}{# set nus for qhadam}
863             kwargs[\textcolor{stringliteral}{'nus'}] = opt.get(\textcolor{stringliteral}{'nus'}, (0.7, 1.0))
864         \textcolor{keywordflow}{if} opt[\textcolor{stringliteral}{'optimizer'}] \textcolor{keywordflow}{in} [\textcolor{stringliteral}{'adam'}, \textcolor{stringliteral}{'sparseadam'}, \textcolor{stringliteral}{'fused\_adam'}, \textcolor{stringliteral}{'adamax'}, \textcolor{stringliteral}{'qhadam'}]:
865             \textcolor{comment}{# set betas for optims that use it}
866             kwargs[\textcolor{stringliteral}{'betas'}] = opt.get(\textcolor{stringliteral}{'betas'}, (0.9, 0.999))
867             \textcolor{comment}{# set adam optimizer, but only if user specified it}
868             \textcolor{keywordflow}{if} opt.get(\textcolor{stringliteral}{'adam\_eps'}):
869                 kwargs[\textcolor{stringliteral}{'eps'}] = opt[\textcolor{stringliteral}{'adam\_eps'}]
870 
871         optim\_class = self.optim\_opts()[opt[\textcolor{stringliteral}{'optimizer'}]]
872         self.optimizer = optim\_class(params, **kwargs)
873         \textcolor{keywordflow}{if} self.fp16:
874             self.optimizer = \hyperlink{namespaceparlai_1_1utils_1_1misc_a7836ac7469dc5744e0ad9e5e54da2396}{fp16\_optimizer\_wrapper}(self.optimizer)
875 
876         \textcolor{comment}{# TODO: we might want to hard reset optimizers here in the}
877         \textcolor{comment}{# case of fine tuning. Some rudimentary experiments seemed to}
878         \textcolor{comment}{# indicate that keeping adam weights around was desirable, so this}
879         \textcolor{comment}{# will remain the behavior for the time being.}
880         \textcolor{keywordflow}{if} optim\_states \textcolor{keywordflow}{and} saved\_optim\_type != opt[\textcolor{stringliteral}{'optimizer'}]:
881             \textcolor{comment}{# we changed from adam to adamax, or sgd to adam, or similar}
882             print(\textcolor{stringliteral}{'WARNING: not loading optim state since optim class changed.'})
883         \textcolor{keywordflow}{elif} optim\_states:
884             \textcolor{comment}{# check for any fp16/fp32 conversions we need to do}
885             optimstate\_fp16 = \textcolor{stringliteral}{'loss\_scaler'} \textcolor{keywordflow}{in} optim\_states
886             \textcolor{keywordflow}{if} self.fp16 \textcolor{keywordflow}{and} optimstate\_fp16:
887                 \textcolor{comment}{# previously trained in fp16, now we're training in fp16.}
888                 \textcolor{comment}{# ideally no action needed, but APEX broke backwards}
889                 \textcolor{comment}{# compatibility and this is the hack around it.}
890                 optim\_states[\textcolor{stringliteral}{'loss\_scaler'}] = self.optimizer.state\_dict()[\textcolor{stringliteral}{'loss\_scaler'}]
891             \textcolor{keywordflow}{elif} optimstate\_fp16 \textcolor{keywordflow}{and} \textcolor{keywordflow}{not} self.fp16:
892                 \textcolor{comment}{# old optimizer was fp16 but now we're doing fp32,}
893                 \textcolor{comment}{# drop the fp16 wrapper from the state\_dict and just load}
894                 \textcolor{comment}{# the fp16 weights into the fp32 tensors}
895                 optim\_states = optim\_states[\textcolor{stringliteral}{'optimizer\_state\_dict'}]
896             \textcolor{keywordflow}{elif} \textcolor{keywordflow}{not} optimstate\_fp16 \textcolor{keywordflow}{and} self.fp16:
897                 \textcolor{comment}{# old optimizer was fp32, but now we're doing fp16.}
898                 \textcolor{comment}{# this is a bit clunky, but alternatives are worse}
899                 self.optimizer.optimizer.load\_state\_dict(optim\_states)
900                 \textcolor{keywordflow}{return}
901             \textcolor{keywordflow}{else}:
902                 \textcolor{comment}{# previously trained in fp32, loading in fp32.}
903                 \textcolor{comment}{# no special treatment needed.}
904                 \textcolor{keywordflow}{pass}
905 
906             \textcolor{comment}{# finally, try to actually load the optimizer state}
907             \textcolor{keywordflow}{try}:
908                 self.optimizer.load\_state\_dict(optim\_states)
909             \textcolor{keywordflow}{except} ValueError:
910                 print(\textcolor{stringliteral}{'WARNING: not loading optim state since model params changed.'})
911 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afa491bf2384b017711ad722b5341b405}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afa491bf2384b017711ad722b5341b405}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!is\+\_\+valid@{is\+\_\+valid}}
\index{is\+\_\+valid@{is\+\_\+valid}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{is\+\_\+valid()}{is\_valid()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+is\+\_\+valid (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{obs }\end{DoxyParamCaption})}

\begin{DoxyVerb}Determine if an observation is valid or not.
\end{DoxyVerb}
 

Definition at line 1441 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1441     \textcolor{keyword}{def }is\_valid(self, obs):
1442         \textcolor{stringliteral}{"""}
1443 \textcolor{stringliteral}{        Determine if an observation is valid or not.}
1444 \textcolor{stringliteral}{        """}
1445         \textcolor{keywordflow}{return} \textcolor{stringliteral}{'text\_vec'} \textcolor{keywordflow}{in} obs \textcolor{keywordflow}{or} \textcolor{stringliteral}{'image'} \textcolor{keywordflow}{in} obs
1446 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a32921aa09a682ee752d4822a5f5ebbb4}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a32921aa09a682ee752d4822a5f5ebbb4}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!last\+\_\+reply@{last\+\_\+reply}}
\index{last\+\_\+reply@{last\+\_\+reply}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{last\+\_\+reply()}{last\_reply()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+last\+\_\+reply (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{use\+\_\+reply = {\ttfamily \textquotesingle{}label\textquotesingle{}} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Retrieve the last reply from the model.

If available, we use the true label instead of the model's prediction.

By default, batch_act stores the batch of replies and this method
will extract the reply of the current instance from the batch.

:param use_label:
    default true, use the label when available instead of the model's
    generated response.
\end{DoxyVerb}
 

Definition at line 1584 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1584     \textcolor{keyword}{def }last\_reply(self, use\_reply='label'):
1585         \textcolor{stringliteral}{"""}
1586 \textcolor{stringliteral}{        Retrieve the last reply from the model.}
1587 \textcolor{stringliteral}{}
1588 \textcolor{stringliteral}{        If available, we use the true label instead of the model's prediction.}
1589 \textcolor{stringliteral}{}
1590 \textcolor{stringliteral}{        By default, batch\_act stores the batch of replies and this method}
1591 \textcolor{stringliteral}{        will extract the reply of the current instance from the batch.}
1592 \textcolor{stringliteral}{}
1593 \textcolor{stringliteral}{        :param use\_label:}
1594 \textcolor{stringliteral}{            default true, use the label when available instead of the model's}
1595 \textcolor{stringliteral}{            generated response.}
1596 \textcolor{stringliteral}{        """}
1597         \textcolor{comment}{# if the last observation was the end of an episode,}
1598         \textcolor{comment}{# then we shouldn't use it as history}
1599         \textcolor{keywordflow}{if} (
1600             use\_reply == \textcolor{stringliteral}{'none'}
1601             \textcolor{keywordflow}{or} \textcolor{keywordflow}{not} self.observation
1602             \textcolor{keywordflow}{or} self.observation[\textcolor{stringliteral}{'episode\_done'}]
1603         ):
1604             \textcolor{keywordflow}{return} \textcolor{keywordtype}{None}
1605 
1606         \textcolor{keywordflow}{if} use\_reply == \textcolor{stringliteral}{'label'}:
1607             \textcolor{comment}{# first look for the true label, if we aren't on a new episode}
1608             label\_key = (
1609                 \textcolor{stringliteral}{'labels'}
1610                 \textcolor{keywordflow}{if} \textcolor{stringliteral}{'labels'} \textcolor{keywordflow}{in} self.observation
1611                 \textcolor{keywordflow}{else} \textcolor{stringliteral}{'eval\_labels'}
1612                 \textcolor{keywordflow}{if} \textcolor{stringliteral}{'eval\_labels'} \textcolor{keywordflow}{in} self.observation
1613                 \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
1614             )
1615             \textcolor{keywordflow}{if} label\_key \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
1616                 lbls = self.observation[label\_key]
1617                 last\_reply = lbls[0] \textcolor{keywordflow}{if} len(lbls) == 1 \textcolor{keywordflow}{else} self.random.choice(lbls)
1618                 \textcolor{keywordflow}{return} last\_reply
1619 
1620         \textcolor{comment}{# otherwise, we use the last reply the model generated}
1621         batch\_reply = self.replies.get(\textcolor{stringliteral}{'batch\_reply'})
1622         \textcolor{keywordflow}{if} batch\_reply \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
1623             \textcolor{keywordflow}{return} batch\_reply[self.batch\_idx].get(\textcolor{stringliteral}{'text'})
1624         \textcolor{keywordflow}{return} \textcolor{keywordtype}{None}
1625 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_af626fc7d32fc9b0dfeec167a52353baf}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_af626fc7d32fc9b0dfeec167a52353baf}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!load@{load}}
\index{load@{load}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{load()}{load()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+load (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{path }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return opt and model states.

Override this method for more specific loading.
\end{DoxyVerb}
 

Definition at line 1720 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1720     \textcolor{keyword}{def }load(self, path):
1721         \textcolor{stringliteral}{"""}
1722 \textcolor{stringliteral}{        Return opt and model states.}
1723 \textcolor{stringliteral}{}
1724 \textcolor{stringliteral}{        Override this method for more specific loading.}
1725 \textcolor{stringliteral}{        """}
1726         states = torch.load(path, map\_location=\textcolor{keyword}{lambda} cpu, \_: cpu)
1727         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'model'} \textcolor{keywordflow}{in} states:
1728             self.load\_state\_dict(states[\textcolor{stringliteral}{'model'}])
1729         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'optimizer'} \textcolor{keywordflow}{in} states \textcolor{keywordflow}{and} hasattr(self, \textcolor{stringliteral}{'optimizer'}):
1730             self.optimizer.load\_state\_dict(states[\textcolor{stringliteral}{'optimizer'}])
1731         \textcolor{keywordflow}{return} states
1732 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dcfca62a677f8de97f09ce993258f84}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dcfca62a677f8de97f09ce993258f84}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!load\+\_\+state\+\_\+dict@{load\+\_\+state\+\_\+dict}}
\index{load\+\_\+state\+\_\+dict@{load\+\_\+state\+\_\+dict}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{load\+\_\+state\+\_\+dict()}{load\_state\_dict()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+load\+\_\+state\+\_\+dict (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{state\+\_\+dict }\end{DoxyParamCaption})}

\begin{DoxyVerb}Load the state dict into model.

This is easily overridable to facilitate transfer of state dicts.
\end{DoxyVerb}
 

Definition at line 1712 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1712     \textcolor{keyword}{def }load\_state\_dict(self, state\_dict):
1713         \textcolor{stringliteral}{"""}
1714 \textcolor{stringliteral}{        Load the state dict into model.}
1715 \textcolor{stringliteral}{}
1716 \textcolor{stringliteral}{        This is easily overridable to facilitate transfer of state dicts.}
1717 \textcolor{stringliteral}{        """}
1718         self.model.load\_state\_dict(state\_dict)
1719 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aba56b961d929e5c5b5da9cf8bd331502}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aba56b961d929e5c5b5da9cf8bd331502}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!match\+\_\+batch@{match\+\_\+batch}}
\index{match\+\_\+batch@{match\+\_\+batch}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{match\+\_\+batch()}{match\_batch()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+match\+\_\+batch (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch\+\_\+reply,  }\item[{}]{valid\+\_\+inds,  }\item[{}]{output = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Match sub-batch of predictions to the original batch indices.

Batches may be only partially filled (i.e when completing the remainder
at the end of the validation or test set), or we may want to sort by
e.g the length of the input sequences if using pack_padded_sequence.

This matches rows back with their original row in the batch for
calculating metrics like accuracy.

If output is None (model choosing not to provide any predictions), we
will just return the batch of replies.

Otherwise, output should be a parlai.core.torch_agent.Output object.
This is a namedtuple, which can provide text predictions and/or
text_candidates predictions. If you would like to map additional
fields into the batch_reply, you can override this method as well as
providing your own namedtuple with additional fields.

:param batch_reply:
    Full-batchsize list of message dictionaries to put responses into.

:param valid_inds:
    Original indices of the predictions.

:param output:
    Output namedtuple which contains sub-batchsize list of text outputs
    from model. May be None (default) if model chooses not to answer.
    This method will check for ``text`` and ``text_candidates`` fields.
\end{DoxyVerb}
 

Definition at line 1544 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1544     \textcolor{keyword}{def }match\_batch(self, batch\_reply, valid\_inds, output=None):
1545         \textcolor{stringliteral}{"""}
1546 \textcolor{stringliteral}{        Match sub-batch of predictions to the original batch indices.}
1547 \textcolor{stringliteral}{}
1548 \textcolor{stringliteral}{        Batches may be only partially filled (i.e when completing the remainder}
1549 \textcolor{stringliteral}{        at the end of the validation or test set), or we may want to sort by}
1550 \textcolor{stringliteral}{        e.g the length of the input sequences if using pack\_padded\_sequence.}
1551 \textcolor{stringliteral}{}
1552 \textcolor{stringliteral}{        This matches rows back with their original row in the batch for}
1553 \textcolor{stringliteral}{        calculating metrics like accuracy.}
1554 \textcolor{stringliteral}{}
1555 \textcolor{stringliteral}{        If output is None (model choosing not to provide any predictions), we}
1556 \textcolor{stringliteral}{        will just return the batch of replies.}
1557 \textcolor{stringliteral}{}
1558 \textcolor{stringliteral}{        Otherwise, output should be a parlai.core.torch\_agent.Output object.}
1559 \textcolor{stringliteral}{        This is a namedtuple, which can provide text predictions and/or}
1560 \textcolor{stringliteral}{        text\_candidates predictions. If you would like to map additional}
1561 \textcolor{stringliteral}{        fields into the batch\_reply, you can override this method as well as}
1562 \textcolor{stringliteral}{        providing your own namedtuple with additional fields.}
1563 \textcolor{stringliteral}{}
1564 \textcolor{stringliteral}{        :param batch\_reply:}
1565 \textcolor{stringliteral}{            Full-batchsize list of message dictionaries to put responses into.}
1566 \textcolor{stringliteral}{}
1567 \textcolor{stringliteral}{        :param valid\_inds:}
1568 \textcolor{stringliteral}{            Original indices of the predictions.}
1569 \textcolor{stringliteral}{}
1570 \textcolor{stringliteral}{        :param output:}
1571 \textcolor{stringliteral}{            Output namedtuple which contains sub-batchsize list of text outputs}
1572 \textcolor{stringliteral}{            from model. May be None (default) if model chooses not to answer.}
1573 \textcolor{stringliteral}{            This method will check for ``text`` and ``text\_candidates`` fields.}
1574 \textcolor{stringliteral}{        """}
1575         \textcolor{keywordflow}{if} output \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1576             \textcolor{keywordflow}{return} batch\_reply
1577         \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} output.items():
1578             \textcolor{keywordflow}{if} v \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1579                 \textcolor{keywordflow}{continue}
1580             \textcolor{keywordflow}{for} i, sub\_val \textcolor{keywordflow}{in} zip(valid\_inds, v):
1581                 batch\_reply[i][k] = sub\_val
1582         \textcolor{keywordflow}{return} batch\_reply
1583 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a87b18f0d6ab11be3c49375af072d0d33}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a87b18f0d6ab11be3c49375af072d0d33}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!observe@{observe}}
\index{observe@{observe}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{observe()}{observe()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+observe (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{observation }\end{DoxyParamCaption})}

\begin{DoxyVerb}Process incoming message in preparation for producing a response.

This includes remembering the past history of the conversation.
\end{DoxyVerb}
 

Definition at line 1626 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1626     \textcolor{keyword}{def }observe(self, observation):
1627         \textcolor{stringliteral}{"""}
1628 \textcolor{stringliteral}{        Process incoming message in preparation for producing a response.}
1629 \textcolor{stringliteral}{}
1630 \textcolor{stringliteral}{        This includes remembering the past history of the conversation.}
1631 \textcolor{stringliteral}{        """}
1632         \textcolor{comment}{# TODO: Migration plan: TorchAgent currently supports being passed}
1633         \textcolor{comment}{# observations as vanilla dicts for legacy interop; eventually we}
1634         \textcolor{comment}{# want to remove this behavior and demand that teachers return Messages}
1635         observation = Message(observation)
1636         reply = self.last\_reply(use\_reply=self.opt.get(\textcolor{stringliteral}{'use\_reply'}, \textcolor{stringliteral}{'label'}))
1637         \textcolor{comment}{# update the history using the observation}
1638         self.history.update\_history(observation, add\_next=reply)
1639         self.observation = observation
1640         \textcolor{keywordflow}{return} self.vectorize(
1641             self.observation,
1642             self.history,
1643             text\_truncate=self.text\_truncate,
1644             label\_truncate=self.label\_truncate,
1645         )
1646 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9c622b8ed5a811841f30fe98cc297cde}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9c622b8ed5a811841f30fe98cc297cde}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!optim\+\_\+opts@{optim\+\_\+opts}}
\index{optim\+\_\+opts@{optim\+\_\+opts}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{optim\+\_\+opts()}{optim\_opts()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+optim\+\_\+opts (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Fetch optimizer selection.

By default, collects everything in torch.optim, as well as importing:
- qhm / qhmadam if installed from github.com/facebookresearch/qhoptim

Override this (and probably call super()) to add your own optimizers.
\end{DoxyVerb}
 

Definition at line 354 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
354     \textcolor{keyword}{def }optim\_opts(self):
355         \textcolor{stringliteral}{"""}
356 \textcolor{stringliteral}{        Fetch optimizer selection.}
357 \textcolor{stringliteral}{}
358 \textcolor{stringliteral}{        By default, collects everything in torch.optim, as well as importing:}
359 \textcolor{stringliteral}{        - qhm / qhmadam if installed from github.com/facebookresearch/qhoptim}
360 \textcolor{stringliteral}{}
361 \textcolor{stringliteral}{        Override this (and probably call super()) to add your own optimizers.}
362 \textcolor{stringliteral}{        """}
363         \textcolor{comment}{# first pull torch.optim in}
364         optims = \{
365             k.lower(): v
366             \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} optim.\_\_dict\_\_.items()
367             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} k.startswith(\textcolor{stringliteral}{'\_\_'}) \textcolor{keywordflow}{and} k[0].isupper()
368         \}
369         \textcolor{keywordflow}{try}:
370             \textcolor{keyword}{import} apex.optimizers.fused\_adam \textcolor{keyword}{as} fused\_adam
371 
372             optims[\textcolor{stringliteral}{'fused\_adam'}] = fused\_adam.FusedAdam
373         \textcolor{keywordflow}{except} ImportError:
374             \textcolor{keywordflow}{pass}
375 
376         \textcolor{keywordflow}{try}:
377             \textcolor{comment}{# https://openreview.net/pdf?id=S1fUpoR5FQ}
378             \textcolor{keyword}{from} qhoptim.pyt \textcolor{keyword}{import} QHM, QHAdam
379 
380             optims[\textcolor{stringliteral}{'qhm'}] = QHM
381             optims[\textcolor{stringliteral}{'qhadam'}] = QHAdam
382         \textcolor{keywordflow}{except} ImportError:
383             \textcolor{comment}{# no QHM installed}
384             \textcolor{keywordflow}{pass}
385 
386         \textcolor{keywordflow}{return} optims
387 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a02beaaedfa30463f9d0a97ea590b516f}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a02beaaedfa30463f9d0a97ea590b516f}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!receive\+\_\+metrics@{receive\+\_\+metrics}}
\index{receive\+\_\+metrics@{receive\+\_\+metrics}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{receive\+\_\+metrics()}{receive\_metrics()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+receive\+\_\+metrics (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{metrics\+\_\+dict }\end{DoxyParamCaption})}

\begin{DoxyVerb}Use the metrics to decide when to adjust LR schedule.

This uses the loss as the validation metric if present, if not this
function does nothing. Note that the model must be reporting loss for
this to work.

Override this to override the behavior.
\end{DoxyVerb}
 

Definition at line 1072 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1072     \textcolor{keyword}{def }receive\_metrics(self, metrics\_dict):
1073         \textcolor{stringliteral}{"""}
1074 \textcolor{stringliteral}{        Use the metrics to decide when to adjust LR schedule.}
1075 \textcolor{stringliteral}{}
1076 \textcolor{stringliteral}{        This uses the loss as the validation metric if present, if not this}
1077 \textcolor{stringliteral}{        function does nothing. Note that the model must be reporting loss for}
1078 \textcolor{stringliteral}{        this to work.}
1079 \textcolor{stringliteral}{}
1080 \textcolor{stringliteral}{        Override this to override the behavior.}
1081 \textcolor{stringliteral}{        """}
1082         \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} hasattr(self, \textcolor{stringliteral}{'scheduler'}) \textcolor{keywordflow}{or} self.scheduler \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
1083             \textcolor{keywordflow}{return}
1084 
1085         \textcolor{keywordflow}{if} self.\_is\_lr\_warming\_up():
1086             \textcolor{comment}{# we're not done warming up, so don't start using validation}
1087             \textcolor{comment}{# metrics to adjust schedule}
1088             \textcolor{keywordflow}{return}
1089 
1090         \textcolor{keywordflow}{if} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'none'}:
1091             \textcolor{comment}{# no scheduler, nothing to adjust here}
1092             \textcolor{keywordflow}{pass}
1093         \textcolor{keywordflow}{elif} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'reduceonplateau'}:
1094             \textcolor{keywordflow}{if} \textcolor{stringliteral}{'loss'} \textcolor{keywordflow}{not} \textcolor{keywordflow}{in} metrics\_dict:
1095                 \textcolor{comment}{# nothing to step on, just skip}
1096                 \hyperlink{namespaceparlai_1_1utils_1_1misc_acf146e70ea7f6867969a7c2b545d4b4b}{warn\_once}(\textcolor{stringliteral}{"LR scheduler expected to see loss metric, but didn't."})
1097                 \textcolor{keywordflow}{return}
1098             self.scheduler.step(metrics\_dict[\textcolor{stringliteral}{'loss'}])
1099         \textcolor{keywordflow}{elif} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'fixed'}:
1100             self.scheduler.step()
1101         \textcolor{keywordflow}{elif} self.opt[\textcolor{stringliteral}{'lr\_scheduler'}] == \textcolor{stringliteral}{'invsqrt'}:
1102             \textcolor{comment}{# this is a training step lr scheduler, nothing to adjust in validation}
1103             \textcolor{keywordflow}{pass}
1104         \textcolor{keywordflow}{else}:
1105             \textcolor{keywordflow}{raise} ValueError(
1106                 \textcolor{stringliteral}{"Don't know how to work with lr scheduler '\{\}'"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(
1107                     self.opt[\textcolor{stringliteral}{'lr\_scheduler'}]
1108                 )
1109             )
1110 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac694770cd4022eb047bf6fbb8f46035c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac694770cd4022eb047bf6fbb8f46035c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!report@{report}}
\index{report@{report}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{report()}{report()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+report (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Report metrics.

Report includes learning rate and number of training updates.
\end{DoxyVerb}
 

Definition at line 1012 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1012     \textcolor{keyword}{def }\hyperlink{namespaceprojects_1_1convai2_1_1eval__f1_a01a47b9c08dad189837a51f085defc45}{report}(self):
1013         \textcolor{stringliteral}{"""}
1014 \textcolor{stringliteral}{        Report metrics.}
1015 \textcolor{stringliteral}{}
1016 \textcolor{stringliteral}{        Report includes learning rate and number of training updates.}
1017 \textcolor{stringliteral}{        """}
1018         metrics = \{\}
1019         \textcolor{comment}{# only report LR if we have a scheduler}
1020         \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'scheduler'}) \textcolor{keywordflow}{and} self.scheduler \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
1021             current\_lr = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.optimizer.param\_groups[0][\textcolor{stringliteral}{'lr'}], 4)
1022             metrics[\textcolor{stringliteral}{'lr'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(current\_lr, 4)
1023         metrics[\textcolor{stringliteral}{'total\_train\_updates'}] = self.\_number\_training\_updates
1024 
1025         steps = self.metrics[\textcolor{stringliteral}{'updates'}]
1026         \textcolor{keywordflow}{if} steps > 0 \textcolor{keywordflow}{and} self.opt.get(\textcolor{stringliteral}{'gradient\_clip'}, -1) > 0:
1027             metrics[\textcolor{stringliteral}{'gnorm'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.metrics[\textcolor{stringliteral}{'gnorm'}] / steps, 4)
1028             metrics[\textcolor{stringliteral}{'clip'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.metrics[\textcolor{stringliteral}{'clip'}] / steps, 2)
1029 
1030         \textcolor{keywordflow}{if} self.use\_cuda:
1031             metrics[\textcolor{stringliteral}{'gpu\_mem\_percent'}] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(self.\_gpu\_usage(), sigfigs=3)
1032 
1033         \textcolor{keywordflow}{return} metrics
1034 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6f568650dd8e245a274671680ebb7587}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6f568650dd8e245a274671680ebb7587}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!reset@{reset}}
\index{reset@{reset}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{reset()}{reset()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+reset (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Clear internal states.
\end{DoxyVerb}
 

Definition at line 1733 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1733     \textcolor{keyword}{def }reset(self):
1734         \textcolor{stringliteral}{"""}
1735 \textcolor{stringliteral}{        Clear internal states.}
1736 \textcolor{stringliteral}{        """}
1737         self.observation = \{\}
1738         self.history.reset()
1739         self.replies.clear()
1740         self.reset\_metrics()
1741 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a03e18955cfd44dd019d0847bc7a46893}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a03e18955cfd44dd019d0847bc7a46893}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!reset\+\_\+metrics@{reset\+\_\+metrics}}
\index{reset\+\_\+metrics@{reset\+\_\+metrics}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{reset\+\_\+metrics()}{reset\_metrics()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+reset\+\_\+metrics (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reset all TorchAgentMetrics.
\end{DoxyVerb}
 

Definition at line 1742 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1742     \textcolor{keyword}{def }reset\_metrics(self):
1743         \textcolor{stringliteral}{"""}
1744 \textcolor{stringliteral}{        Reset all TorchAgentMetrics.}
1745 \textcolor{stringliteral}{        """}
1746         super().reset\_metrics()
1747         self.metrics[\textcolor{stringliteral}{'gnorm'}] = 0.0
1748         self.metrics[\textcolor{stringliteral}{'clip'}] = 0.0
1749         self.metrics[\textcolor{stringliteral}{'updates'}] = 0
1750 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adac7ee3db855786e8414e9f35fcb6e46}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adac7ee3db855786e8414e9f35fcb6e46}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!save@{save}}
\index{save@{save}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{save()}{save()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+save (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{path = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Save model parameters to path (or default to model_file arg).

Please try to refrain from overriding this function, and instead override
`state_dict(self)` for more specific saving.
\end{DoxyVerb}
 

Definition at line 1681 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1681     \textcolor{keyword}{def }save(self, path=None):
1682         \textcolor{stringliteral}{"""}
1683 \textcolor{stringliteral}{        Save model parameters to path (or default to model\_file arg).}
1684 \textcolor{stringliteral}{}
1685 \textcolor{stringliteral}{        Please try to refrain from overriding this function, and instead override}
1686 \textcolor{stringliteral}{        `state\_dict(self)` for more specific saving.}
1687 \textcolor{stringliteral}{        """}
1688         path = self.opt.get(\textcolor{stringliteral}{'model\_file'}, \textcolor{keywordtype}{None}) \textcolor{keywordflow}{if} path \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} path
1689 
1690         \textcolor{keywordflow}{if} path:
1691             \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'dict'}):  \textcolor{comment}{# force save dictionary}
1692                 \textcolor{comment}{# TODO: Look into possibly overriding opt('dict\_file') with new path}
1693                 self.dict.save(path + \textcolor{stringliteral}{'.dict'}, sort=\textcolor{keyword}{False})
1694             states = self.state\_dict()
1695             \textcolor{keywordflow}{if} states:  \textcolor{comment}{# anything found to save?}
1696                 with open(path, \textcolor{stringliteral}{'wb'}) \textcolor{keyword}{as} write:
1697                     torch.save(states, write)
1698 
1699                 \textcolor{comment}{# save opt file}
1700                 with open(path + \textcolor{stringliteral}{'.opt'}, \textcolor{stringliteral}{'w'}, encoding=\textcolor{stringliteral}{'utf-8'}) \textcolor{keyword}{as} handle:
1701                     \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'model\_version'}):
1702                         self.opt[\textcolor{stringliteral}{'model\_version'}] = self.model\_version()
1703                     saved\_opts = deepcopy(self.opt)
1704                     \textcolor{keywordflow}{if} \textcolor{stringliteral}{'interactive\_mode'} \textcolor{keywordflow}{in} saved\_opts:
1705                         \textcolor{comment}{# We do not save the state of interactive mode, it is only decided}
1706                         \textcolor{comment}{# by scripts or command line.}
1707                         del saved\_opts[\textcolor{stringliteral}{'interactive\_mode'}]
1708                     json.dump(saved\_opts, handle)
1709                     \textcolor{comment}{# for convenience of working with jq, make sure there's a newline}
1710                     handle.write(\textcolor{stringliteral}{'\(\backslash\)n'})
1711 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6a7aff29231816a0f3cade9c72409dfc}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6a7aff29231816a0f3cade9c72409dfc}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}}
\index{set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{set\+\_\+interactive\+\_\+mode()}{set\_interactive\_mode()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+set\+\_\+interactive\+\_\+mode (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{mode,  }\item[{}]{shared }\end{DoxyParamCaption})}

\begin{DoxyVerb}Set interactive mode on or off.
\end{DoxyVerb}
 

Definition at line 1817 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1817     \textcolor{keyword}{def }set\_interactive\_mode(self, mode, shared):
1818         \textcolor{stringliteral}{"""}
1819 \textcolor{stringliteral}{        Set interactive mode on or off.}
1820 \textcolor{stringliteral}{        """}
1821         \textcolor{keywordflow}{if} shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{and} mode:
1822             \textcolor{comment}{# Only print in the non-shared version.}
1823             print(\textcolor{stringliteral}{"["} + self.id + \textcolor{stringliteral}{': full interactive mode on.'} + \textcolor{stringliteral}{']'})
1824 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a373f0e276bf7c9d914a4e3363e9c2712}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a373f0e276bf7c9d914a4e3363e9c2712}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!share@{share}}
\index{share@{share}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{share()}{share()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+share (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Share fields from parent as well as useful objects in this class.

Subclasses will likely want to share their model as well.
\end{DoxyVerb}
 

Definition at line 1212 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1212     \textcolor{keyword}{def }share(self):
1213         \textcolor{stringliteral}{"""}
1214 \textcolor{stringliteral}{        Share fields from parent as well as useful objects in this class.}
1215 \textcolor{stringliteral}{}
1216 \textcolor{stringliteral}{        Subclasses will likely want to share their model as well.}
1217 \textcolor{stringliteral}{        """}
1218         shared = super().share()
1219 
1220         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1 \textcolor{keywordflow}{and} isinstance(self.metrics, dict):
1221             \textcolor{comment}{# move metrics and model to shared memory}
1222             self.metrics = SharedTable(self.metrics)
1223             self.model.share\_memory()
1224         shared[\textcolor{stringliteral}{'metrics'}] = self.metrics
1225 
1226         shared[\textcolor{stringliteral}{'dict'}] = self.dict
1227         shared[\textcolor{stringliteral}{'model'}] = self.model
1228         shared[\textcolor{stringliteral}{'criterion'}] = self.criterion
1229         shared[\textcolor{stringliteral}{'opt'}] = self.opt
1230         shared[\textcolor{stringliteral}{'replies'}] = self.replies
1231         \textcolor{keywordflow}{return} shared
1232 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9f89e606931a4622a5c6a6f6b832235c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!state\+\_\+dict@{state\+\_\+dict}}
\index{state\+\_\+dict@{state\+\_\+dict}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{state\+\_\+dict()}{state\_dict()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+state\+\_\+dict (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Get the state dict for saving.

Override this method for more specific saving.
\end{DoxyVerb}
 

Definition at line 1647 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1647     \textcolor{keyword}{def }state\_dict(self):
1648         \textcolor{stringliteral}{"""}
1649 \textcolor{stringliteral}{        Get the state dict for saving.}
1650 \textcolor{stringliteral}{}
1651 \textcolor{stringliteral}{        Override this method for more specific saving.}
1652 \textcolor{stringliteral}{        """}
1653         states = \{\}
1654         \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'model'}):  \textcolor{comment}{# save model params}
1655             \textcolor{keywordflow}{if} hasattr(self.model, \textcolor{stringliteral}{'module'}):
1656                 \textcolor{comment}{# did we wrap in a DistributedDataParallel}
1657                 states[\textcolor{stringliteral}{'model'}] = self.model.module.state\_dict()
1658             \textcolor{keywordflow}{else}:
1659                 states[\textcolor{stringliteral}{'model'}] = self.model.state\_dict()
1660 
1661         \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'optimizer'}):
1662             \textcolor{comment}{# save optimizer params}
1663             states[\textcolor{stringliteral}{'optimizer'}] = self.optimizer.state\_dict()
1664             states[\textcolor{stringliteral}{'optimizer\_type'}] = self.opt[\textcolor{stringliteral}{'optimizer'}]
1665 
1666         \textcolor{comment}{# lr scheduler}
1667         \textcolor{keywordflow}{if} torch.\_\_version\_\_.startswith(\textcolor{stringliteral}{'0.'}):
1668             \hyperlink{namespaceparlai_1_1utils_1_1misc_acf146e70ea7f6867969a7c2b545d4b4b}{warn\_once}(
1669                 \textcolor{stringliteral}{"Must upgrade to Pytorch 1.0 to save the state of your "} \textcolor{stringliteral}{"LR scheduler."}
1670             )
1671         \textcolor{keywordflow}{else}:
1672             states[\textcolor{stringliteral}{'number\_training\_updates'}] = self.\_number\_training\_updates
1673             \textcolor{keywordflow}{if} getattr(self, \textcolor{stringliteral}{'scheduler'}, \textcolor{keywordtype}{None}):
1674                 states[\textcolor{stringliteral}{'lr\_scheduler'}] = self.scheduler.state\_dict()
1675                 states[\textcolor{stringliteral}{'lr\_scheduler\_type'}] = self.opt[\textcolor{stringliteral}{'lr\_scheduler'}]
1676             \textcolor{keywordflow}{if} getattr(self, \textcolor{stringliteral}{'warmup\_scheduler'}, \textcolor{keywordtype}{None}):
1677                 states[\textcolor{stringliteral}{'warmup\_scheduler'}] = self.warmup\_scheduler.state\_dict()
1678 
1679         \textcolor{keywordflow}{return} states
1680 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8ba9d535736c0af100d00c5e7b02b61b}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a8ba9d535736c0af100d00c5e7b02b61b}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!train\+\_\+step@{train\+\_\+step}}
\index{train\+\_\+step@{train\+\_\+step}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{train\+\_\+step()}{train\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+train\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}[Abstract] Process one batch with training labels.
\end{DoxyVerb}
 

Definition at line 1804 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1804     \textcolor{keyword}{def }train\_step(self, batch):
1805         \textcolor{stringliteral}{"""}
1806 \textcolor{stringliteral}{        [Abstract] Process one batch with training labels.}
1807 \textcolor{stringliteral}{        """}
1808         \textcolor{keywordflow}{pass}
1809 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7e2c9e180887397daa6229a0f9700b1c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a7e2c9e180887397daa6229a0f9700b1c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!update\+\_\+params@{update\+\_\+params}}
\index{update\+\_\+params@{update\+\_\+params}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{update\+\_\+params()}{update\_params()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+update\+\_\+params (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Perform step of optimization.

Handles clipping gradients and adjusting LR schedule if needed.
Gradient accumulation is also performed if agent is called with
--update-freq.

It is recommended (but not forced) that you call this in train_step.
\end{DoxyVerb}
 

Definition at line 1841 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1841     \textcolor{keyword}{def }update\_params(self):
1842         \textcolor{stringliteral}{"""}
1843 \textcolor{stringliteral}{        Perform step of optimization.}
1844 \textcolor{stringliteral}{}
1845 \textcolor{stringliteral}{        Handles clipping gradients and adjusting LR schedule if needed.}
1846 \textcolor{stringliteral}{        Gradient accumulation is also performed if agent is called with}
1847 \textcolor{stringliteral}{        --update-freq.}
1848 \textcolor{stringliteral}{}
1849 \textcolor{stringliteral}{        It is recommended (but not forced) that you call this in train\_step.}
1850 \textcolor{stringliteral}{        """}
1851         update\_freq = self.opt.get(\textcolor{stringliteral}{'update\_freq'}, 1)
1852         \textcolor{keywordflow}{if} update\_freq > 1:
1853             \textcolor{comment}{# we're doing gradient accumulation, so we don't only want to step}
1854             \textcolor{comment}{# every N updates instead}
1855             self.\_number\_grad\_accum = (self.\_number\_grad\_accum + 1) % update\_freq
1856             \textcolor{keywordflow}{if} self.\_number\_grad\_accum != 0:
1857                 \textcolor{keywordflow}{return}
1858 
1859         \textcolor{keywordflow}{if} self.fp16:
1860             \textcolor{comment}{# we've been accumulating grads in fp16 and delaying the fp32 copy update.}
1861             \textcolor{comment}{# finally time to perform the update.}
1862             self.optimizer.update\_master\_grads()
1863 
1864         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'gradient\_clip'}, -1) > 0:
1865             \textcolor{keywordflow}{if} self.fp16:
1866                 grad\_norm = self.optimizer.clip\_master\_grads(self.opt[\textcolor{stringliteral}{'gradient\_clip'}])
1867             \textcolor{keywordflow}{else}:
1868                 grad\_norm = torch.nn.utils.clip\_grad\_norm\_(
1869                     self.model.parameters(), self.opt[\textcolor{stringliteral}{'gradient\_clip'}]
1870                 )
1871             self.metrics[\textcolor{stringliteral}{'gnorm'}] += grad\_norm
1872             self.metrics[\textcolor{stringliteral}{'clip'}] += \hyperlink{namespaceprojects_1_1controllable__dialogue_1_1make__control__dataset_aa2b7207688c641dbc094ab44eca27113}{float}(grad\_norm > self.opt[\textcolor{stringliteral}{'gradient\_clip'}])
1873 
1874         self.metrics[\textcolor{stringliteral}{'updates'}] += 1
1875         self.optimizer.step()
1876 
1877         \textcolor{comment}{# keep track up number of steps, compute warmup factor}
1878         self.\_number\_training\_updates += 1
1879 
1880         \textcolor{comment}{# compute warmup adjustment if needed}
1881         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'warmup\_updates'}, -1) > 0:
1882             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} hasattr(self, \textcolor{stringliteral}{'warmup\_scheduler'}):
1883                 \textcolor{keywordflow}{raise} RuntimeError(\textcolor{stringliteral}{'Looks like you forgot to call build\_lr\_scheduler'})
1884             \textcolor{keywordflow}{if} self.\_is\_lr\_warming\_up():
1885                 self.warmup\_scheduler.step(epoch=self.\_number\_training\_updates)
1886 
1887         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'lr\_scheduler'}) == \textcolor{stringliteral}{'invsqrt'} \textcolor{keywordflow}{and} \textcolor{keywordflow}{not} self.\_is\_lr\_warming\_up():
1888             \textcolor{comment}{# training step scheduler}
1889             self.scheduler.step(self.\_number\_training\_updates)
1890 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a48bb9b153353a0565ab7253dc1daef99}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a48bb9b153353a0565ab7253dc1daef99}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!vectorize@{vectorize}}
\index{vectorize@{vectorize}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{vectorize()}{vectorize()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+vectorize (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{obs,  }\item[{}]{history,  }\item[{}]{add\+\_\+start = {\ttfamily True},  }\item[{}]{add\+\_\+end = {\ttfamily True},  }\item[{}]{text\+\_\+truncate = {\ttfamily None},  }\item[{}]{label\+\_\+truncate = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Make vectors out of observation fields and store in the observation.

In particular, the 'text' and 'labels'/'eval_labels' fields are
processed and a new field is added to the observation with the suffix
'_vec'.

If you want to use additional fields on your subclass, you can override
this function, call super().vectorize(...) to process the text and
labels, and then process the other fields in your subclass.

Additionally, if you want to override some of these default parameters,
then we recommend using a pattern like:

.. code-block:: python

  def vectorize(self, *args, **kwargs):
      kwargs['add_start'] = False
      return super().vectorize(*args, **kwargs)


:param obs:
    Single observation from observe function.

:param add_start:
    default True, adds the start token to each label.

:param add_end:
    default True, adds the end token to each label.

:param text_truncate:
    default None, if set truncates text vectors to the specified
    length.

:param label_truncate:
    default None, if set truncates label vectors to the specified
    length.

:return:
    the input observation, with 'text_vec', 'label_vec', and
    'cands_vec' fields added.
\end{DoxyVerb}
 

Definition at line 1393 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1393     ):
1394         \textcolor{stringliteral}{"""}
1395 \textcolor{stringliteral}{        Make vectors out of observation fields and store in the observation.}
1396 \textcolor{stringliteral}{}
1397 \textcolor{stringliteral}{        In particular, the 'text' and 'labels'/'eval\_labels' fields are}
1398 \textcolor{stringliteral}{        processed and a new field is added to the observation with the suffix}
1399 \textcolor{stringliteral}{        '\_vec'.}
1400 \textcolor{stringliteral}{}
1401 \textcolor{stringliteral}{        If you want to use additional fields on your subclass, you can override}
1402 \textcolor{stringliteral}{        this function, call super().vectorize(...) to process the text and}
1403 \textcolor{stringliteral}{        labels, and then process the other fields in your subclass.}
1404 \textcolor{stringliteral}{}
1405 \textcolor{stringliteral}{        Additionally, if you want to override some of these default parameters,}
1406 \textcolor{stringliteral}{        then we recommend using a pattern like:}
1407 \textcolor{stringliteral}{}
1408 \textcolor{stringliteral}{        .. code-block:: python}
1409 \textcolor{stringliteral}{}
1410 \textcolor{stringliteral}{          def vectorize(self, *args, **kwargs):}
1411 \textcolor{stringliteral}{              kwargs['add\_start'] = False}
1412 \textcolor{stringliteral}{              return super().vectorize(*args, **kwargs)}
1413 \textcolor{stringliteral}{}
1414 \textcolor{stringliteral}{}
1415 \textcolor{stringliteral}{        :param obs:}
1416 \textcolor{stringliteral}{            Single observation from observe function.}
1417 \textcolor{stringliteral}{}
1418 \textcolor{stringliteral}{        :param add\_start:}
1419 \textcolor{stringliteral}{            default True, adds the start token to each label.}
1420 \textcolor{stringliteral}{}
1421 \textcolor{stringliteral}{        :param add\_end:}
1422 \textcolor{stringliteral}{            default True, adds the end token to each label.}
1423 \textcolor{stringliteral}{}
1424 \textcolor{stringliteral}{        :param text\_truncate:}
1425 \textcolor{stringliteral}{            default None, if set truncates text vectors to the specified}
1426 \textcolor{stringliteral}{            length.}
1427 \textcolor{stringliteral}{}
1428 \textcolor{stringliteral}{        :param label\_truncate:}
1429 \textcolor{stringliteral}{            default None, if set truncates label vectors to the specified}
1430 \textcolor{stringliteral}{            length.}
1431 \textcolor{stringliteral}{}
1432 \textcolor{stringliteral}{        :return:}
1433 \textcolor{stringliteral}{            the input observation, with 'text\_vec', 'label\_vec', and}
1434 \textcolor{stringliteral}{            'cands\_vec' fields added.}
1435 \textcolor{stringliteral}{        """}
1436         self.\_set\_text\_vec(obs, history, text\_truncate)
1437         self.\_set\_label\_vec(obs, add\_start, add\_end, label\_truncate)
1438         self.\_set\_label\_cands\_vec(obs, add\_start, add\_end, label\_truncate)
1439         \textcolor{keywordflow}{return} obs
1440 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a91c163f3e2d39b380095b7083f673b6e}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a91c163f3e2d39b380095b7083f673b6e}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!zero\+\_\+grad@{zero\+\_\+grad}}
\index{zero\+\_\+grad@{zero\+\_\+grad}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{zero\+\_\+grad()}{zero\_grad()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+zero\+\_\+grad (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Zero out optimizer.

It is recommended you call this in train_step. It automatically handles gradient
accumulation if agent is called with --update-freq.
\end{DoxyVerb}
 

Definition at line 1891 of file torch\+\_\+agent.\+py.


\begin{DoxyCode}
1891     \textcolor{keyword}{def }zero\_grad(self):
1892         \textcolor{stringliteral}{"""}
1893 \textcolor{stringliteral}{        Zero out optimizer.}
1894 \textcolor{stringliteral}{}
1895 \textcolor{stringliteral}{        It is recommended you call this in train\_step. It automatically handles gradient}
1896 \textcolor{stringliteral}{        accumulation if agent is called with --update-freq.}
1897 \textcolor{stringliteral}{        """}
1898         \textcolor{keywordflow}{if} self.\_number\_grad\_accum != 0:
1899             \textcolor{comment}{# if we're accumulating gradients, don't actually zero things out yet.}
1900             \textcolor{keywordflow}{return}
1901 
1902         self.optimizer.zero\_grad()
1903 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a63011fa9bd927de8acc9ffa676caa73a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a63011fa9bd927de8acc9ffa676caa73a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!add\+\_\+person\+\_\+tokens@{add\+\_\+person\+\_\+tokens}}
\index{add\+\_\+person\+\_\+tokens@{add\+\_\+person\+\_\+tokens}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{add\+\_\+person\+\_\+tokens}{add\_person\_tokens}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+add\+\_\+person\+\_\+tokens}



Definition at line 752 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae67e7dc97dff3c46522712945ca23f50}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae67e7dc97dff3c46522712945ca23f50}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!batch\+\_\+idx@{batch\+\_\+idx}}
\index{batch\+\_\+idx@{batch\+\_\+idx}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{batch\+\_\+idx}{batch\_idx}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+batch\+\_\+idx}



Definition at line 738 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a13d46ae8aed6052679b62c3961a4de62}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a13d46ae8aed6052679b62c3961a4de62}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!criterion@{criterion}}
\index{criterion@{criterion}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{criterion}{criterion}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+criterion}



Definition at line 708 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_abebf29c0bb956bbc5ccc02777d2af3dd}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_abebf29c0bb956bbc5ccc02777d2af3dd}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!dict@{dict}}
\index{dict@{dict}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{dict}{dict}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+dict}



Definition at line 685 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3a80083f0e34d8abc15b50123efec884}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3a80083f0e34d8abc15b50123efec884}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!E\+M\+P\+TY@{E\+M\+P\+TY}}
\index{E\+M\+P\+TY@{E\+M\+P\+TY}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{E\+M\+P\+TY}{EMPTY}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+E\+M\+P\+TY}



Definition at line 726 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a31bb7c8bf380660ee4e3822756563599}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a31bb7c8bf380660ee4e3822756563599}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}}
\index{E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{E\+N\+D\+\_\+\+I\+DX}{END\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+E\+N\+D\+\_\+\+I\+DX}



Definition at line 729 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa6f916e01d876679b529a893ad4f52f6}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_aa6f916e01d876679b529a893ad4f52f6}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!fp16@{fp16}}
\index{fp16@{fp16}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{fp16}{fp16}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+fp16}



Definition at line 679 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0484b0246f0a930adc575899cdef033c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!history@{history}}
\index{history@{history}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{history}{history}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+history}



Definition at line 748 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a15cbb1f743c1d341d914ade47e49071b}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a15cbb1f743c1d341d914ade47e49071b}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!histsz@{histsz}}
\index{histsz@{histsz}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{histsz}{histsz}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+histsz}



Definition at line 740 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4ac66a09c1c164ea08f4b257c61c38a0}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4ac66a09c1c164ea08f4b257c61c38a0}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!id@{id}}
\index{id@{id}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{id}{id}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+id}



Definition at line 723 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab0bd6456c94dfd9afae73b86f05016cf}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ab0bd6456c94dfd9afae73b86f05016cf}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!is\+\_\+training@{is\+\_\+training}}
\index{is\+\_\+training@{is\+\_\+training}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{is\+\_\+training}{is\_training}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+is\+\_\+training}



Definition at line 750 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_adbdd7cf2deb2c43d982c57852b83e685}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!label\+\_\+truncate@{label\+\_\+truncate}}
\index{label\+\_\+truncate@{label\+\_\+truncate}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{label\+\_\+truncate}{label\_truncate}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+label\+\_\+truncate}



Definition at line 746 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a392ed66573001dfa2846d5042e8fc5a5}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a392ed66573001dfa2846d5042e8fc5a5}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!metrics@{metrics}}
\index{metrics@{metrics}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{metrics}{metrics}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+metrics}



Definition at line 696 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afe40410d2e3b2565ecd27441266011fc}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_afe40410d2e3b2565ecd27441266011fc}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!model@{model}}
\index{model@{model}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{model}{model}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+model}



Definition at line 707 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a95cedd561757c9fc10dbf3a956e7f912}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a95cedd561757c9fc10dbf3a956e7f912}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}}
\index{N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{N\+U\+L\+L\+\_\+\+I\+DX}{NULL\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+N\+U\+L\+L\+\_\+\+I\+DX}



Definition at line 727 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a4bc525b20568822a042b3bbfa3da3a69}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!observation@{observation}}
\index{observation@{observation}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{observation}{observation}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+observation}



Definition at line 1639 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!opt@{opt}}
\index{opt@{opt}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{opt}{opt}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+opt}



Definition at line 705 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9533344de40049bf13209739bc92199d}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a9533344de40049bf13209739bc92199d}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!optimizer@{optimizer}}
\index{optimizer@{optimizer}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{optimizer}{optimizer}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+optimizer}



Definition at line 872 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac946030b54cc854162e8bc6b7aad7272}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ac946030b54cc854162e8bc6b7aad7272}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!P1\+\_\+\+T\+O\+K\+EN@{P1\+\_\+\+T\+O\+K\+EN}}
\index{P1\+\_\+\+T\+O\+K\+EN@{P1\+\_\+\+T\+O\+K\+EN}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{P1\+\_\+\+T\+O\+K\+EN}{P1\_TOKEN}}
{\footnotesize\ttfamily string parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+P1\+\_\+\+T\+O\+K\+EN = \textquotesingle{}\+\_\+\+\_\+p1\+\_\+\+\_\+\textquotesingle{}\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 350 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_af6e16e0532e71b06328e078cb3c9324c}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_af6e16e0532e71b06328e078cb3c9324c}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!P2\+\_\+\+T\+O\+K\+EN@{P2\+\_\+\+T\+O\+K\+EN}}
\index{P2\+\_\+\+T\+O\+K\+EN@{P2\+\_\+\+T\+O\+K\+EN}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{P2\+\_\+\+T\+O\+K\+EN}{P2\_TOKEN}}
{\footnotesize\ttfamily string parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+P2\+\_\+\+T\+O\+K\+EN = \textquotesingle{}\+\_\+\+\_\+p2\+\_\+\+\_\+\textquotesingle{}\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 351 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a805a9e47552d54d56f5b232ab4d5121f}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a805a9e47552d54d56f5b232ab4d5121f}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!proj\+\_\+rp@{proj\+\_\+rp}}
\index{proj\+\_\+rp@{proj\+\_\+rp}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{proj\+\_\+rp}{proj\_rp}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+proj\+\_\+rp}



Definition at line 1173 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a1ca476189900643fab04d1ac0ebfc719}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a1ca476189900643fab04d1ac0ebfc719}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!random@{random}}
\index{random@{random}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{random}{random}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+random}



Definition at line 736 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6355b9b0c0ccb24ffe1b5e3d89903cc3}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a6355b9b0c0ccb24ffe1b5e3d89903cc3}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!rank\+\_\+candidates@{rank\+\_\+candidates}}
\index{rank\+\_\+candidates@{rank\+\_\+candidates}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{rank\+\_\+candidates}{rank\_candidates}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+rank\+\_\+candidates}



Definition at line 751 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dd17721e788aafd51cd5af7bf7fc967}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a5dd17721e788aafd51cd5af7bf7fc967}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!replies@{replies}}
\index{replies@{replies}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{replies}{replies}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+replies}



Definition at line 683 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0affe6b199275c182a27c9aa07393347}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a0affe6b199275c182a27c9aa07393347}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!scheduler@{scheduler}}
\index{scheduler@{scheduler}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{scheduler}{scheduler}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+scheduler}



Definition at line 952 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a2018afae9938937f80b61475314012cd}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a2018afae9938937f80b61475314012cd}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!S\+T\+A\+R\+T\+\_\+\+I\+DX@{S\+T\+A\+R\+T\+\_\+\+I\+DX}}
\index{S\+T\+A\+R\+T\+\_\+\+I\+DX@{S\+T\+A\+R\+T\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{S\+T\+A\+R\+T\+\_\+\+I\+DX}{START\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+S\+T\+A\+R\+T\+\_\+\+I\+DX}



Definition at line 728 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_ae3a69ecb5f20ce4f8a09c05c5f6f4376}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!text\+\_\+truncate@{text\+\_\+truncate}}
\index{text\+\_\+truncate@{text\+\_\+truncate}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{text\+\_\+truncate}{text\_truncate}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+text\+\_\+truncate}



Definition at line 744 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3ae27e9fe68d255a960bcb5180f48a65}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a3ae27e9fe68d255a960bcb5180f48a65}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!truncate@{truncate}}
\index{truncate@{truncate}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{truncate}{truncate}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+truncate}



Definition at line 742 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a10b8d2605e619d5d3dc9f67777cb190a}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a10b8d2605e619d5d3dc9f67777cb190a}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!use\+\_\+cuda@{use\+\_\+cuda}}
\index{use\+\_\+cuda@{use\+\_\+cuda}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{use\+\_\+cuda}{use\_cuda}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+use\+\_\+cuda}



Definition at line 672 of file torch\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a54d8632c546ab621c93c34f13c964726}\label{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a54d8632c546ab621c93c34f13c964726}} 
\index{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}!warmup\+\_\+scheduler@{warmup\+\_\+scheduler}}
\index{warmup\+\_\+scheduler@{warmup\+\_\+scheduler}!parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent@{parlai\+::core\+::torch\+\_\+agent\+::\+Torch\+Agent}}
\subsubsection{\texorpdfstring{warmup\+\_\+scheduler}{warmup\_scheduler}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+agent.\+Torch\+Agent.\+warmup\+\_\+scheduler}



Definition at line 944 of file torch\+\_\+agent.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/core/\hyperlink{torch__agent_8py}{torch\+\_\+agent.\+py}\end{DoxyCompactItemize}
