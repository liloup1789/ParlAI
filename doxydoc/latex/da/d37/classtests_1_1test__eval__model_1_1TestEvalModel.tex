\hypertarget{classtests_1_1test__eval__model_1_1TestEvalModel}{}\section{tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model Class Reference}
\label{classtests_1_1test__eval__model_1_1TestEvalModel}\index{tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model@{tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model}}


Inheritance diagram for tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=215pt]{dd/dfb/classtests_1_1test__eval__model_1_1TestEvalModel__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=215pt]{dd/d6b/classtests_1_1test__eval__model_1_1TestEvalModel__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classtests_1_1test__eval__model_1_1TestEvalModel_a899d6a41fb8f56be62a7145d9937ee52}{test\+\_\+output} (self)
\item 
def \hyperlink{classtests_1_1test__eval__model_1_1TestEvalModel_a35d01001a5c2f289c98b384e1a53e515}{test\+\_\+metrics\+\_\+all} (self)
\item 
def \hyperlink{classtests_1_1test__eval__model_1_1TestEvalModel_a7b7b27f681704f217f711b04311977c2}{test\+\_\+metrics\+\_\+select} (self)
\item 
def \hyperlink{classtests_1_1test__eval__model_1_1TestEvalModel_a06987267bf1d5f021f3ddcbe489a820f}{test\+\_\+multitasking\+\_\+metrics} (self)
\item 
def \hyperlink{classtests_1_1test__eval__model_1_1TestEvalModel_a6f8c8d67ca1f6a036122e191fdc77c26}{test\+\_\+train\+\_\+evalmode} (self)
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}Basic tests on the eval_model.py example.
\end{DoxyVerb}
 

Definition at line 13 of file test\+\_\+eval\+\_\+model.\+py.



\subsection{Member Function Documentation}
\mbox{\Hypertarget{classtests_1_1test__eval__model_1_1TestEvalModel_a35d01001a5c2f289c98b384e1a53e515}\label{classtests_1_1test__eval__model_1_1TestEvalModel_a35d01001a5c2f289c98b384e1a53e515}} 
\index{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}!test\+\_\+metrics\+\_\+all@{test\+\_\+metrics\+\_\+all}}
\index{test\+\_\+metrics\+\_\+all@{test\+\_\+metrics\+\_\+all}!tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}}
\subsubsection{\texorpdfstring{test\+\_\+metrics\+\_\+all()}{test\_metrics\_all()}}
{\footnotesize\ttfamily def tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model.\+test\+\_\+metrics\+\_\+all (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Test output of running eval_model.
\end{DoxyVerb}
 

Definition at line 51 of file test\+\_\+eval\+\_\+model.\+py.


\begin{DoxyCode}
51     \textcolor{keyword}{def }test\_metrics\_all(self):
52         \textcolor{stringliteral}{"""}
53 \textcolor{stringliteral}{        Test output of running eval\_model.}
54 \textcolor{stringliteral}{        """}
55         parser = \hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1run_a17bafea2534d593de1fbf1e0724e5b67}{setup\_args}()
56         parser.set\_defaults(
57             task=\textcolor{stringliteral}{'integration\_tests'},
58             model=\textcolor{stringliteral}{'repeat\_label'},
59             datatype=\textcolor{stringliteral}{'valid'},
60             num\_examples=5,
61             display\_examples=\textcolor{keyword}{False},
62             metrics=\textcolor{stringliteral}{'all'},
63         )
64 
65         opt = parser.parse\_args(print\_args=\textcolor{keyword}{False})
66         str\_output, valid, test = testing\_utils.eval\_model(opt)
67         self.assertGreater(len(str\_output), 0, \textcolor{stringliteral}{"Output is empty"})
68 
69         \textcolor{comment}{# decode the output}
70         scores = str\_output.split(\textcolor{stringliteral}{"\(\backslash\)n---\(\backslash\)n"})
71 
72         \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(1, len(scores)):
73             score = ast.literal\_eval(scores[i])
74             \textcolor{comment}{# check totals}
75             self.assertEqual(score[\textcolor{stringliteral}{'exs'}], i, \textcolor{stringliteral}{"Total is incorrect"})
76             \textcolor{comment}{# accuracy should be one}
77             self.assertEqual(\textcolor{stringliteral}{'accuracy'} \textcolor{keywordflow}{in} score, \textcolor{keyword}{True}, \textcolor{stringliteral}{"Accuracy is missing from all"})
78             self.assertEqual(score[\textcolor{stringliteral}{'accuracy'}], 1, \textcolor{stringliteral}{"Accuracy != 1"})
79             self.assertEqual(\textcolor{stringliteral}{'rouge-1'} \textcolor{keywordflow}{in} score, \textcolor{keyword}{True}, \textcolor{stringliteral}{"Rouge is missing from all"})
80             self.assertEqual(score[\textcolor{stringliteral}{'rouge-1'}], 1, \textcolor{stringliteral}{'rouge1 != 1'})
81             self.assertEqual(score[\textcolor{stringliteral}{'rouge-2'}], 1, \textcolor{stringliteral}{'rouge-2 != 1'})
82             self.assertEqual(score[\textcolor{stringliteral}{'rouge-L'}], 1, \textcolor{stringliteral}{'rouge-L != 1'})
83 
\end{DoxyCode}
\mbox{\Hypertarget{classtests_1_1test__eval__model_1_1TestEvalModel_a7b7b27f681704f217f711b04311977c2}\label{classtests_1_1test__eval__model_1_1TestEvalModel_a7b7b27f681704f217f711b04311977c2}} 
\index{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}!test\+\_\+metrics\+\_\+select@{test\+\_\+metrics\+\_\+select}}
\index{test\+\_\+metrics\+\_\+select@{test\+\_\+metrics\+\_\+select}!tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}}
\subsubsection{\texorpdfstring{test\+\_\+metrics\+\_\+select()}{test\_metrics\_select()}}
{\footnotesize\ttfamily def tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model.\+test\+\_\+metrics\+\_\+select (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Test output of running eval_model.
\end{DoxyVerb}
 

Definition at line 84 of file test\+\_\+eval\+\_\+model.\+py.


\begin{DoxyCode}
84     \textcolor{keyword}{def }test\_metrics\_select(self):
85         \textcolor{stringliteral}{"""}
86 \textcolor{stringliteral}{        Test output of running eval\_model.}
87 \textcolor{stringliteral}{        """}
88         parser = \hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1run_a17bafea2534d593de1fbf1e0724e5b67}{setup\_args}()
89         parser.set\_defaults(
90             task=\textcolor{stringliteral}{'integration\_tests'},
91             model=\textcolor{stringliteral}{'repeat\_label'},
92             datatype=\textcolor{stringliteral}{'valid'},
93             num\_examples=5,
94             display\_examples=\textcolor{keyword}{False},
95             metrics=\textcolor{stringliteral}{'accuracy,rouge'},
96         )
97 
98         opt = parser.parse\_args(print\_args=\textcolor{keyword}{False})
99         str\_output, valid, test = testing\_utils.eval\_model(opt)
100         self.assertGreater(len(str\_output), 0, \textcolor{stringliteral}{"Output is empty"})
101 
102         \textcolor{comment}{# decode the output}
103         scores = str\_output.split(\textcolor{stringliteral}{"\(\backslash\)n---\(\backslash\)n"})
104 
105         \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(1, len(scores)):
106             score = ast.literal\_eval(scores[i])
107             \textcolor{comment}{# check totals}
108             self.assertEqual(score[\textcolor{stringliteral}{'exs'}], i, \textcolor{stringliteral}{"Total is incorrect"})
109             \textcolor{comment}{# accuracy should be one}
110             self.assertEqual(
111                 \textcolor{stringliteral}{'accuracy'} \textcolor{keywordflow}{in} score, \textcolor{keyword}{True}, \textcolor{stringliteral}{"Accuracy is missing from selection"}
112             )
113             self.assertEqual(score[\textcolor{stringliteral}{'accuracy'}], 1, \textcolor{stringliteral}{"Accuracy != 1"})
114             self.assertEqual(
115                 \textcolor{stringliteral}{'rouge-1'} \textcolor{keywordflow}{in} score, \textcolor{keyword}{True}, \textcolor{stringliteral}{"Rouge is missing from selection"}
116             )
117             self.assertEqual(score[\textcolor{stringliteral}{'rouge-1'}], 1, \textcolor{stringliteral}{'rouge1 != 1'})
118             self.assertEqual(score[\textcolor{stringliteral}{'rouge-2'}], 1, \textcolor{stringliteral}{'rouge-2 != 1'})
119             self.assertEqual(score[\textcolor{stringliteral}{'rouge-L'}], 1, \textcolor{stringliteral}{'rouge-L != 1'})
120 
\end{DoxyCode}
\mbox{\Hypertarget{classtests_1_1test__eval__model_1_1TestEvalModel_a06987267bf1d5f021f3ddcbe489a820f}\label{classtests_1_1test__eval__model_1_1TestEvalModel_a06987267bf1d5f021f3ddcbe489a820f}} 
\index{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}!test\+\_\+multitasking\+\_\+metrics@{test\+\_\+multitasking\+\_\+metrics}}
\index{test\+\_\+multitasking\+\_\+metrics@{test\+\_\+multitasking\+\_\+metrics}!tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}}
\subsubsection{\texorpdfstring{test\+\_\+multitasking\+\_\+metrics()}{test\_multitasking\_metrics()}}
{\footnotesize\ttfamily def tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model.\+test\+\_\+multitasking\+\_\+metrics (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line 121 of file test\+\_\+eval\+\_\+model.\+py.


\begin{DoxyCode}
121     \textcolor{keyword}{def }test\_multitasking\_metrics(self):
122         stdout, valid, test = testing\_utils.eval\_model(
123             \{
124                 \textcolor{stringliteral}{'task'}: \textcolor{stringliteral}{'integration\_tests:candidate,'}
125                 \textcolor{stringliteral}{'integration\_tests:multiturnCandidate'},
126                 \textcolor{stringliteral}{'model'}: \textcolor{stringliteral}{'random\_candidate'},
127                 \textcolor{stringliteral}{'num\_epochs'}: 0.5,
128                 \textcolor{stringliteral}{'aggregate\_micro'}: \textcolor{keyword}{True},
129             \}
130         )
131 
132         task1\_acc = valid[\textcolor{stringliteral}{'tasks'}][\textcolor{stringliteral}{'integration\_tests:candidate'}][\textcolor{stringliteral}{'accuracy'}]
133         task2\_acc = valid[\textcolor{stringliteral}{'tasks'}][\textcolor{stringliteral}{'integration\_tests:multiturnCandidate'}][\textcolor{stringliteral}{'accuracy'}]
134         total\_acc = valid[\textcolor{stringliteral}{'accuracy'}]
135         \textcolor{comment}{# task 2 is 4 times the size of task 1}
136         self.assertAlmostEqual(
137             total\_acc,
138             (task1\_acc + 4 * task2\_acc) / 5,
139             4,
140             \textcolor{stringliteral}{'Task accuracy is averaged incorrectly'},
141         )
142 
143         stdout, valid, test = testing\_utils.eval\_model(
144             \{
145                 \textcolor{stringliteral}{'task'}: \textcolor{stringliteral}{'integration\_tests:candidate,'}
146                 \textcolor{stringliteral}{'integration\_tests:multiturnCandidate'},
147                 \textcolor{stringliteral}{'model'}: \textcolor{stringliteral}{'random\_candidate'},
148                 \textcolor{stringliteral}{'num\_epochs'}: 0.5,
149                 \textcolor{stringliteral}{'aggregate\_micro'}: \textcolor{keyword}{False},
150             \}
151         )
152         task1\_acc = valid[\textcolor{stringliteral}{'tasks'}][\textcolor{stringliteral}{'integration\_tests:candidate'}][\textcolor{stringliteral}{'accuracy'}]
153         task2\_acc = valid[\textcolor{stringliteral}{'tasks'}][\textcolor{stringliteral}{'integration\_tests:multiturnCandidate'}][\textcolor{stringliteral}{'accuracy'}]
154         total\_acc = valid[\textcolor{stringliteral}{'accuracy'}]
155         \textcolor{comment}{# metrics should be averaged equally across tasks}
156         self.assertAlmostEqual(
157             total\_acc,
158             (task1\_acc + task2\_acc) / 2,
159             4,
160             \textcolor{stringliteral}{'Task accuracy is averaged incorrectly'},
161         )
162 
\end{DoxyCode}
\mbox{\Hypertarget{classtests_1_1test__eval__model_1_1TestEvalModel_a899d6a41fb8f56be62a7145d9937ee52}\label{classtests_1_1test__eval__model_1_1TestEvalModel_a899d6a41fb8f56be62a7145d9937ee52}} 
\index{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}!test\+\_\+output@{test\+\_\+output}}
\index{test\+\_\+output@{test\+\_\+output}!tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}}
\subsubsection{\texorpdfstring{test\+\_\+output()}{test\_output()}}
{\footnotesize\ttfamily def tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model.\+test\+\_\+output (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Test output of running eval_model.
\end{DoxyVerb}
 

Definition at line 18 of file test\+\_\+eval\+\_\+model.\+py.


\begin{DoxyCode}
18     \textcolor{keyword}{def }test\_output(self):
19         \textcolor{stringliteral}{"""}
20 \textcolor{stringliteral}{        Test output of running eval\_model.}
21 \textcolor{stringliteral}{        """}
22         parser = \hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1run_a17bafea2534d593de1fbf1e0724e5b67}{setup\_args}()
23         parser.set\_defaults(
24             task=\textcolor{stringliteral}{'integration\_tests'},
25             model=\textcolor{stringliteral}{'repeat\_label'},
26             datatype=\textcolor{stringliteral}{'valid'},
27             num\_examples=5,
28             display\_examples=\textcolor{keyword}{False},
29         )
30 
31         opt = parser.parse\_args(print\_args=\textcolor{keyword}{False})
32         str\_output, valid, test = testing\_utils.eval\_model(opt)
33         self.assertGreater(len(str\_output), 0, \textcolor{stringliteral}{"Output is empty"})
34 
35         \textcolor{comment}{# decode the output}
36         scores = str\_output.split(\textcolor{stringliteral}{"\(\backslash\)n---\(\backslash\)n"})
37 
38         \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(1, len(scores)):
39             score = ast.literal\_eval(scores[i])
40             \textcolor{comment}{# check totals}
41             self.assertEqual(score[\textcolor{stringliteral}{'exs'}], i, \textcolor{stringliteral}{"Total is incorrect"})
42             \textcolor{comment}{# accuracy should be one}
43             self.assertEqual(
44                 \textcolor{stringliteral}{'accuracy'} \textcolor{keywordflow}{in} score, \textcolor{keyword}{True}, \textcolor{stringliteral}{"Accuracy is missing from default"}
45             )
46             self.assertEqual(score[\textcolor{stringliteral}{'accuracy'}], 1, \textcolor{stringliteral}{"Accuracy != 1"})
47             self.assertEqual(
48                 \textcolor{stringliteral}{'rouge-1'} \textcolor{keywordflow}{in} score, \textcolor{keyword}{False}, \textcolor{stringliteral}{"Rouge is in the default metrics"}
49             )
50 
\end{DoxyCode}
\mbox{\Hypertarget{classtests_1_1test__eval__model_1_1TestEvalModel_a6f8c8d67ca1f6a036122e191fdc77c26}\label{classtests_1_1test__eval__model_1_1TestEvalModel_a6f8c8d67ca1f6a036122e191fdc77c26}} 
\index{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}!test\+\_\+train\+\_\+evalmode@{test\+\_\+train\+\_\+evalmode}}
\index{test\+\_\+train\+\_\+evalmode@{test\+\_\+train\+\_\+evalmode}!tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model@{tests\+::test\+\_\+eval\+\_\+model\+::\+Test\+Eval\+Model}}
\subsubsection{\texorpdfstring{test\+\_\+train\+\_\+evalmode()}{test\_train\_evalmode()}}
{\footnotesize\ttfamily def tests.\+test\+\_\+eval\+\_\+model.\+Test\+Eval\+Model.\+test\+\_\+train\+\_\+evalmode (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Test that evaluating a model with train:evalmode completes an epoch.
\end{DoxyVerb}
 

Definition at line 163 of file test\+\_\+eval\+\_\+model.\+py.


\begin{DoxyCode}
163     \textcolor{keyword}{def }test\_train\_evalmode(self):
164         \textcolor{stringliteral}{"""}
165 \textcolor{stringliteral}{        Test that evaluating a model with train:evalmode completes an epoch.}
166 \textcolor{stringliteral}{        """}
167         base\_dict = \{\textcolor{stringliteral}{'model'}: \textcolor{stringliteral}{'repeat\_label'}, \textcolor{stringliteral}{'datatype'}: \textcolor{stringliteral}{'train:evalmode'}\}
168 
169         teachers = [\textcolor{stringliteral}{'integration\_tests:fixed\_dialog\_candidate'}, \textcolor{stringliteral}{'integration\_tests'}]
170         batchsize = [1, 64]
171         \textcolor{keywordflow}{for} bs \textcolor{keywordflow}{in} batchsize:
172             \textcolor{keywordflow}{for} teacher \textcolor{keywordflow}{in} teachers:
173                 d = base\_dict.copy()
174                 d[\textcolor{stringliteral}{'task'}] = teacher
175                 d[\textcolor{stringliteral}{'batchsize'}] = bs
176                 with testing\_utils.timeout(time=20):
177                     stdout, valid, test = testing\_utils.eval\_model(
178                         d, valid\_datatype=d[\textcolor{stringliteral}{'datatype'}]
179                     )
180                 self.assertEqual(
181                     \hyperlink{namespacelanguage__model_1_1eval__ppl_a7d12ee00479673c5c8d1f6d01faa272a}{int}(valid[\textcolor{stringliteral}{'exs'}]),
182                     500,
183                     f\textcolor{stringliteral}{'train:evalmode failed with bs \{bs\} and teacher \{teacher\}'}
184                     f\textcolor{stringliteral}{' stdout: \{stdout\}'},
185                 )
186 
187 
\end{DoxyCode}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
tests/\hyperlink{test__eval__model_8py}{test\+\_\+eval\+\_\+model.\+py}\end{DoxyCompactItemize}
