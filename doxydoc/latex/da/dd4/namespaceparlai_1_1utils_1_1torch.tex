\hypertarget{namespaceparlai_1_1utils_1_1torch}{}\section{parlai.\+utils.\+torch Namespace Reference}
\label{namespaceparlai_1_1utils_1_1torch}\index{parlai.\+utils.\+torch@{parlai.\+utils.\+torch}}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{namespaceparlai_1_1utils_1_1torch_a6c6e25115353dba479cd72dc31dc76ae}{neginf}
\item 
def \hyperlink{namespaceparlai_1_1utils_1_1torch_a30f55f2d76c1e7f01e2612ecef231946}{padded\+\_\+tensor}
\item 
def \hyperlink{namespaceparlai_1_1utils_1_1torch_a1494906187c1ba19f92defb0d4c19ffe}{padded\+\_\+3d}
\item 
def \hyperlink{namespaceparlai_1_1utils_1_1torch_a6c7101b91c9bc5f6e00c4c65fc5ab21c}{argsort}
\item 
def \hyperlink{namespaceparlai_1_1utils_1_1torch_acd34433af9f43b196920120e6009494e}{fp16\+\_\+optimizer\+\_\+wrapper}
\end{DoxyCompactItemize}
\subsection*{Variables}
\begin{DoxyCompactItemize}
\item 
\hyperlink{namespaceparlai_1_1utils_1_1torch_ab38e7db22c2af18f6be15a319b63c489}{N\+E\+A\+R\+\_\+\+I\+NF}
\item 
\hyperlink{namespaceparlai_1_1utils_1_1torch_af25a0bd083e5ec4a1532b48acb165911}{N\+E\+A\+R\+\_\+\+I\+N\+F\+\_\+\+F\+P16}
\end{DoxyCompactItemize}


\subsection{Function Documentation}
\mbox{\Hypertarget{namespaceparlai_1_1utils_1_1torch_a6c7101b91c9bc5f6e00c4c65fc5ab21c}\label{namespaceparlai_1_1utils_1_1torch_a6c7101b91c9bc5f6e00c4c65fc5ab21c}} 
\index{parlai\+::utils\+::torch@{parlai\+::utils\+::torch}!argsort@{argsort}}
\index{argsort@{argsort}!parlai\+::utils\+::torch@{parlai\+::utils\+::torch}}
\subsubsection{\texorpdfstring{argsort()}{argsort()}}
{\footnotesize\ttfamily def parlai.\+utils.\+torch.\+argsort (\begin{DoxyParamCaption}\item[{}]{keys }\end{DoxyParamCaption})}



Definition at line 153 of file torch.\+py.


\begin{DoxyCode}
153 \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1utils_1_1torch_a6c7101b91c9bc5f6e00c4c65fc5ab21c}{argsort}(keys: List[Any], *lists: List[List[Any]], descending: bool = \textcolor{keyword}{False}):
154     \textcolor{stringliteral}{"""}
155 \textcolor{stringliteral}{    Reorder each list in lists by the (descending) sorted order of keys.}
156 \textcolor{stringliteral}{}
157 \textcolor{stringliteral}{    :param iter keys:}
158 \textcolor{stringliteral}{        Keys to order by.}
159 \textcolor{stringliteral}{    :param list[list] lists:}
160 \textcolor{stringliteral}{        Lists to reordered by keys's order.  Correctly handles lists and 1-D}
161 \textcolor{stringliteral}{        tensors.}
162 \textcolor{stringliteral}{    :param bool descending:}
163 \textcolor{stringliteral}{        Use descending order if true.}
164 \textcolor{stringliteral}{}
165 \textcolor{stringliteral}{    :returns:}
166 \textcolor{stringliteral}{        The reordered items.}
167 \textcolor{stringliteral}{    """}
168     ind\_sorted = sorted(range(len(keys)), key=\textcolor{keyword}{lambda} k: keys[k])
169     \textcolor{keywordflow}{if} descending:
170         ind\_sorted = list(reversed(ind\_sorted))
171     output = []
172     \textcolor{keywordflow}{for} lst \textcolor{keywordflow}{in} lists:
173         \textcolor{comment}{# watch out in case we don't have torch installed}
174         \textcolor{keywordflow}{if} isinstance(lst, torch.Tensor):
175             output.append(lst[ind\_sorted])
176         \textcolor{keywordflow}{else}:
177             output.append([lst[i] \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} ind\_sorted])
178     \textcolor{keywordflow}{return} output
179 
180 
\end{DoxyCode}
\mbox{\Hypertarget{namespaceparlai_1_1utils_1_1torch_acd34433af9f43b196920120e6009494e}\label{namespaceparlai_1_1utils_1_1torch_acd34433af9f43b196920120e6009494e}} 
\index{parlai\+::utils\+::torch@{parlai\+::utils\+::torch}!fp16\+\_\+optimizer\+\_\+wrapper@{fp16\+\_\+optimizer\+\_\+wrapper}}
\index{fp16\+\_\+optimizer\+\_\+wrapper@{fp16\+\_\+optimizer\+\_\+wrapper}!parlai\+::utils\+::torch@{parlai\+::utils\+::torch}}
\subsubsection{\texorpdfstring{fp16\+\_\+optimizer\+\_\+wrapper()}{fp16\_optimizer\_wrapper()}}
{\footnotesize\ttfamily def parlai.\+utils.\+torch.\+fp16\+\_\+optimizer\+\_\+wrapper (\begin{DoxyParamCaption}\item[{}]{optimizer }\end{DoxyParamCaption})}



Definition at line 182 of file torch.\+py.


\begin{DoxyCode}
182     optimizer: torch.optim.Optimizer,  \textcolor{comment}{# type: ignore}
183     verbose: bool = \textcolor{keyword}{False},
184     dynamic\_loss\_scale: bool = \textcolor{keyword}{True},
185     loss\_initial\_scale: float = 2.0 ** 17,
186 ):
187     \textcolor{stringliteral}{"""}
188 \textcolor{stringliteral}{    Wrap the an optimizer with FP16 loss scaling protection.}
189 \textcolor{stringliteral}{}
190 \textcolor{stringliteral}{    Requires apex to be installed. Will throw an ImportError if it is not.}
191 \textcolor{stringliteral}{}
192 \textcolor{stringliteral}{    :param optimizer:}
193 \textcolor{stringliteral}{        Any torch optimizer}
194 \textcolor{stringliteral}{    :param bool verbose:}
195 \textcolor{stringliteral}{        Enables verbose output in the FP16 optimizer. Turning this on can help}
196 \textcolor{stringliteral}{        debug when FP16 is underperforming.}
197 \textcolor{stringliteral}{    :param bool dynamic\_loss\_scaling:}
198 \textcolor{stringliteral}{        FP16 requires loss scaling to avoid underflows. It is recommended this}
199 \textcolor{stringliteral}{        stays on, but advanced users may want it off.}
200 \textcolor{stringliteral}{    :param float loss\_initial\_scale:}
201 \textcolor{stringliteral}{        Initial loss scaling. Default chosen empirically, but models with very low}
202 \textcolor{stringliteral}{        or high loss values may need this adjusted. Stick with powers of 2.}
203 \textcolor{stringliteral}{}
204 \textcolor{stringliteral}{    :returns:}
205 \textcolor{stringliteral}{        An APEX FP16 optimizer. Please note this has different requirements on}
206 \textcolor{stringliteral}{        how backward() and step() are called.}
207 \textcolor{stringliteral}{    """}
208     \textcolor{keywordflow}{try}:
209         \textcolor{keyword}{import} apex.fp16\_utils
210     \textcolor{keywordflow}{except} ImportError:
211         \textcolor{keywordflow}{raise} ImportError(
212             \textcolor{stringliteral}{'No fp16 support without apex. Please install it from '}
213             \textcolor{stringliteral}{'https://github.com/NVIDIA/apex'}
214         )
215     \textcolor{keywordflow}{return} apex.fp16\_utils.FP16\_Optimizer(
216         optimizer,
217         dynamic\_loss\_scale=dynamic\_loss\_scale,
218         verbose=verbose,
219         \textcolor{comment}{# TODO: We may later want to remove this flag. Right now it}
220         \textcolor{comment}{# empirically improves the first few backward passes, but future APEX}
221         \textcolor{comment}{# improvements may make this unnecessary.}
222         dynamic\_loss\_args=\{\textcolor{stringliteral}{'init\_scale'}: loss\_initial\_scale\},
223     )
224 \end{DoxyCode}
\mbox{\Hypertarget{namespaceparlai_1_1utils_1_1torch_a6c6e25115353dba479cd72dc31dc76ae}\label{namespaceparlai_1_1utils_1_1torch_a6c6e25115353dba479cd72dc31dc76ae}} 
\index{parlai\+::utils\+::torch@{parlai\+::utils\+::torch}!neginf@{neginf}}
\index{neginf@{neginf}!parlai\+::utils\+::torch@{parlai\+::utils\+::torch}}
\subsubsection{\texorpdfstring{neginf()}{neginf()}}
{\footnotesize\ttfamily def parlai.\+utils.\+torch.\+neginf (\begin{DoxyParamCaption}\item[{}]{dtype }\end{DoxyParamCaption})}



Definition at line 24 of file torch.\+py.


\begin{DoxyCode}
24 \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1utils_1_1torch_a6c6e25115353dba479cd72dc31dc76ae}{neginf}(dtype: torch.dtype) -> float:
25     \textcolor{stringliteral}{"""}
26 \textcolor{stringliteral}{    Return a representable finite number near -inf for a dtype.}
27 \textcolor{stringliteral}{    """}
28     \textcolor{keywordflow}{if} dtype \textcolor{keywordflow}{is} torch.float16:
29         \textcolor{keywordflow}{return} -NEAR\_INF\_FP16
30     \textcolor{keywordflow}{else}:
31         \textcolor{keywordflow}{return} -NEAR\_INF
32 
33 
\end{DoxyCode}
\mbox{\Hypertarget{namespaceparlai_1_1utils_1_1torch_a1494906187c1ba19f92defb0d4c19ffe}\label{namespaceparlai_1_1utils_1_1torch_a1494906187c1ba19f92defb0d4c19ffe}} 
\index{parlai\+::utils\+::torch@{parlai\+::utils\+::torch}!padded\+\_\+3d@{padded\+\_\+3d}}
\index{padded\+\_\+3d@{padded\+\_\+3d}!parlai\+::utils\+::torch@{parlai\+::utils\+::torch}}
\subsubsection{\texorpdfstring{padded\+\_\+3d()}{padded\_3d()}}
{\footnotesize\ttfamily def parlai.\+utils.\+torch.\+padded\+\_\+3d (\begin{DoxyParamCaption}\item[{}]{tensors }\end{DoxyParamCaption})}



Definition at line 106 of file torch.\+py.


\begin{DoxyCode}
106     tensors: List[torch.LongTensor],
107     pad\_idx: int = 0,
108     use\_cuda: bool = \textcolor{keyword}{False},
109     dtype: Optional[torch.dtype] = torch.long,
110     fp16friendly: bool = \textcolor{keyword}{False},
111 ):
112     \textcolor{stringliteral}{"""}
113 \textcolor{stringliteral}{    Make 3D padded tensor for list of lists of 1D tensors or lists.}
114 \textcolor{stringliteral}{}
115 \textcolor{stringliteral}{    :param tensors:}
116 \textcolor{stringliteral}{        list of lists of 1D tensors (or lists)}
117 \textcolor{stringliteral}{    :param pad\_idx:}
118 \textcolor{stringliteral}{        padding to fill tensor with}
119 \textcolor{stringliteral}{    :param use\_cuda:}
120 \textcolor{stringliteral}{        whether to call cuda() before returning}
121 \textcolor{stringliteral}{    :param bool fp16friendly:}
122 \textcolor{stringliteral}{        if True, pads the final dimension to be a multiple of 8.}
123 \textcolor{stringliteral}{}
124 \textcolor{stringliteral}{    :returns:}
125 \textcolor{stringliteral}{        3D tensor with the maximum dimensions of the inputs}
126 \textcolor{stringliteral}{    """}
127     a = len(tensors)
128     b = max(len(row) \textcolor{keywordflow}{for} row \textcolor{keywordflow}{in} tensors)  \textcolor{comment}{# type: ignore}
129     c = max(len(item) \textcolor{keywordflow}{for} row \textcolor{keywordflow}{in} tensors \textcolor{keywordflow}{for} item \textcolor{keywordflow}{in} row)  \textcolor{comment}{# type: ignore}
130 
131     \textcolor{comment}{# pad empty tensors}
132     \textcolor{keywordflow}{if} fp16friendly \textcolor{keywordflow}{and} c % 8 != 0:
133         c += 8 - (c % 8)
134     c = max(c, 1)
135 
136     output = torch.full((a, b, c), pad\_idx, dtype=dtype)
137 
138     \textcolor{keywordflow}{for} i, row \textcolor{keywordflow}{in} enumerate(tensors):
139         item: Sized
140         \textcolor{keywordflow}{for} j, item \textcolor{keywordflow}{in} enumerate(row):  \textcolor{comment}{# type: ignore}
141             \textcolor{keywordflow}{if} len(item) == 0:
142                 \textcolor{keywordflow}{continue}
143             \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} isinstance(item, torch.Tensor):
144                 item = torch.Tensor(item, dtype=dtype)
145             output[i, j, : len(item)] = item
146 
147     \textcolor{keywordflow}{if} use\_cuda:
148         output = output.cuda()
149 
150     \textcolor{keywordflow}{return} output
151 
152 
\end{DoxyCode}
\mbox{\Hypertarget{namespaceparlai_1_1utils_1_1torch_a30f55f2d76c1e7f01e2612ecef231946}\label{namespaceparlai_1_1utils_1_1torch_a30f55f2d76c1e7f01e2612ecef231946}} 
\index{parlai\+::utils\+::torch@{parlai\+::utils\+::torch}!padded\+\_\+tensor@{padded\+\_\+tensor}}
\index{padded\+\_\+tensor@{padded\+\_\+tensor}!parlai\+::utils\+::torch@{parlai\+::utils\+::torch}}
\subsubsection{\texorpdfstring{padded\+\_\+tensor()}{padded\_tensor()}}
{\footnotesize\ttfamily def parlai.\+utils.\+torch.\+padded\+\_\+tensor (\begin{DoxyParamCaption}\item[{}]{items }\end{DoxyParamCaption})}



Definition at line 35 of file torch.\+py.


\begin{DoxyCode}
35     items: List[Union[List[int], torch.LongTensor]],
36     pad\_idx: int = 0,
37     use\_cuda: bool = \textcolor{keyword}{False},
38     left\_padded: bool = \textcolor{keyword}{False},
39     max\_len: Optional[int] = \textcolor{keywordtype}{None},
40     fp16friendly: bool = \textcolor{keyword}{False},
41 ) -> Tuple[torch.LongTensor, List[int]]:
42     \textcolor{stringliteral}{"""}
43 \textcolor{stringliteral}{    Create a right-padded matrix from an uneven list of lists.}
44 \textcolor{stringliteral}{}
45 \textcolor{stringliteral}{    Returns (padded, lengths), where padded is the padded matrix, and lengths}
46 \textcolor{stringliteral}{    is a list containing the lengths of each row.}
47 \textcolor{stringliteral}{}
48 \textcolor{stringliteral}{    Matrix is right-padded (filled to the right) by default, but can be}
49 \textcolor{stringliteral}{    left padded if the flag is set to True.}
50 \textcolor{stringliteral}{}
51 \textcolor{stringliteral}{    Matrix can also be placed on cuda automatically.}
52 \textcolor{stringliteral}{}
53 \textcolor{stringliteral}{    :param list[iter[int]] items: List of items}
54 \textcolor{stringliteral}{    :param bool sort: If True, orders by the length}
55 \textcolor{stringliteral}{    :param int pad\_idx: the value to use for padding}
56 \textcolor{stringliteral}{    :param bool use\_cuda: if true, places `padded` on GPU}
57 \textcolor{stringliteral}{    :param bool left\_padded:}
58 \textcolor{stringliteral}{    :param int max\_len: if None, the max length is the maximum item length}
59 \textcolor{stringliteral}{    :param bool fp16friendly: if True, pads the time dimension to be a multiple of 8.}
60 \textcolor{stringliteral}{}
61 \textcolor{stringliteral}{    :returns: (padded, lengths) tuple}
62 \textcolor{stringliteral}{    :rtype: (Tensor[int64], list[int])}
63 \textcolor{stringliteral}{    """}
64 
65     \textcolor{comment}{# number of items}
66     n = len(items)
67     \textcolor{comment}{# length of each item}
68     lens: List[int] = [len(item) \textcolor{keywordflow}{for} item \textcolor{keywordflow}{in} items]  \textcolor{comment}{# type: ignore}
69     \textcolor{comment}{# max in time dimension}
70     t = max(lens) \textcolor{keywordflow}{if} max\_len \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} max\_len
71 
72     \textcolor{comment}{# if input tensors are empty, we should expand to nulls}
73     t = max(t, 1)
74 
75     \textcolor{keywordflow}{if} fp16friendly \textcolor{keywordflow}{and} (t % 8 != 0):
76         \textcolor{comment}{# pad to be a multiple of 8 to ensure we use the tensor cores}
77         t += 8 - (t % 8)
78 
79     \textcolor{keywordflow}{if} isinstance(items[0], torch.Tensor):
80         \textcolor{comment}{# keep type of input tensors, they may already be cuda ones}
81         output = items[0].new(n, t)  \textcolor{comment}{# type: ignore}
82     \textcolor{keywordflow}{else}:
83         output = torch.LongTensor(n, t)  \textcolor{comment}{# type: ignore}
84     output.fill\_(pad\_idx)
85 
86     \textcolor{keywordflow}{for} i, (item, length) \textcolor{keywordflow}{in} enumerate(zip(items, lens)):
87         \textcolor{keywordflow}{if} length == 0:
88             \textcolor{comment}{# skip empty items}
89             \textcolor{keywordflow}{continue}
90         \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} isinstance(item, torch.Tensor):
91             \textcolor{comment}{# put non-tensors into a tensor}
92             item = torch.LongTensor(item)  \textcolor{comment}{# type: ignore}
93         \textcolor{keywordflow}{if} left\_padded:
94             \textcolor{comment}{# place at end}
95             output[i, t - length :] = item
96         \textcolor{keywordflow}{else}:
97             \textcolor{comment}{# place at beginning}
98             output[i, :length] = item
99 
100     \textcolor{keywordflow}{if} use\_cuda:
101         output = output.cuda()
102     \textcolor{keywordflow}{return} output, lens
103 
104 
\end{DoxyCode}


\subsection{Variable Documentation}
\mbox{\Hypertarget{namespaceparlai_1_1utils_1_1torch_ab38e7db22c2af18f6be15a319b63c489}\label{namespaceparlai_1_1utils_1_1torch_ab38e7db22c2af18f6be15a319b63c489}} 
\index{parlai\+::utils\+::torch@{parlai\+::utils\+::torch}!N\+E\+A\+R\+\_\+\+I\+NF@{N\+E\+A\+R\+\_\+\+I\+NF}}
\index{N\+E\+A\+R\+\_\+\+I\+NF@{N\+E\+A\+R\+\_\+\+I\+NF}!parlai\+::utils\+::torch@{parlai\+::utils\+::torch}}
\subsubsection{\texorpdfstring{N\+E\+A\+R\+\_\+\+I\+NF}{NEAR\_INF}}
{\footnotesize\ttfamily parlai.\+utils.\+torch.\+N\+E\+A\+R\+\_\+\+I\+NF}



Definition at line 20 of file torch.\+py.

\mbox{\Hypertarget{namespaceparlai_1_1utils_1_1torch_af25a0bd083e5ec4a1532b48acb165911}\label{namespaceparlai_1_1utils_1_1torch_af25a0bd083e5ec4a1532b48acb165911}} 
\index{parlai\+::utils\+::torch@{parlai\+::utils\+::torch}!N\+E\+A\+R\+\_\+\+I\+N\+F\+\_\+\+F\+P16@{N\+E\+A\+R\+\_\+\+I\+N\+F\+\_\+\+F\+P16}}
\index{N\+E\+A\+R\+\_\+\+I\+N\+F\+\_\+\+F\+P16@{N\+E\+A\+R\+\_\+\+I\+N\+F\+\_\+\+F\+P16}!parlai\+::utils\+::torch@{parlai\+::utils\+::torch}}
\subsubsection{\texorpdfstring{N\+E\+A\+R\+\_\+\+I\+N\+F\+\_\+\+F\+P16}{NEAR\_INF\_FP16}}
{\footnotesize\ttfamily parlai.\+utils.\+torch.\+N\+E\+A\+R\+\_\+\+I\+N\+F\+\_\+\+F\+P16}



Definition at line 21 of file torch.\+py.

