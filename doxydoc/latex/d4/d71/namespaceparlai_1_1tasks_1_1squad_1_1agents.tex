\hypertarget{namespaceparlai_1_1tasks_1_1squad_1_1agents}{}\section{parlai.\+tasks.\+squad.\+agents Namespace Reference}
\label{namespaceparlai_1_1tasks_1_1squad_1_1agents}\index{parlai.\+tasks.\+squad.\+agents@{parlai.\+tasks.\+squad.\+agents}}
\subsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \hyperlink{classparlai_1_1tasks_1_1squad_1_1agents_1_1DefaultTeacher}{Default\+Teacher}
\item 
class \hyperlink{classparlai_1_1tasks_1_1squad_1_1agents_1_1FulldocsentenceTeacher}{Fulldocsentence\+Teacher}
\item 
class \hyperlink{classparlai_1_1tasks_1_1squad_1_1agents_1_1FulldocTeacher}{Fulldoc\+Teacher}
\item 
class \hyperlink{classparlai_1_1tasks_1_1squad_1_1agents_1_1IndexTeacher}{Index\+Teacher}
\item 
class \hyperlink{classparlai_1_1tasks_1_1squad_1_1agents_1_1OpensquadTeacher}{Opensquad\+Teacher}
\item 
class \hyperlink{classparlai_1_1tasks_1_1squad_1_1agents_1_1SentenceTeacher}{Sentence\+Teacher}
\item 
class \hyperlink{classparlai_1_1tasks_1_1squad_1_1agents_1_1TitleTeacher}{Title\+Teacher}
\end{DoxyCompactItemize}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{namespaceparlai_1_1tasks_1_1squad_1_1agents_aedb3f218a9f6d84f322f3b17372bd047}{get\+\_\+sentence\+\_\+tokenizer} ()
\end{DoxyCompactItemize}


\subsection{Function Documentation}
\mbox{\Hypertarget{namespaceparlai_1_1tasks_1_1squad_1_1agents_aedb3f218a9f6d84f322f3b17372bd047}\label{namespaceparlai_1_1tasks_1_1squad_1_1agents_aedb3f218a9f6d84f322f3b17372bd047}} 
\index{parlai\+::tasks\+::squad\+::agents@{parlai\+::tasks\+::squad\+::agents}!get\+\_\+sentence\+\_\+tokenizer@{get\+\_\+sentence\+\_\+tokenizer}}
\index{get\+\_\+sentence\+\_\+tokenizer@{get\+\_\+sentence\+\_\+tokenizer}!parlai\+::tasks\+::squad\+::agents@{parlai\+::tasks\+::squad\+::agents}}
\subsubsection{\texorpdfstring{get\+\_\+sentence\+\_\+tokenizer()}{get\_sentence\_tokenizer()}}
{\footnotesize\ttfamily def parlai.\+tasks.\+squad.\+agents.\+get\+\_\+sentence\+\_\+tokenizer (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

\begin{DoxyVerb}Loads the nltk sentence tokenizer.
\end{DoxyVerb}
 

Definition at line 15 of file agents.\+py.


\begin{DoxyCode}
15 \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1tasks_1_1squad_1_1agents_aedb3f218a9f6d84f322f3b17372bd047}{get\_sentence\_tokenizer}():
16     \textcolor{stringliteral}{"""}
17 \textcolor{stringliteral}{    Loads the nltk sentence tokenizer.}
18 \textcolor{stringliteral}{    """}
19     \textcolor{keywordflow}{try}:
20         \textcolor{keyword}{import} nltk
21     \textcolor{keywordflow}{except} ImportError:
22         \textcolor{keywordflow}{raise} ImportError(\textcolor{stringliteral}{'Please install nltk (e.g. pip install nltk).'})
23     \textcolor{comment}{# nltk-specific setup}
24     st\_path = \textcolor{stringliteral}{'tokenizers/punkt/\{0\}.pickle'}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(\textcolor{stringliteral}{'english'})
25     \textcolor{keywordflow}{try}:
26         sent\_tok = nltk.data.load(st\_path)
27     \textcolor{keywordflow}{except} LookupError:
28         nltk.download(\textcolor{stringliteral}{'punkt'})
29         sent\_tok = nltk.data.load(st\_path)
30     \textcolor{keywordflow}{return} sent\_tok
31 
32 
\end{DoxyCode}
