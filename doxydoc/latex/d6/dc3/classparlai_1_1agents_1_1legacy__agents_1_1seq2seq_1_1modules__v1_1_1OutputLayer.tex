\hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer}{}\section{parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer Class Reference}
\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer}\index{parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer@{parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer}}


Inheritance diagram for parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=211pt]{d7/d64/classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=211pt]{da/da3/classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a616c177990a9bf7ea59eb50ebaeaf2c6}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, num\+\_\+features, embeddingsize, hiddensize, \hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad3c1ff9eaf45681a40e70c0b769e33b3}{dropout}=0, \hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ac84c90f5514a9ada2feb1dc20502653f}{numsoftmax}=1, shared\+\_\+weight=None, \hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a7f6c19fac0b6133b396eb9c724a84562}{padding\+\_\+idx}=-\/1)
\item 
def \hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a0e8baf4ecbc8a3ff9e6a04aa313e7021}{reset\+\_\+parameters} (self)
\item 
def \hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad631d05ca77591036d35f3ce70a4fe4f}{forward} (self, input)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad3c1ff9eaf45681a40e70c0b769e33b3}{dropout}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a7f6c19fac0b6133b396eb9c724a84562}{padding\+\_\+idx}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a3ab9ef74e6f7707aa1cc6836130c60b8}{e2s}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_aa16722ddd0a958a40f91d8f9c6b77b11}{weight}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a7433cdae585595f17189bfa0e72d1eff}{bias}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ac84c90f5514a9ada2feb1dc20502653f}{numsoftmax}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a41ecc03fc87d6cd00a283ad2a0064f75}{esz}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a493a0c8e16a2408821bf384c6f4c5f3c}{softmax}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_af3e2e3aef27d46b86b465d9e11fee5f4}{prior}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a56740b60df8571108f99e18e5bedfc91}{latent}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad3133ae3076f535f3a4e6c1e0c151082}{activation}
\item 
\hyperlink{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_aa849464b1e10b672cf3e3b988d170ad3}{o2e}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}Takes in final states and returns distribution over candidates.
\end{DoxyVerb}
 

Definition at line 597 of file modules\+\_\+v1.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a616c177990a9bf7ea59eb50ebaeaf2c6}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a616c177990a9bf7ea59eb50ebaeaf2c6}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{num\+\_\+features,  }\item[{}]{embeddingsize,  }\item[{}]{hiddensize,  }\item[{}]{dropout = {\ttfamily 0},  }\item[{}]{numsoftmax = {\ttfamily 1},  }\item[{}]{shared\+\_\+weight = {\ttfamily None},  }\item[{}]{padding\+\_\+idx = {\ttfamily -\/1} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Initialize output layer.

:param num_features:  number of candidates to rank
:param hiddensize:    (last) dimension of the input vectors
:param embeddingsize: (last) dimension of the candidate vectors
:param numsoftmax:   (default 1) number of softmaxes to calculate.
              see arxiv.org/abs/1711.03953 for more info.
              increasing this slows down computation but can
              add more expressivity to the embeddings.
:param shared_weight: (num_features x esz) vector of weights to use as
              the final linear layer's weight matrix. default
              None starts with a new linear layer.
:param padding_idx:   model should output a large negative number for
              score at this index. if set to -1 (default),
              this is disabled. if >= 0, subtracts one from
              num_features and always outputs -1e20 at this
              index. only used when shared_weight is not None.
              setting this param helps protect gradient from
              entering shared embedding matrices.
\end{DoxyVerb}
 

Definition at line 611 of file modules\+\_\+v1.\+py.


\begin{DoxyCode}
611     ):
612         \textcolor{stringliteral}{"""}
613 \textcolor{stringliteral}{        Initialize output layer.}
614 \textcolor{stringliteral}{}
615 \textcolor{stringliteral}{        :param num\_features:  number of candidates to rank}
616 \textcolor{stringliteral}{        :param hiddensize:    (last) dimension of the input vectors}
617 \textcolor{stringliteral}{        :param embeddingsize: (last) dimension of the candidate vectors}
618 \textcolor{stringliteral}{        :param numsoftmax:   (default 1) number of softmaxes to calculate.}
619 \textcolor{stringliteral}{                              see arxiv.org/abs/1711.03953 for more info.}
620 \textcolor{stringliteral}{                              increasing this slows down computation but can}
621 \textcolor{stringliteral}{                              add more expressivity to the embeddings.}
622 \textcolor{stringliteral}{        :param shared\_weight: (num\_features x esz) vector of weights to use as}
623 \textcolor{stringliteral}{                              the final linear layer's weight matrix. default}
624 \textcolor{stringliteral}{                              None starts with a new linear layer.}
625 \textcolor{stringliteral}{        :param padding\_idx:   model should output a large negative number for}
626 \textcolor{stringliteral}{                              score at this index. if set to -1 (default),}
627 \textcolor{stringliteral}{                              this is disabled. if >= 0, subtracts one from}
628 \textcolor{stringliteral}{                              num\_features and always outputs -1e20 at this}
629 \textcolor{stringliteral}{                              index. only used when shared\_weight is not None.}
630 \textcolor{stringliteral}{                              setting this param helps protect gradient from}
631 \textcolor{stringliteral}{                              entering shared embedding matrices.}
632 \textcolor{stringliteral}{        """}
633         super().\_\_init\_\_()
634         self.dropout = nn.Dropout(p=dropout)
635 
636         self.padding\_idx = padding\_idx \textcolor{keywordflow}{if} shared\_weight \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} -1
637 
638         \textcolor{comment}{# embedding to scores}
639         \textcolor{keywordflow}{if} shared\_weight \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
640             \textcolor{comment}{# just a regular linear layer}
641             self.e2s = nn.Linear(embeddingsize, num\_features, bias=\textcolor{keyword}{True})
642         \textcolor{keywordflow}{else}:
643             \textcolor{comment}{# use shared weights and a bias layer instead}
644             \textcolor{keywordflow}{if} padding\_idx == 0:
645                 num\_features -= 1  \textcolor{comment}{# don't include padding}
646                 shared\_weight = shared\_weight.narrow(0, 1, num\_features)
647             \textcolor{keywordflow}{elif} padding\_idx > 0:
648                 \textcolor{keywordflow}{raise} RuntimeError(\textcolor{stringliteral}{'nonzero pad\_idx not yet implemented'})
649             self.weight = Parameter(shared\_weight)
650             self.bias = Parameter(torch.Tensor(num\_features))
651             self.reset\_parameters()
652             self.e2s = \textcolor{keyword}{lambda} x: F.linear(x, self.weight, self.bias)
653 
654         self.numsoftmax = numsoftmax
655         \textcolor{keywordflow}{if} numsoftmax > 1:
656             self.esz = embeddingsize
657             self.softmax = nn.Softmax(dim=1)
658             self.prior = nn.Linear(hiddensize, numsoftmax, bias=\textcolor{keyword}{False})
659             self.latent = nn.Linear(hiddensize, numsoftmax * embeddingsize)
660             self.activation = nn.Tanh()
661         \textcolor{keywordflow}{else}:
662             \textcolor{comment}{# rnn output to embedding}
663             \textcolor{keywordflow}{if} hiddensize != embeddingsize:
664                 \textcolor{comment}{# learn projection to correct dimensions}
665                 self.o2e = nn.Linear(hiddensize, embeddingsize, bias=\textcolor{keyword}{True})
666             \textcolor{keywordflow}{else}:
667                 \textcolor{comment}{# no need for any transformation here}
668                 self.o2e = \textcolor{keyword}{lambda} x: x
669 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad631d05ca77591036d35f3ce70a4fe4f}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad631d05ca77591036d35f3ce70a4fe4f}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!forward@{forward}}
\index{forward@{forward}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily def parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+forward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{input }\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute scores from inputs.

:param input: (bsz x seq_len x num_directions * hiddensize) tensor of
       states, e.g. the output states of an RNN

:returns: (bsz x seqlen x num_cands) scores for each candidate
\end{DoxyVerb}
 

Definition at line 678 of file modules\+\_\+v1.\+py.


\begin{DoxyCode}
678     \textcolor{keyword}{def }forward(self, input):
679         \textcolor{stringliteral}{"""}
680 \textcolor{stringliteral}{        Compute scores from inputs.}
681 \textcolor{stringliteral}{}
682 \textcolor{stringliteral}{        :param input: (bsz x seq\_len x num\_directions * hiddensize) tensor of}
683 \textcolor{stringliteral}{                       states, e.g. the output states of an RNN}
684 \textcolor{stringliteral}{}
685 \textcolor{stringliteral}{        :returns: (bsz x seqlen x num\_cands) scores for each candidate}
686 \textcolor{stringliteral}{        """}
687         \textcolor{comment}{# next compute scores over dictionary}
688         \textcolor{keywordflow}{if} self.numsoftmax > 1:
689             bsz = input.size(0)
690             seqlen = input.size(1) \textcolor{keywordflow}{if} input.dim() > 1 \textcolor{keywordflow}{else} 1
691 
692             \textcolor{comment}{# first compute different softmax scores based on input vec}
693             \textcolor{comment}{# hsz => numsoftmax * esz}
694             latent = self.latent(input)
695             active = self.dropout(self.activation(latent))
696             \textcolor{comment}{# esz => num\_features}
697             logit = self.e2s(active.view(-1, self.esz))
698 
699             \textcolor{comment}{# calculate priors: distribution over which softmax scores to use}
700             \textcolor{comment}{# hsz => numsoftmax}
701             prior\_logit = self.prior(input).view(-1, self.numsoftmax)
702             \textcolor{comment}{# softmax over numsoftmax's}
703             prior = self.softmax(prior\_logit)
704 
705             \textcolor{comment}{# now combine priors with logits}
706             prob = self.softmax(logit).view(bsz * seqlen, self.numsoftmax, -1)
707             probs = (prob * prior.unsqueeze(2)).sum(1).view(bsz, seqlen, -1)
708             scores = probs.log()
709         \textcolor{keywordflow}{else}:
710             \textcolor{comment}{# hsz => esz, good time for dropout}
711             e = self.dropout(self.o2e(input))
712             \textcolor{comment}{# esz => num\_features}
713             scores = self.e2s(e)
714 
715         \textcolor{keywordflow}{if} self.padding\_idx == 0:
716             pad\_score = scores.new(scores.size(0), scores.size(1), 1).fill\_(-NEAR\_INF)
717             scores = torch.cat([pad\_score, scores], dim=-1)
718 
719         \textcolor{keywordflow}{return} scores
720 
721 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a0e8baf4ecbc8a3ff9e6a04aa313e7021}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a0e8baf4ecbc8a3ff9e6a04aa313e7021}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!reset\+\_\+parameters@{reset\+\_\+parameters}}
\index{reset\+\_\+parameters@{reset\+\_\+parameters}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{reset\+\_\+parameters()}{reset\_parameters()}}
{\footnotesize\ttfamily def parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+reset\+\_\+parameters (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reset bias param.
\end{DoxyVerb}
 

Definition at line 670 of file modules\+\_\+v1.\+py.


\begin{DoxyCode}
670     \textcolor{keyword}{def }reset\_parameters(self):
671         \textcolor{stringliteral}{"""}
672 \textcolor{stringliteral}{        Reset bias param.}
673 \textcolor{stringliteral}{        """}
674         \textcolor{keywordflow}{if} hasattr(self, \textcolor{stringliteral}{'bias'}):
675             stdv = 1.0 / math.sqrt(self.bias.size(0))
676             self.bias.data.uniform\_(-stdv, stdv)
677 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad3133ae3076f535f3a4e6c1e0c151082}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad3133ae3076f535f3a4e6c1e0c151082}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!activation@{activation}}
\index{activation@{activation}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{activation}{activation}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+activation}



Definition at line 660 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a7433cdae585595f17189bfa0e72d1eff}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a7433cdae585595f17189bfa0e72d1eff}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!bias@{bias}}
\index{bias@{bias}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{bias}{bias}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+bias}



Definition at line 650 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad3c1ff9eaf45681a40e70c0b769e33b3}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ad3c1ff9eaf45681a40e70c0b769e33b3}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!dropout@{dropout}}
\index{dropout@{dropout}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{dropout}{dropout}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+dropout}



Definition at line 634 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a3ab9ef74e6f7707aa1cc6836130c60b8}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a3ab9ef74e6f7707aa1cc6836130c60b8}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!e2s@{e2s}}
\index{e2s@{e2s}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{e2s}{e2s}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+e2s}



Definition at line 641 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a41ecc03fc87d6cd00a283ad2a0064f75}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a41ecc03fc87d6cd00a283ad2a0064f75}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!esz@{esz}}
\index{esz@{esz}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{esz}{esz}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+esz}



Definition at line 656 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a56740b60df8571108f99e18e5bedfc91}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a56740b60df8571108f99e18e5bedfc91}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!latent@{latent}}
\index{latent@{latent}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{latent}{latent}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+latent}



Definition at line 659 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ac84c90f5514a9ada2feb1dc20502653f}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_ac84c90f5514a9ada2feb1dc20502653f}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!numsoftmax@{numsoftmax}}
\index{numsoftmax@{numsoftmax}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{numsoftmax}{numsoftmax}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+numsoftmax}



Definition at line 654 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_aa849464b1e10b672cf3e3b988d170ad3}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_aa849464b1e10b672cf3e3b988d170ad3}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!o2e@{o2e}}
\index{o2e@{o2e}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{o2e}{o2e}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+o2e}



Definition at line 665 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a7f6c19fac0b6133b396eb9c724a84562}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a7f6c19fac0b6133b396eb9c724a84562}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!padding\+\_\+idx@{padding\+\_\+idx}}
\index{padding\+\_\+idx@{padding\+\_\+idx}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{padding\+\_\+idx}{padding\_idx}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+padding\+\_\+idx}



Definition at line 636 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_af3e2e3aef27d46b86b465d9e11fee5f4}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_af3e2e3aef27d46b86b465d9e11fee5f4}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!prior@{prior}}
\index{prior@{prior}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{prior}{prior}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+prior}



Definition at line 658 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a493a0c8e16a2408821bf384c6f4c5f3c}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_a493a0c8e16a2408821bf384c6f4c5f3c}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!softmax@{softmax}}
\index{softmax@{softmax}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{softmax}{softmax}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+softmax}



Definition at line 657 of file modules\+\_\+v1.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_aa16722ddd0a958a40f91d8f9c6b77b11}\label{classparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1modules__v1_1_1OutputLayer_aa16722ddd0a958a40f91d8f9c6b77b11}} 
\index{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}!weight@{weight}}
\index{weight@{weight}!parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer@{parlai\+::agents\+::legacy\+\_\+agents\+::seq2seq\+::modules\+\_\+v1\+::\+Output\+Layer}}
\subsubsection{\texorpdfstring{weight}{weight}}
{\footnotesize\ttfamily parlai.\+agents.\+legacy\+\_\+agents.\+seq2seq.\+modules\+\_\+v1.\+Output\+Layer.\+weight}



Definition at line 649 of file modules\+\_\+v1.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/agents/legacy\+\_\+agents/seq2seq/\hyperlink{modules__v1_8py}{modules\+\_\+v1.\+py}\end{DoxyCompactItemize}
