\hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent}{}\section{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent Class Reference}
\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent}\index{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent@{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent}}


Inheritance diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{df/d9f/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=261pt]{d5/d12/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a9b840de6769acee3aac913d25c448a1d}{upgrade\+\_\+opt}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad2e2f6361e46785d0b79e4c5031e5710}{add\+\_\+cmdline\+\_\+args} (cls, argparser)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a994ed6de4104aa3135deed2fcba75520}{\+\_\+\+\_\+init\+\_\+\+\_\+}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8f8437dd8d0dc44f941dbc6182121284}{build\+\_\+criterion} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8a3c13d2b8988d2a0cbb71f44ae81f52}{set\+\_\+interactive\+\_\+mode} (self, mode, shared=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7cac9c087d7357d32a7c3bc8fa74930c}{reset\+\_\+metrics} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad10e64dd33f1add04ba5bcf36b86c2bf}{share} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3ed32722f939a8afd258830b7093fc18}{report} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a66f36d7201bc1b9a019d3525a5934cf7}{vectorize} (self, args, kwargs)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a94808a13bba0d5283613acd98516bd3c}{compute\+\_\+loss} (self, batch, return\+\_\+output=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_afe2226ddfc838ec27580e3499cc0bae7}{train\+\_\+step} (self, batch)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ac584268dd08c6fcb0045aa968cad8561}{eval\+\_\+step} (self, batch)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_acf02a68b75948cf5bafb24be48813127}{beam\+\_\+size}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a63f7f11d4917e843498e95dc87e30eb1}{beam\+\_\+min\+\_\+length}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a64484ea8971fc2a665e99f99a60f0653}{beam\+\_\+block\+\_\+ngram}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7991351ff26caf7c59e24fe2e36bf6ea}{beam\+\_\+context\+\_\+block\+\_\+ngram}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ab6ff17d050234854c4ce34fbff73bf79}{output\+\_\+token\+\_\+losses}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad44b60dfb7bc5576ff108ed5a1d1c227}{compute\+\_\+tokenized\+\_\+bleu}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8dedd6cbd8e87332284d6ef993d02eea}{fairseq\+\_\+bleu\+\_\+scorer}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a20d87620f983b47787280389465ec61e}{ntlk\+\_\+bleu\+\_\+scores}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_aa6f478c963651331f919fc0ebd44bac3}{criterion}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3b661c0eb6f3e65f061908142819bdc2}{model}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a713b4b7ae6d30a664c97c4ea121f8e38}{skip\+\_\+generation}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a427057bbe1b2182e5bbd476b7739de31}{buffer\+\_\+initialized}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a56e1c7094c455837b9f8976d314d10f4}{nltk\+\_\+bleu\+\_\+scores}
\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\begin{DoxyVerb}Abstract Generator agent; only meant to be extended.

TorchGeneratorAgent aims to handle much of the bookkeeping and infrastructure work
for any generative models, like seq2seq or transformer. It implements the train_step
and eval_step. The only requirement is that your model *must* implemented the
interface TorchGeneratorModel interface.
\end{DoxyVerb}
 

Definition at line 251 of file torch\+\_\+generator\+\_\+agent.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a994ed6de4104aa3135deed2fcba75520}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a994ed6de4104aa3135deed2fcba75520}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{opt }\end{DoxyParamCaption})}



Definition at line 343 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
343     \textcolor{keyword}{def }\_\_init\_\_(self, opt: Opt, shared=\textcolor{keywordtype}{None}):
344         init\_model, is\_finetune = self.\_get\_init\_model(opt, shared)
345         super().\_\_init\_\_(opt, shared)
346 
347         self.beam\_size = opt.get(\textcolor{stringliteral}{'beam\_size'}, 1)
348         self.beam\_min\_length = opt.get(\textcolor{stringliteral}{'beam\_min\_length'}, 1)
349         self.beam\_block\_ngram = opt.get(\textcolor{stringliteral}{'beam\_block\_ngram'}, -1)
350         self.beam\_context\_block\_ngram = opt.get(\textcolor{stringliteral}{'beam\_context\_block\_ngram'}, -1)
351 
352         self.beam\_context\_block\_ngram = opt.get(\textcolor{stringliteral}{'beam\_context\_block\_ngram'}, -1)
353 
354         self.output\_token\_losses = opt.get(\textcolor{stringliteral}{'verbose'}, \textcolor{keyword}{False})
355         self.compute\_tokenized\_bleu = opt.get(\textcolor{stringliteral}{'compute\_tokenized\_bleu'}, \textcolor{keyword}{False})
356 
357         \textcolor{keywordflow}{if} shared:
358             \textcolor{comment}{# set up shared properties}
359             states = shared.get(\textcolor{stringliteral}{'states'}, \{\})
360             self.fairseq\_bleu\_scorer = shared[\textcolor{stringliteral}{'fairseq\_bleu\_scorer'}]
361             self.ntlk\_bleu\_scores = shared[\textcolor{stringliteral}{'nltk\_bleu\_scores'}]
362         \textcolor{keywordflow}{else}:
363             \textcolor{comment}{# Note: we cannot change the type of metrics ahead of time, so you}
364             \textcolor{comment}{# should correctly initialize to floats or ints here}
365             self.metrics[\textcolor{stringliteral}{'nll\_loss'}] = 0.0
366             self.metrics[\textcolor{stringliteral}{'loss'}] = 0.0
367             self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] = 0
368             self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}] = 0
369 
370             \textcolor{comment}{# this is not a shared instance of this class, so do full init}
371             self.criterion = self.build\_criterion()
372             self.\_init\_and\_reset\_bleu\_scorers()
373             \textcolor{comment}{# ensure all distributed copies will always be in sync}
374             self.model = self.build\_model()
375 
376             \textcolor{keywordflow}{if} self.model \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{or} self.criterion \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
377                 \textcolor{keywordflow}{raise} AttributeError(
378                     \textcolor{stringliteral}{'build\_model() and build\_criterion() need to return the model or criterion'}
379                 )
380             \textcolor{keywordflow}{if} self.use\_cuda:
381                 self.model.cuda()
382                 self.criterion.cuda()
383 
384             \hyperlink{namespaceparlai_1_1utils_1_1distributed_a47e6d93d849e487d7d3f6e1a83468073}{sync\_parameters}(self.model)
385             print(\textcolor{stringliteral}{"Total parameters: \{\}"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(self.\_total\_parameters()))
386             print(\textcolor{stringliteral}{"Trainable parameters:  \{\}"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(self.\_trainable\_parameters()))
387 
388             \textcolor{keywordflow}{if} self.fp16:
389                 self.model = self.model.half()
390 
391             \textcolor{keywordflow}{if} init\_model \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
392                 \textcolor{comment}{# load model parameters if available}
393                 print(\textcolor{stringliteral}{'[ Loading existing model params from \{\} ]'} \textcolor{stringliteral}{''}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(init\_model))
394                 states = self.load(init\_model)
395             \textcolor{keywordflow}{else}:
396                 states = \{\}
397 
398         \textcolor{keywordflow}{if} (
399             \textcolor{comment}{# only build an optimizer if we're training}
400             \textcolor{stringliteral}{'train'} \textcolor{keywordflow}{in} opt.get(\textcolor{stringliteral}{'datatype'}, \textcolor{stringliteral}{''})
401             \textcolor{comment}{# and this is the main model, or on every fork if doing hogwild}
402             \textcolor{keywordflow}{and} (shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{or} self.opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1)
403         ):
404             \textcolor{comment}{# do this regardless of share state, but don't}
405             self.init\_optim(
406                 [p \textcolor{keywordflow}{for} p \textcolor{keywordflow}{in} self.model.parameters() \textcolor{keywordflow}{if} p.requires\_grad],
407                 optim\_states=states.get(\textcolor{stringliteral}{'optimizer'}),
408                 saved\_optim\_type=states.get(\textcolor{stringliteral}{'optimizer\_type'}),
409             )
410             self.build\_lr\_scheduler(states, hard\_reset=is\_finetune)
411 
412         \textcolor{keywordflow}{if} shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{and} \hyperlink{namespaceparlai_1_1utils_1_1distributed_a023acb5e3b66e1f27e21247c35661279}{is\_distributed}():
413             self.model = torch.nn.parallel.DistributedDataParallel(
414                 self.model, device\_ids=[self.opt[\textcolor{stringliteral}{'gpu'}]], broadcast\_buffers=\textcolor{keyword}{False}
415             )
416 
417         self.reset()
418 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad2e2f6361e46785d0b79e4c5031e5710}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad2e2f6361e46785d0b79e4c5031e5710}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}}
\index{add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{add\+\_\+cmdline\+\_\+args()}{add\_cmdline\_args()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+add\+\_\+cmdline\+\_\+args (\begin{DoxyParamCaption}\item[{}]{cls,  }\item[{}]{argparser }\end{DoxyParamCaption})}

\begin{DoxyVerb}Add command line arguments.
\end{DoxyVerb}
 

Definition at line 280 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
280     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(cls, argparser):
281         \textcolor{stringliteral}{"""}
282 \textcolor{stringliteral}{        Add command line arguments.}
283 \textcolor{stringliteral}{        """}
284         agent = argparser.add\_argument\_group(\textcolor{stringliteral}{'Torch Generator Agent'})
285         agent.add\_argument(
286             \textcolor{stringliteral}{'--beam-size'},
287             type=int,
288             default=1,
289             help=\textcolor{stringliteral}{'Beam size, if 1 then greedy search'},
290         )
291         agent.add\_argument(
292             \textcolor{stringliteral}{'--beam-min-length'},
293             type=int,
294             default=1,
295             help=\textcolor{stringliteral}{'Minimum length of prediction to be generated by the beam search'},
296         )
297         agent.add\_argument(
298             \textcolor{stringliteral}{'--beam-context-block-ngram'},
299             type=int,
300             default=-1,
301             help=(
302                 \textcolor{stringliteral}{'Size n-grams to block in beam search from the context. val <= 0 '}
303                 \textcolor{stringliteral}{'implies no blocking'}
304             ),
305         )
306         agent.add\_argument(
307 
308             \textcolor{stringliteral}{'--beam-block-ngram'},
309             type=int,
310             default=-1,
311             help=\textcolor{stringliteral}{'Size n-grams to block in beam search. val <= 0 implies no blocking'},
312         )
313         agent.add\_argument(
314             \textcolor{stringliteral}{'--skip-generation'},
315             type=\textcolor{stringliteral}{'bool'},
316             default=\textcolor{keyword}{False},
317             hidden=\textcolor{keyword}{True},
318             help=\textcolor{stringliteral}{'Skip beam search. Useful for speeding up training, '}
319             \textcolor{stringliteral}{'if perplexity is the validation metric.'},
320         )
321         agent.add\_argument(
322             \textcolor{stringliteral}{'--inference'},
323             choices=\{\textcolor{stringliteral}{'beam'}, \textcolor{stringliteral}{'greedy'}, \textcolor{stringliteral}{'topk'}, \textcolor{stringliteral}{'nucleus'}\},
324             default=\textcolor{stringliteral}{'greedy'},
325             help=\textcolor{stringliteral}{'Generation algorithm'},
326         )
327         agent.add\_argument(
328             \textcolor{stringliteral}{'--topk'}, type=int, default=10, help=\textcolor{stringliteral}{'K used in Top K sampling'}
329         )
330         agent.add\_argument(
331             \textcolor{stringliteral}{'--topp'}, type=float, default=0.9, help=\textcolor{stringliteral}{'p used in nucleus sampling'}
332         )
333         agent.add\_argument(
334             \textcolor{stringliteral}{'--compute-tokenized-bleu'},
335             type=\textcolor{stringliteral}{'bool'},
336             default=\textcolor{keyword}{False},
337             help=\textcolor{stringliteral}{'if true, compute tokenized bleu scores'},
338         )
339 
340         super(TorchGeneratorAgent, cls).\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(argparser)
341         \textcolor{keywordflow}{return} agent
342 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8f8437dd8d0dc44f941dbc6182121284}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8f8437dd8d0dc44f941dbc6182121284}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!build\+\_\+criterion@{build\+\_\+criterion}}
\index{build\+\_\+criterion@{build\+\_\+criterion}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+criterion()}{build\_criterion()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+build\+\_\+criterion (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Construct and return the loss function.

By default torch.nn.CrossEntropyLoss.

If overridden, this model should produce a sum that can be used for a per-token loss.
\end{DoxyVerb}
 

Definition at line 419 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
419     \textcolor{keyword}{def }build\_criterion(self):
420         \textcolor{stringliteral}{"""}
421 \textcolor{stringliteral}{        Construct and return the loss function.}
422 \textcolor{stringliteral}{}
423 \textcolor{stringliteral}{        By default torch.nn.CrossEntropyLoss.}
424 \textcolor{stringliteral}{}
425 \textcolor{stringliteral}{        If overridden, this model should produce a sum that can be used for a per-token loss.}
426 \textcolor{stringliteral}{        """}
427         \textcolor{keywordflow}{return} torch.nn.CrossEntropyLoss(ignore\_index=self.NULL\_IDX, reduction=\textcolor{stringliteral}{'none'})
428 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a94808a13bba0d5283613acd98516bd3c}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a94808a13bba0d5283613acd98516bd3c}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!compute\+\_\+loss@{compute\+\_\+loss}}
\index{compute\+\_\+loss@{compute\+\_\+loss}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{compute\+\_\+loss()}{compute\_loss()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+compute\+\_\+loss (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch,  }\item[{}]{return\+\_\+output = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute and return the loss for the given batch.

Easily overridable for customized loss functions.

If return_output is True, the full output from the call to self.model()
is also returned, via a (loss, model_output) pair.
\end{DoxyVerb}
 

Definition at line 597 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
597     \textcolor{keyword}{def }compute\_loss(self, batch, return\_output=False):
598         \textcolor{stringliteral}{"""}
599 \textcolor{stringliteral}{        Compute and return the loss for the given batch.}
600 \textcolor{stringliteral}{}
601 \textcolor{stringliteral}{        Easily overridable for customized loss functions.}
602 \textcolor{stringliteral}{}
603 \textcolor{stringliteral}{        If return\_output is True, the full output from the call to self.model()}
604 \textcolor{stringliteral}{        is also returned, via a (loss, model\_output) pair.}
605 \textcolor{stringliteral}{        """}
606         \textcolor{keywordflow}{if} batch.label\_vec \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
607             \textcolor{keywordflow}{raise} ValueError(\textcolor{stringliteral}{'Cannot compute loss without a label.'})
608         model\_output = self.model(*self.\_model\_input(batch), ys=batch.label\_vec)
609         scores, preds, *\_ = model\_output
610         score\_view = scores.view(-1, scores.size(-1))
611         loss = self.criterion(score\_view, batch.label\_vec.view(-1)).sum()
612         \textcolor{comment}{# save loss to metrics}
613         notnull = batch.label\_vec.ne(self.NULL\_IDX)
614         target\_tokens = notnull.long().sum().item()
615         correct = ((batch.label\_vec == preds) * notnull).sum().item()
616         self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] += correct
617         self.metrics[\textcolor{stringliteral}{'nll\_loss'}] += loss.item()
618         self.metrics[\textcolor{stringliteral}{'num\_tokens'}] += target\_tokens
619         loss /= target\_tokens  \textcolor{comment}{# average loss per token}
620         \textcolor{keywordflow}{if} return\_output:
621             \textcolor{keywordflow}{return} (loss, model\_output)
622         \textcolor{keywordflow}{else}:
623             \textcolor{keywordflow}{return} loss
624 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ac584268dd08c6fcb0045aa968cad8561}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ac584268dd08c6fcb0045aa968cad8561}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!eval\+\_\+step@{eval\+\_\+step}}
\index{eval\+\_\+step@{eval\+\_\+step}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{eval\+\_\+step()}{eval\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+eval\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}Evaluate a single batch of examples.
\end{DoxyVerb}
 

Definition at line 743 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
743     \textcolor{keyword}{def }eval\_step(self, batch):
744         \textcolor{stringliteral}{"""}
745 \textcolor{stringliteral}{        Evaluate a single batch of examples.}
746 \textcolor{stringliteral}{        """}
747         \textcolor{keywordflow}{if} batch.text\_vec \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{and} batch.image \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
748             \textcolor{keywordflow}{return}
749         \textcolor{keywordflow}{if} batch.text\_vec \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
750             bsz = batch.text\_vec.size(0)
751         \textcolor{keywordflow}{else}:
752             bsz = len(batch.image)
753         self.model.eval()
754         cand\_scores = \textcolor{keywordtype}{None}
755         token\_losses = \textcolor{keywordtype}{None}
756 
757         \textcolor{keywordflow}{if} batch.label\_vec \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
758             \textcolor{comment}{# calculate loss on targets with teacher forcing}
759             loss, model\_output = self.compute\_loss(batch, return\_output=\textcolor{keyword}{True})
760             self.metrics[\textcolor{stringliteral}{'loss'}] += loss.item()
761             \textcolor{keywordflow}{if} self.output\_token\_losses:
762                 token\_losses = self.\_construct\_token\_losses(
763                     batch.label\_vec, model\_output
764                 )
765 
766         preds = \textcolor{keywordtype}{None}
767         \textcolor{keywordflow}{if} self.skip\_generation:
768             \hyperlink{namespaceparlai_1_1utils_1_1misc_a884a3aefa90581f53bc592fa6a78dc43}{warn\_once}(
769                 \textcolor{stringliteral}{"--skip-generation does not produce accurate metrics beyond ppl"},
770                 RuntimeWarning,
771             )
772         \textcolor{keywordflow}{else}:
773             maxlen = self.label\_truncate \textcolor{keywordflow}{or} 256
774             beam\_preds\_scores, \_ = self.\_generate(batch, self.beam\_size, maxlen)
775             preds, scores = zip(*beam\_preds\_scores)
776 
777         cand\_choices = \textcolor{keywordtype}{None}
778         \textcolor{comment}{# TODO: abstract out the scoring here}
779         \textcolor{keywordflow}{if} self.rank\_candidates:
780             \textcolor{comment}{# compute roughly ppl to rank candidates}
781             cand\_choices = []
782             encoder\_states = self.model.encoder(*self.\_model\_input(batch))
783             \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(bsz):
784                 num\_cands = len(batch.candidate\_vecs[i])
785                 enc = self.model.reorder\_encoder\_states(encoder\_states, [i] * num\_cands)
786                 cands, \_ = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_adb5a414ae439f14c54e8c760b91cc4c8}{padded\_tensor}(
787                     batch.candidate\_vecs[i], self.NULL\_IDX, self.use\_cuda
788                 )
789                 scores, \_ = self.model.decode\_forced(enc, cands)
790                 cand\_losses = F.cross\_entropy(
791                     scores.view(num\_cands * cands.size(1), -1),
792                     cands.view(-1),
793                     reduction=\textcolor{stringliteral}{'none'},
794                 ).view(num\_cands, cands.size(1))
795                 \textcolor{comment}{# now cand\_losses is cands x seqlen size, but we still need to}
796                 \textcolor{comment}{# check padding and such}
797                 mask = (cands != self.NULL\_IDX).\hyperlink{namespaceprojects_1_1controllable__dialogue_1_1make__control__dataset_aa2b7207688c641dbc094ab44eca27113}{float}()
798                 cand\_scores = (cand\_losses * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-9)
799                 \_, ordering = cand\_scores.sort()
800                 cand\_choices.append([batch.candidates[i][o] \textcolor{keywordflow}{for} o \textcolor{keywordflow}{in} ordering])
801 
802         text = [self.\_v2t(p) \textcolor{keywordflow}{for} p \textcolor{keywordflow}{in} preds] \textcolor{keywordflow}{if} preds \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
803         \textcolor{keywordflow}{if} text \textcolor{keywordflow}{and} self.compute\_tokenized\_bleu:
804             \textcolor{comment}{# compute additional bleu scores}
805             self.\_compute\_fairseq\_bleu(batch, text)
806             self.\_compute\_nltk\_bleu(batch, text)
807         \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a2689006ea97d09413fb242f984bd8016}{Output}(text, cand\_choices, token\_losses=token\_losses)
808 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3ed32722f939a8afd258830b7093fc18}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3ed32722f939a8afd258830b7093fc18}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!report@{report}}
\index{report@{report}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{report()}{report()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+report (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Report loss and perplexity from model's perspective.

Note that this includes predicting __END__ and __UNK__ tokens and may differ
from a truly independent measurement.

Additionally report tokenized bleu scores, if desired.
\end{DoxyVerb}
 

Definition at line 526 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
526     \textcolor{keyword}{def }\hyperlink{namespaceprojects_1_1convai2_1_1eval__f1_a01a47b9c08dad189837a51f085defc45}{report}(self):
527         \textcolor{stringliteral}{"""}
528 \textcolor{stringliteral}{        Report loss and perplexity from model's perspective.}
529 \textcolor{stringliteral}{}
530 \textcolor{stringliteral}{        Note that this includes predicting \_\_END\_\_ and \_\_UNK\_\_ tokens and may differ}
531 \textcolor{stringliteral}{        from a truly independent measurement.}
532 \textcolor{stringliteral}{}
533 \textcolor{stringliteral}{        Additionally report tokenized bleu scores, if desired.}
534 \textcolor{stringliteral}{        """}
535         base = super().\hyperlink{namespaceprojects_1_1convai2_1_1eval__f1_a01a47b9c08dad189837a51f085defc45}{report}()
536         m = \{\}
537         num\_tok = self.metrics[\textcolor{stringliteral}{'num\_tokens'}]
538         \textcolor{keywordflow}{if} num\_tok > 0:
539             m[\textcolor{stringliteral}{'loss'}] = self.metrics[\textcolor{stringliteral}{'loss'}]
540             \textcolor{keywordflow}{if} self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] > 0:
541                 m[\textcolor{stringliteral}{'token\_acc'}] = self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] / num\_tok
542             m[\textcolor{stringliteral}{'nll\_loss'}] = self.metrics[\textcolor{stringliteral}{'nll\_loss'}] / num\_tok
543             \textcolor{keywordflow}{try}:
544                 m[\textcolor{stringliteral}{'ppl'}] = math.exp(m[\textcolor{stringliteral}{'nll\_loss'}])
545             \textcolor{keywordflow}{except} OverflowError:
546                 m[\textcolor{stringliteral}{'ppl'}] = \hyperlink{namespaceprojects_1_1controllable__dialogue_1_1make__control__dataset_aa2b7207688c641dbc094ab44eca27113}{float}(\textcolor{stringliteral}{'inf'})
547         \textcolor{keywordflow}{if} self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}] > 0:
548             m[\textcolor{stringliteral}{'total\_skipped\_batches'}] = self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}]
549         \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} m.items():
550             \textcolor{comment}{# clean up: rounds to sigfigs and converts tensors to floats}
551             base[k] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(v, 4)
552         \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} self.skip\_generation \textcolor{keywordflow}{and} self.compute\_tokenized\_bleu:
553             base.update(\{\textcolor{stringliteral}{'fairseq\_bleu'}: \textcolor{stringliteral}{'N/A'}, \textcolor{stringliteral}{'nltk\_bleu\_unnormalized'}: \textcolor{stringliteral}{'N/A'}\})
554             \textcolor{keywordflow}{if} fairseq\_bleu \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
555                 \textcolor{keywordflow}{try}:
556                     fairseq\_bleu\_scores = \{
557                         k: self.fairseq\_bleu\_scorer.result\_string(order=k)
558                         \textcolor{keywordflow}{for} k \textcolor{keywordflow}{in} range(1, 5)
559                     \}
560                 \textcolor{keywordflow}{except} ZeroDivisionError:
561                     \textcolor{comment}{# some preds are REAL bad}
562                     fairseq\_bleu\_scores = \{k: \textcolor{stringliteral}{'= 0,'} \textcolor{keywordflow}{for} k \textcolor{keywordflow}{in} range(1, 5)\}
563 
564                 base[\textcolor{stringliteral}{'fairseq\_bleu'}] = \{
565                     k: \hyperlink{namespaceprojects_1_1controllable__dialogue_1_1make__control__dataset_aa2b7207688c641dbc094ab44eca27113}{float}(v[v.index(\textcolor{stringliteral}{'= '}) + 2 : v.index(\textcolor{stringliteral}{','})])
566                     \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} fairseq\_bleu\_scores.items()
567                 \}
568             \textcolor{keywordflow}{if} nltkbleu \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
569                 base[\textcolor{stringliteral}{'nltk\_bleu\_unnormalized'}] = \{
570                     k: \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(v[\textcolor{stringliteral}{'score'}] / v[\textcolor{stringliteral}{'cnt'}], 4)
571                     \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} self.nltk\_bleu\_scores.items()
572                 \}
573         \textcolor{keywordflow}{return} base
574 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7cac9c087d7357d32a7c3bc8fa74930c}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7cac9c087d7357d32a7c3bc8fa74930c}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!reset\+\_\+metrics@{reset\+\_\+metrics}}
\index{reset\+\_\+metrics@{reset\+\_\+metrics}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{reset\+\_\+metrics()}{reset\_metrics()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+reset\+\_\+metrics (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reset metrics for reporting loss and perplexity.
\end{DoxyVerb}
 

Definition at line 500 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
500     \textcolor{keyword}{def }reset\_metrics(self):
501         \textcolor{stringliteral}{"""}
502 \textcolor{stringliteral}{        Reset metrics for reporting loss and perplexity.}
503 \textcolor{stringliteral}{        """}
504         super().reset\_metrics()
505         \textcolor{comment}{# Note: we cannot change the type of metrics ahead of time, so you}
506         \textcolor{comment}{# should correctly initialize to floats or ints here}
507         self.metrics[\textcolor{stringliteral}{'loss'}] = 0.0
508         self.metrics[\textcolor{stringliteral}{'nll\_loss'}] = 0.0
509         self.metrics[\textcolor{stringliteral}{'num\_tokens'}] = 0
510         self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] = 0
511         self.\_init\_and\_reset\_bleu\_scorers()
512 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8a3c13d2b8988d2a0cbb71f44ae81f52}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8a3c13d2b8988d2a0cbb71f44ae81f52}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}}
\index{set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{set\+\_\+interactive\+\_\+mode()}{set\_interactive\_mode()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+set\+\_\+interactive\+\_\+mode (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{mode,  }\item[{}]{shared = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Turn on interactive mode.
\end{DoxyVerb}
 

Definition at line 443 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
443     \textcolor{keyword}{def }set\_interactive\_mode(self, mode, shared=False):
444         \textcolor{stringliteral}{"""}
445 \textcolor{stringliteral}{        Turn on interactive mode.}
446 \textcolor{stringliteral}{        """}
447         super().set\_interactive\_mode(mode, shared)
448         \textcolor{keywordflow}{if} mode:
449             self.skip\_generation = \textcolor{keyword}{False}
450         \textcolor{keywordflow}{else}:
451             self.skip\_generation = self.opt.get(\textcolor{stringliteral}{'skip\_generation'}, \textcolor{keyword}{False})
452 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad10e64dd33f1add04ba5bcf36b86c2bf}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad10e64dd33f1add04ba5bcf36b86c2bf}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!share@{share}}
\index{share@{share}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{share()}{share()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+share (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Share internal states between parent and child instances.
\end{DoxyVerb}
 

Definition at line 513 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
513     \textcolor{keyword}{def }share(self):
514         \textcolor{stringliteral}{"""}
515 \textcolor{stringliteral}{        Share internal states between parent and child instances.}
516 \textcolor{stringliteral}{        """}
517         shared = super().share()
518         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1:
519             shared[\textcolor{stringliteral}{'states'}] = \{  \textcolor{comment}{# don't share optimizer states}
520                 \textcolor{stringliteral}{'optimizer\_type'}: self.opt[\textcolor{stringliteral}{'optimizer'}]
521             \}
522         shared[\textcolor{stringliteral}{'fairseq\_bleu\_scorer'}] = self.fairseq\_bleu\_scorer
523         shared[\textcolor{stringliteral}{'nltk\_bleu\_scores'}] = self.nltk\_bleu\_scores
524         \textcolor{keywordflow}{return} shared
525 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_afe2226ddfc838ec27580e3499cc0bae7}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_afe2226ddfc838ec27580e3499cc0bae7}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!train\+\_\+step@{train\+\_\+step}}
\index{train\+\_\+step@{train\+\_\+step}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{train\+\_\+step()}{train\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+train\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}Train on a single batch of examples.
\end{DoxyVerb}
 

Definition at line 625 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
625     \textcolor{keyword}{def }train\_step(self, batch):
626         \textcolor{stringliteral}{"""}
627 \textcolor{stringliteral}{        Train on a single batch of examples.}
628 \textcolor{stringliteral}{        """}
629         \textcolor{keywordflow}{if} batch.text\_vec \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
630             batchsize = batch.text\_vec.size(0)
631         \textcolor{keywordflow}{elif} batch.image \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
632             batchsize = len(batch.image)
633         \textcolor{comment}{# helps with memory usage}
634         self.\_init\_cuda\_buffer(batchsize, self.truncate \textcolor{keywordflow}{or} 256)
635         self.model.\hyperlink{namespaceprojects_1_1mastering__the__dungeon_1_1mturk_1_1tasks_1_1MTD_1_1run_a36a5f4f6f9df0611a6818610518d2cf0}{train}()
636         self.zero\_grad()
637 
638         \textcolor{keywordflow}{try}:
639             loss = self.compute\_loss(batch)
640             self.metrics[\textcolor{stringliteral}{'loss'}] += loss.item()
641             self.backward(loss)
642             self.update\_params()
643         \textcolor{keywordflow}{except} RuntimeError \textcolor{keyword}{as} e:
644             \textcolor{comment}{# catch out of memory exceptions during fwd/bck (skip batch)}
645             \textcolor{keywordflow}{if} \textcolor{stringliteral}{'out of memory'} \textcolor{keywordflow}{in} \hyperlink{namespacegenerate__task__READMEs_a5b88452ffb87b78c8c85ececebafc09f}{str}(e):
646                 print(
647                     \textcolor{stringliteral}{'| WARNING: ran out of memory, skipping batch. '}
648                     \textcolor{stringliteral}{'if this happens frequently, decrease batchsize or '}
649                     \textcolor{stringliteral}{'truncate the inputs to the model.'}
650                 )
651                 self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}] += 1
652                 \textcolor{comment}{# gradients are synced on backward, now this model is going to be}
653                 \textcolor{comment}{# out of sync! catch up with the other workers}
654                 self.\_init\_cuda\_buffer(8, 8, \textcolor{keyword}{True})
655             \textcolor{keywordflow}{else}:
656                 \textcolor{keywordflow}{raise} e
657 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a9b840de6769acee3aac913d25c448a1d}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a9b840de6769acee3aac913d25c448a1d}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!upgrade\+\_\+opt@{upgrade\+\_\+opt}}
\index{upgrade\+\_\+opt@{upgrade\+\_\+opt}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{upgrade\+\_\+opt()}{upgrade\_opt()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+upgrade\+\_\+opt (\begin{DoxyParamCaption}\item[{}]{cls,  }\item[{}]{opt\+\_\+from\+\_\+disk }\end{DoxyParamCaption})}



Definition at line 262 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
262     \textcolor{keyword}{def }upgrade\_opt(cls, opt\_from\_disk: Opt):
263         \textcolor{comment}{# call the parent upgrades}
264         opt\_from\_disk = super(TorchGeneratorAgent, cls).upgrade\_opt(opt\_from\_disk)
265 
266         \textcolor{comment}{# 2019-08-18: Adding support for generation other than beam search}
267         \textcolor{comment}{# Previously, selecting --beam-size > 1 enabled beam search and == 1 was}
268         \textcolor{comment}{# greedy. New behavior is --inference greedy or --inference beam.}
269         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'inference'} \textcolor{keywordflow}{not} \textcolor{keywordflow}{in} opt\_from\_disk:
270             \textcolor{keyword}{assert} \textcolor{stringliteral}{'beam\_size'} \textcolor{keywordflow}{in} opt\_from\_disk
271             \textcolor{keywordflow}{if} opt\_from\_disk[\textcolor{stringliteral}{'beam\_size'}] == 1:
272                 method = \textcolor{stringliteral}{'greedy'}
273             \textcolor{keywordflow}{else}:
274                 method = \textcolor{stringliteral}{'beam'}
275             opt\_from\_disk[\textcolor{stringliteral}{'inference'}] = method
276             \hyperlink{namespaceparlai_1_1utils_1_1misc_a884a3aefa90581f53bc592fa6a78dc43}{warn\_once}(f\textcolor{stringliteral}{'Old model inference method inferred as \{method\}'})
277         \textcolor{keywordflow}{return} opt\_from\_disk
278 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a66f36d7201bc1b9a019d3525a5934cf7}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a66f36d7201bc1b9a019d3525a5934cf7}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!vectorize@{vectorize}}
\index{vectorize@{vectorize}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{vectorize()}{vectorize()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+vectorize (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{args,  }\item[{}]{kwargs }\end{DoxyParamCaption})}

\begin{DoxyVerb}Override vectorize for generative models.
\end{DoxyVerb}
 

Definition at line 575 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
575     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1utils_a5c76cc39e3014c7bcf9199d566dbdc0f}{vectorize}(self, *args, **kwargs):
576         \textcolor{stringliteral}{"""}
577 \textcolor{stringliteral}{        Override vectorize for generative models.}
578 \textcolor{stringliteral}{        """}
579         kwargs[\textcolor{stringliteral}{'add\_start'}] = \textcolor{keyword}{False}  \textcolor{comment}{# model does this in module code}
580         kwargs[\textcolor{stringliteral}{'add\_end'}] = \textcolor{keyword}{True}  \textcolor{comment}{# we do want this}
581         \textcolor{keywordflow}{return} super().\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1utils_a5c76cc39e3014c7bcf9199d566dbdc0f}{vectorize}(*args, **kwargs)
582 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a64484ea8971fc2a665e99f99a60f0653}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a64484ea8971fc2a665e99f99a60f0653}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+block\+\_\+ngram@{beam\+\_\+block\+\_\+ngram}}
\index{beam\+\_\+block\+\_\+ngram@{beam\+\_\+block\+\_\+ngram}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+block\+\_\+ngram}{beam\_block\_ngram}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+block\+\_\+ngram}



Definition at line 349 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7991351ff26caf7c59e24fe2e36bf6ea}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7991351ff26caf7c59e24fe2e36bf6ea}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+context\+\_\+block\+\_\+ngram@{beam\+\_\+context\+\_\+block\+\_\+ngram}}
\index{beam\+\_\+context\+\_\+block\+\_\+ngram@{beam\+\_\+context\+\_\+block\+\_\+ngram}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+context\+\_\+block\+\_\+ngram}{beam\_context\_block\_ngram}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+context\+\_\+block\+\_\+ngram}



Definition at line 350 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a63f7f11d4917e843498e95dc87e30eb1}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a63f7f11d4917e843498e95dc87e30eb1}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+min\+\_\+length@{beam\+\_\+min\+\_\+length}}
\index{beam\+\_\+min\+\_\+length@{beam\+\_\+min\+\_\+length}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+min\+\_\+length}{beam\_min\_length}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+min\+\_\+length}



Definition at line 348 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_acf02a68b75948cf5bafb24be48813127}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_acf02a68b75948cf5bafb24be48813127}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+size@{beam\+\_\+size}}
\index{beam\+\_\+size@{beam\+\_\+size}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+size}{beam\_size}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+size}



Definition at line 347 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a427057bbe1b2182e5bbd476b7739de31}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a427057bbe1b2182e5bbd476b7739de31}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!buffer\+\_\+initialized@{buffer\+\_\+initialized}}
\index{buffer\+\_\+initialized@{buffer\+\_\+initialized}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{buffer\+\_\+initialized}{buffer\_initialized}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+buffer\+\_\+initialized}



Definition at line 476 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad44b60dfb7bc5576ff108ed5a1d1c227}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad44b60dfb7bc5576ff108ed5a1d1c227}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!compute\+\_\+tokenized\+\_\+bleu@{compute\+\_\+tokenized\+\_\+bleu}}
\index{compute\+\_\+tokenized\+\_\+bleu@{compute\+\_\+tokenized\+\_\+bleu}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{compute\+\_\+tokenized\+\_\+bleu}{compute\_tokenized\_bleu}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+compute\+\_\+tokenized\+\_\+bleu}



Definition at line 355 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_aa6f478c963651331f919fc0ebd44bac3}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_aa6f478c963651331f919fc0ebd44bac3}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!criterion@{criterion}}
\index{criterion@{criterion}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{criterion}{criterion}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+criterion}



Definition at line 371 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8dedd6cbd8e87332284d6ef993d02eea}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8dedd6cbd8e87332284d6ef993d02eea}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!fairseq\+\_\+bleu\+\_\+scorer@{fairseq\+\_\+bleu\+\_\+scorer}}
\index{fairseq\+\_\+bleu\+\_\+scorer@{fairseq\+\_\+bleu\+\_\+scorer}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{fairseq\+\_\+bleu\+\_\+scorer}{fairseq\_bleu\_scorer}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+fairseq\+\_\+bleu\+\_\+scorer}



Definition at line 360 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3b661c0eb6f3e65f061908142819bdc2}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3b661c0eb6f3e65f061908142819bdc2}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!model@{model}}
\index{model@{model}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{model}{model}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+model}



Definition at line 374 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a56e1c7094c455837b9f8976d314d10f4}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a56e1c7094c455837b9f8976d314d10f4}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!nltk\+\_\+bleu\+\_\+scores@{nltk\+\_\+bleu\+\_\+scores}}
\index{nltk\+\_\+bleu\+\_\+scores@{nltk\+\_\+bleu\+\_\+scores}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{nltk\+\_\+bleu\+\_\+scores}{nltk\_bleu\_scores}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+nltk\+\_\+bleu\+\_\+scores}



Definition at line 496 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a20d87620f983b47787280389465ec61e}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a20d87620f983b47787280389465ec61e}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!ntlk\+\_\+bleu\+\_\+scores@{ntlk\+\_\+bleu\+\_\+scores}}
\index{ntlk\+\_\+bleu\+\_\+scores@{ntlk\+\_\+bleu\+\_\+scores}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{ntlk\+\_\+bleu\+\_\+scores}{ntlk\_bleu\_scores}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+ntlk\+\_\+bleu\+\_\+scores}



Definition at line 361 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ab6ff17d050234854c4ce34fbff73bf79}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ab6ff17d050234854c4ce34fbff73bf79}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!output\+\_\+token\+\_\+losses@{output\+\_\+token\+\_\+losses}}
\index{output\+\_\+token\+\_\+losses@{output\+\_\+token\+\_\+losses}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{output\+\_\+token\+\_\+losses}{output\_token\_losses}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+output\+\_\+token\+\_\+losses}



Definition at line 354 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a713b4b7ae6d30a664c97c4ea121f8e38}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a713b4b7ae6d30a664c97c4ea121f8e38}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!skip\+\_\+generation@{skip\+\_\+generation}}
\index{skip\+\_\+generation@{skip\+\_\+generation}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{skip\+\_\+generation}{skip\_generation}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+skip\+\_\+generation}



Definition at line 449 of file torch\+\_\+generator\+\_\+agent.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/core/\hyperlink{torch__generator__agent_8py}{torch\+\_\+generator\+\_\+agent.\+py}\end{DoxyCompactItemize}
