\hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent}{}\section{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent Class Reference}
\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent}\index{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent@{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent}}


Inheritance diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{df/d9f/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=318pt]{d5/d12/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8bb3183c7de0e8831157536c6ce1751b}{upgrade\+\_\+opt} (cls, opt\+\_\+from\+\_\+disk)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad2e2f6361e46785d0b79e4c5031e5710}{add\+\_\+cmdline\+\_\+args} (cls, argparser)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a60f9613d8d2761569c8862b690b24bce}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, \hyperlink{classparlai_1_1core_1_1torch__agent_1_1TorchAgent_a785bb920cf8c8afc3e9bf6a8b77e335a}{opt}, shared=None)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8f8437dd8d0dc44f941dbc6182121284}{build\+\_\+criterion} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8a3c13d2b8988d2a0cbb71f44ae81f52}{set\+\_\+interactive\+\_\+mode} (self, mode, shared=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7cac9c087d7357d32a7c3bc8fa74930c}{reset\+\_\+metrics} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad10e64dd33f1add04ba5bcf36b86c2bf}{share} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3ed32722f939a8afd258830b7093fc18}{report} (self)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a66f36d7201bc1b9a019d3525a5934cf7}{vectorize} (self, args, kwargs)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a94808a13bba0d5283613acd98516bd3c}{compute\+\_\+loss} (self, batch, return\+\_\+output=False)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_afe2226ddfc838ec27580e3499cc0bae7}{train\+\_\+step} (self, batch)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ac584268dd08c6fcb0045aa968cad8561}{eval\+\_\+step} (self, batch)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_acf02a68b75948cf5bafb24be48813127}{beam\+\_\+size}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a63f7f11d4917e843498e95dc87e30eb1}{beam\+\_\+min\+\_\+length}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a64484ea8971fc2a665e99f99a60f0653}{beam\+\_\+block\+\_\+ngram}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7991351ff26caf7c59e24fe2e36bf6ea}{beam\+\_\+context\+\_\+block\+\_\+ngram}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ab6ff17d050234854c4ce34fbff73bf79}{output\+\_\+token\+\_\+losses}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_aa6f478c963651331f919fc0ebd44bac3}{criterion}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3b661c0eb6f3e65f061908142819bdc2}{model}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a713b4b7ae6d30a664c97c4ea121f8e38}{skip\+\_\+generation}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a427057bbe1b2182e5bbd476b7739de31}{buffer\+\_\+initialized}
\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\begin{DoxyVerb}Abstract Generator agent; only meant to be extended.

TorchGeneratorAgent aims to handle much of the bookkeeping and infrastructure work
for any generative models, like seq2seq or transformer. It implements the train_step
and eval_step. The only requirement is that your model *must* implemented the
interface TorchGeneratorModel interface.
\end{DoxyVerb}
 

Definition at line 240 of file torch\+\_\+generator\+\_\+agent.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a60f9613d8d2761569c8862b690b24bce}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a60f9613d8d2761569c8862b690b24bce}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{opt,  }\item[{}]{shared = {\ttfamily None} }\end{DoxyParamCaption})}



Definition at line 342 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
342     \textcolor{keyword}{def }\_\_init\_\_(self, opt, shared=None):
343         init\_model, is\_finetune = self.\_get\_init\_model(opt, shared)
344         super().\_\_init\_\_(opt, shared)
345 
346         self.beam\_size = opt.get(\textcolor{stringliteral}{'beam\_size'}, 1)
347         self.beam\_min\_length = opt.get(\textcolor{stringliteral}{'beam\_min\_length'}, 1)
348         self.beam\_block\_ngram = opt.get(\textcolor{stringliteral}{'beam\_block\_ngram'}, -1)
349 <<<<<<< HEAD
350         self.beam\_context\_block\_ngram = opt.get(\textcolor{stringliteral}{'beam\_context\_block\_ngram'}, -1)
351 =======
352 <<<<<<< HEAD
353 <<<<<<< HEAD
354         self.beam\_context\_block\_ngram = opt.get(\textcolor{stringliteral}{'beam\_context\_block\_ngram'}, -1)
355 =======
356 >>>>>>> 4f6b99642d60aff1a41b9eae8bd2ccd9e40ebba4
357 >>>>>>> origin/master
358 =======
359 >>>>>>> 4f6b99642d60aff1a41b9eae8bd2ccd9e40ebba4
360 >>>>>>> ef574cebef2a8d5aa38b73176b1e71a919d6670f
361         self.output\_token\_losses = opt.get(\textcolor{stringliteral}{'verbose'}, \textcolor{keyword}{False})
362 
363         \textcolor{keywordflow}{if} shared:
364             \textcolor{comment}{# set up shared properties}
365             states = shared.get(\textcolor{stringliteral}{'states'}, \{\})
366         \textcolor{keywordflow}{else}:
367             \textcolor{comment}{# Note: we cannot change the type of metrics ahead of time, so you}
368             \textcolor{comment}{# should correctly initialize to floats or ints here}
369             self.metrics[\textcolor{stringliteral}{'nll\_loss'}] = 0.0
370             self.metrics[\textcolor{stringliteral}{'loss'}] = 0.0
371             self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] = 0
372             self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}] = 0
373 
374             \textcolor{comment}{# this is not a shared instance of this class, so do full init}
375             self.criterion = self.build\_criterion()
376             \textcolor{comment}{# ensure all distributed copies will always be in sync}
377             self.model = self.build\_model()
378 
379             \textcolor{keywordflow}{if} self.model \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{or} self.criterion \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
380                 \textcolor{keywordflow}{raise} AttributeError(
381                     \textcolor{stringliteral}{'build\_model() and build\_criterion() need to return the model or criterion'}
382                 )
383             \textcolor{keywordflow}{if} self.use\_cuda:
384                 self.model.cuda()
385                 self.criterion.cuda()
386 
387             \hyperlink{namespaceparlai_1_1utils_1_1distributed_afc64140f9a6437dc1a2b2bd4294ba8ef}{check\_synced\_parameters}(self.model)
388             print(\textcolor{stringliteral}{"Total parameters: \{\}"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(self.\_total\_parameters()))
389             print(\textcolor{stringliteral}{"Trainable parameters:  \{\}"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(self.\_trainable\_parameters()))
390 
391             \textcolor{keywordflow}{if} self.fp16:
392                 self.model = self.model.half()
393 
394             \textcolor{keywordflow}{if} init\_model \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
395                 \textcolor{comment}{# load model parameters if available}
396                 print(\textcolor{stringliteral}{'[ Loading existing model params from \{\} ]'} \textcolor{stringliteral}{''}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(init\_model))
397                 states = self.load(init\_model)
398             \textcolor{keywordflow}{else}:
399                 states = \{\}
400 
401         \textcolor{keywordflow}{if} (
402             \textcolor{comment}{# only build an optimizer if we're training}
403             \textcolor{stringliteral}{'train'} \textcolor{keywordflow}{in} opt.get(\textcolor{stringliteral}{'datatype'}, \textcolor{stringliteral}{''})
404             \textcolor{comment}{# and this is the main model, or on every fork if doing hogwild}
405             \textcolor{keywordflow}{and} (shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{or} self.opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1)
406         ):
407             \textcolor{comment}{# do this regardless of share state, but don't}
408             self.init\_optim(
409                 [p \textcolor{keywordflow}{for} p \textcolor{keywordflow}{in} self.model.parameters() \textcolor{keywordflow}{if} p.requires\_grad],
410                 optim\_states=states.get(\textcolor{stringliteral}{'optimizer'}),
411                 saved\_optim\_type=states.get(\textcolor{stringliteral}{'optimizer\_type'}),
412             )
413             self.build\_lr\_scheduler(states, hard\_reset=is\_finetune)
414 
415         \textcolor{keywordflow}{if} shared \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{and} \hyperlink{namespaceparlai_1_1utils_1_1distributed_a023acb5e3b66e1f27e21247c35661279}{is\_distributed}():
416             self.model = torch.nn.parallel.DistributedDataParallel(
417                 self.model, device\_ids=[self.opt[\textcolor{stringliteral}{'gpu'}]], broadcast\_buffers=\textcolor{keyword}{False}
418             )
419 
420         self.reset()
421 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad2e2f6361e46785d0b79e4c5031e5710}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad2e2f6361e46785d0b79e4c5031e5710}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}}
\index{add\+\_\+cmdline\+\_\+args@{add\+\_\+cmdline\+\_\+args}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{add\+\_\+cmdline\+\_\+args()}{add\_cmdline\_args()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+add\+\_\+cmdline\+\_\+args (\begin{DoxyParamCaption}\item[{}]{cls,  }\item[{}]{argparser }\end{DoxyParamCaption})}

\begin{DoxyVerb}Add command line arguments.
\end{DoxyVerb}
 

Definition at line 269 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
269     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(cls, argparser):
270         \textcolor{stringliteral}{"""}
271 \textcolor{stringliteral}{        Add command line arguments.}
272 \textcolor{stringliteral}{        """}
273         agent = argparser.add\_argument\_group(\textcolor{stringliteral}{'Torch Generator Agent'})
274         agent.add\_argument(
275             \textcolor{stringliteral}{'--beam-size'},
276             type=int,
277             default=1,
278             help=\textcolor{stringliteral}{'Beam size, if 1 then greedy search'},
279         )
280         agent.add\_argument(
281             \textcolor{stringliteral}{'--beam-min-length'},
282             type=int,
283             default=1,
284             help=\textcolor{stringliteral}{'Minimum length of prediction to be generated by the beam search'},
285         )
286         agent.add\_argument(
287 <<<<<<< HEAD
288 <<<<<<< HEAD
289 =======
290 <<<<<<< HEAD
291 >>>>>>> origin/master
292 =======
293 >>>>>>> ef574cebef2a8d5aa38b73176b1e71a919d6670f
294             \textcolor{stringliteral}{'--beam-context-block-ngram'},
295             type=int,
296             default=-1,
297             help=(
298                 \textcolor{stringliteral}{'Size n-grams to block in beam search from the context. val <= 0 '}
299                 \textcolor{stringliteral}{'implies no blocking'}
300             ),
301         )
302         agent.add\_argument(
303 <<<<<<< HEAD
304 <<<<<<< HEAD
305 =======
306 =======
307 >>>>>>> 4f6b99642d60aff1a41b9eae8bd2ccd9e40ebba4
308 >>>>>>> origin/master
309 =======
310 =======
311 >>>>>>> 4f6b99642d60aff1a41b9eae8bd2ccd9e40ebba4
312 >>>>>>> ef574cebef2a8d5aa38b73176b1e71a919d6670f
313             \textcolor{stringliteral}{'--beam-block-ngram'},
314             type=int,
315             default=-1,
316             help=\textcolor{stringliteral}{'Size n-grams to block in beam search. val <= 0 implies no blocking'},
317         )
318         agent.add\_argument(
319             \textcolor{stringliteral}{'--skip-generation'},
320             type=\textcolor{stringliteral}{'bool'},
321             default=\textcolor{keyword}{False},
322             hidden=\textcolor{keyword}{True},
323             help=\textcolor{stringliteral}{'Skip beam search. Useful for speeding up training, '}
324             \textcolor{stringliteral}{'if perplexity is the validation metric.'},
325         )
326         agent.add\_argument(
327             \textcolor{stringliteral}{'--inference'},
328             choices=\{\textcolor{stringliteral}{'beam'}, \textcolor{stringliteral}{'greedy'}, \textcolor{stringliteral}{'topk'}, \textcolor{stringliteral}{'nucleus'}\},
329             default=\textcolor{stringliteral}{'greedy'},
330             help=\textcolor{stringliteral}{'Generation algorithm'},
331         )
332         agent.add\_argument(
333             \textcolor{stringliteral}{'--topk'}, type=int, default=10, help=\textcolor{stringliteral}{'K used in Top K sampling'}
334         )
335         agent.add\_argument(
336             \textcolor{stringliteral}{'--topp'}, type=float, default=0.9, help=\textcolor{stringliteral}{'p used in nucleus sampling'}
337         )
338 
339         super(TorchGeneratorAgent, cls).\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1config_a62fdd5554f1da6be0cba185271058320}{add\_cmdline\_args}(argparser)
340         \textcolor{keywordflow}{return} agent
341 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8f8437dd8d0dc44f941dbc6182121284}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8f8437dd8d0dc44f941dbc6182121284}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!build\+\_\+criterion@{build\+\_\+criterion}}
\index{build\+\_\+criterion@{build\+\_\+criterion}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{build\+\_\+criterion()}{build\_criterion()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+build\+\_\+criterion (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Construct and return the loss function.

By default torch.nn.CrossEntropyLoss.

If overridden, this model should produce a sum that can be used for a per-token loss.
\end{DoxyVerb}
 

Definition at line 422 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
422     \textcolor{keyword}{def }build\_criterion(self):
423         \textcolor{stringliteral}{"""}
424 \textcolor{stringliteral}{        Construct and return the loss function.}
425 \textcolor{stringliteral}{}
426 \textcolor{stringliteral}{        By default torch.nn.CrossEntropyLoss.}
427 \textcolor{stringliteral}{}
428 \textcolor{stringliteral}{        If overridden, this model should produce a sum that can be used for a per-token loss.}
429 \textcolor{stringliteral}{        """}
430         \textcolor{keywordflow}{return} torch.nn.CrossEntropyLoss(ignore\_index=self.NULL\_IDX, reduction=\textcolor{stringliteral}{'none'})
431 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a94808a13bba0d5283613acd98516bd3c}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a94808a13bba0d5283613acd98516bd3c}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!compute\+\_\+loss@{compute\+\_\+loss}}
\index{compute\+\_\+loss@{compute\+\_\+loss}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{compute\+\_\+loss()}{compute\_loss()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+compute\+\_\+loss (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch,  }\item[{}]{return\+\_\+output = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Compute and return the loss for the given batch.

Easily overridable for customized loss functions.

If return_output is True, the full output from the call to self.model()
is also returned, via a (loss, model_output) pair.
\end{DoxyVerb}
 

Definition at line 562 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
562     \textcolor{keyword}{def }compute\_loss(self, batch, return\_output=False):
563         \textcolor{stringliteral}{"""}
564 \textcolor{stringliteral}{        Compute and return the loss for the given batch.}
565 \textcolor{stringliteral}{}
566 \textcolor{stringliteral}{        Easily overridable for customized loss functions.}
567 \textcolor{stringliteral}{}
568 \textcolor{stringliteral}{        If return\_output is True, the full output from the call to self.model()}
569 \textcolor{stringliteral}{        is also returned, via a (loss, model\_output) pair.}
570 \textcolor{stringliteral}{        """}
571         \textcolor{keywordflow}{if} batch.label\_vec \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
572             \textcolor{keywordflow}{raise} ValueError(\textcolor{stringliteral}{'Cannot compute loss without a label.'})
573         model\_output = self.model(*self.\_model\_input(batch), ys=batch.label\_vec)
574         scores, preds, *\_ = model\_output
575         score\_view = scores.view(-1, scores.size(-1))
576         loss = self.criterion(score\_view, batch.label\_vec.view(-1)).sum()
577         \textcolor{comment}{# save loss to metrics}
578         notnull = batch.label\_vec.ne(self.NULL\_IDX)
579         target\_tokens = notnull.long().sum().item()
580         correct = ((batch.label\_vec == preds) * notnull).sum().item()
581         self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] += correct
582         self.metrics[\textcolor{stringliteral}{'nll\_loss'}] += loss.item()
583         self.metrics[\textcolor{stringliteral}{'num\_tokens'}] += target\_tokens
584         loss /= target\_tokens  \textcolor{comment}{# average loss per token}
585         \textcolor{keywordflow}{if} return\_output:
586             \textcolor{keywordflow}{return} (loss, model\_output)
587         \textcolor{keywordflow}{else}:
588             \textcolor{keywordflow}{return} loss
589 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ac584268dd08c6fcb0045aa968cad8561}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ac584268dd08c6fcb0045aa968cad8561}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!eval\+\_\+step@{eval\+\_\+step}}
\index{eval\+\_\+step@{eval\+\_\+step}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{eval\+\_\+step()}{eval\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+eval\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}Evaluate a single batch of examples.
\end{DoxyVerb}
 

Definition at line 639 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
639     \textcolor{keyword}{def }eval\_step(self, batch):
640         \textcolor{stringliteral}{"""}
641 \textcolor{stringliteral}{        Evaluate a single batch of examples.}
642 \textcolor{stringliteral}{        """}
643         \textcolor{keywordflow}{if} batch.text\_vec \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
644             \textcolor{keywordflow}{return}
645         bsz = batch.text\_vec.size(0)
646         self.model.eval()
647         cand\_scores = \textcolor{keywordtype}{None}
648         token\_losses = \textcolor{keywordtype}{None}
649 
650         \textcolor{keywordflow}{if} batch.label\_vec \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
651             \textcolor{comment}{# calculate loss on targets with teacher forcing}
652             loss, model\_output = self.compute\_loss(batch, return\_output=\textcolor{keyword}{True})
653             self.metrics[\textcolor{stringliteral}{'loss'}] += loss.item()
654             \textcolor{keywordflow}{if} self.output\_token\_losses:
655                 token\_losses = self.\_construct\_token\_losses(
656                     batch.label\_vec, model\_output
657                 )
658 
659         preds = \textcolor{keywordtype}{None}
660         \textcolor{keywordflow}{if} self.skip\_generation:
661             \hyperlink{namespaceparlai_1_1utils_1_1misc_acf146e70ea7f6867969a7c2b545d4b4b}{warn\_once}(
662                 \textcolor{stringliteral}{"--skip-generation does not produce accurate metrics beyond ppl"},
663                 RuntimeWarning,
664             )
665         \textcolor{keywordflow}{else}:
666             maxlen = self.label\_truncate \textcolor{keywordflow}{or} 256
667             beam\_preds\_scores, \_ = self.\_generate(batch, self.beam\_size, maxlen)
668             preds, scores = zip(*beam\_preds\_scores)
669 
670         cand\_choices = \textcolor{keywordtype}{None}
671         \textcolor{comment}{# TODO: abstract out the scoring here}
672         \textcolor{keywordflow}{if} self.rank\_candidates:
673             \textcolor{comment}{# compute roughly ppl to rank candidates}
674             cand\_choices = []
675             encoder\_states = self.model.encoder(*self.\_model\_input(batch))
676             \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(bsz):
677                 num\_cands = len(batch.candidate\_vecs[i])
678                 enc = self.model.reorder\_encoder\_states(encoder\_states, [i] * num\_cands)
679                 cands, \_ = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v1_adb5a414ae439f14c54e8c760b91cc4c8}{padded\_tensor}(
680                     batch.candidate\_vecs[i], self.NULL\_IDX, self.use\_cuda
681                 )
682                 scores, \_ = self.model.decode\_forced(enc, cands)
683                 cand\_losses = F.cross\_entropy(
684                     scores.view(num\_cands * cands.size(1), -1),
685                     cands.view(-1),
686                     reduction=\textcolor{stringliteral}{'none'},
687                 ).view(num\_cands, cands.size(1))
688                 \textcolor{comment}{# now cand\_losses is cands x seqlen size, but we still need to}
689                 \textcolor{comment}{# check padding and such}
690                 mask = (cands != self.NULL\_IDX).\hyperlink{namespaceprojects_1_1controllable__dialogue_1_1make__control__dataset_aa2b7207688c641dbc094ab44eca27113}{float}()
691                 cand\_scores = (cand\_losses * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-9)
692                 \_, ordering = cand\_scores.sort()
693                 cand\_choices.append([batch.candidates[i][o] \textcolor{keywordflow}{for} o \textcolor{keywordflow}{in} ordering])
694 
695         text = [self.\_v2t(p) \textcolor{keywordflow}{for} p \textcolor{keywordflow}{in} preds] \textcolor{keywordflow}{if} preds \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} \textcolor{keywordtype}{None}
696         \textcolor{keywordflow}{return} \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1torch__agent__v1_a2689006ea97d09413fb242f984bd8016}{Output}(text, cand\_choices, token\_losses=token\_losses)
697 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3ed32722f939a8afd258830b7093fc18}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3ed32722f939a8afd258830b7093fc18}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!report@{report}}
\index{report@{report}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{report()}{report()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+report (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Report loss and perplexity from model's perspective.

Note that this includes predicting __END__ and __UNK__ tokens and may differ
from a truly independent measurement.
\end{DoxyVerb}
 

Definition at line 514 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
514     \textcolor{keyword}{def }\hyperlink{namespaceprojects_1_1convai2_1_1eval__f1_a01a47b9c08dad189837a51f085defc45}{report}(self):
515         \textcolor{stringliteral}{"""}
516 \textcolor{stringliteral}{        Report loss and perplexity from model's perspective.}
517 \textcolor{stringliteral}{}
518 \textcolor{stringliteral}{        Note that this includes predicting \_\_END\_\_ and \_\_UNK\_\_ tokens and may differ}
519 \textcolor{stringliteral}{        from a truly independent measurement.}
520 \textcolor{stringliteral}{        """}
521         base = super().\hyperlink{namespaceprojects_1_1convai2_1_1eval__f1_a01a47b9c08dad189837a51f085defc45}{report}()
522         m = \{\}
523         num\_tok = self.metrics[\textcolor{stringliteral}{'num\_tokens'}]
524         \textcolor{keywordflow}{if} num\_tok > 0:
525             m[\textcolor{stringliteral}{'loss'}] = self.metrics[\textcolor{stringliteral}{'loss'}]
526             \textcolor{keywordflow}{if} self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] > 0:
527                 m[\textcolor{stringliteral}{'token\_acc'}] = self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] / num\_tok
528             m[\textcolor{stringliteral}{'nll\_loss'}] = self.metrics[\textcolor{stringliteral}{'nll\_loss'}] / num\_tok
529             \textcolor{keywordflow}{try}:
530                 m[\textcolor{stringliteral}{'ppl'}] = math.exp(m[\textcolor{stringliteral}{'nll\_loss'}])
531             \textcolor{keywordflow}{except} OverflowError:
532                 m[\textcolor{stringliteral}{'ppl'}] = \hyperlink{namespaceprojects_1_1controllable__dialogue_1_1make__control__dataset_aa2b7207688c641dbc094ab44eca27113}{float}(\textcolor{stringliteral}{'inf'})
533         \textcolor{keywordflow}{if} self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}] > 0:
534             m[\textcolor{stringliteral}{'total\_skipped\_batches'}] = self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}]
535         \textcolor{keywordflow}{for} k, v \textcolor{keywordflow}{in} m.items():
536             \textcolor{comment}{# clean up: rounds to sigfigs and converts tensors to floats}
537             base[k] = \hyperlink{namespaceparlai_1_1agents_1_1legacy__agents_1_1seq2seq_1_1utils__v0_af377ec61bfc0423461e7b409ffc883b9}{round\_sigfigs}(v, 4)
538         \textcolor{keywordflow}{return} base
539 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7cac9c087d7357d32a7c3bc8fa74930c}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7cac9c087d7357d32a7c3bc8fa74930c}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!reset\+\_\+metrics@{reset\+\_\+metrics}}
\index{reset\+\_\+metrics@{reset\+\_\+metrics}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{reset\+\_\+metrics()}{reset\_metrics()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+reset\+\_\+metrics (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reset metrics for reporting loss and perplexity.
\end{DoxyVerb}
 

Definition at line 491 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
491     \textcolor{keyword}{def }reset\_metrics(self):
492         \textcolor{stringliteral}{"""}
493 \textcolor{stringliteral}{        Reset metrics for reporting loss and perplexity.}
494 \textcolor{stringliteral}{        """}
495         super().reset\_metrics()
496         \textcolor{comment}{# Note: we cannot change the type of metrics ahead of time, so you}
497         \textcolor{comment}{# should correctly initialize to floats or ints here}
498         self.metrics[\textcolor{stringliteral}{'loss'}] = 0.0
499         self.metrics[\textcolor{stringliteral}{'nll\_loss'}] = 0.0
500         self.metrics[\textcolor{stringliteral}{'num\_tokens'}] = 0
501         self.metrics[\textcolor{stringliteral}{'correct\_tokens'}] = 0
502 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8a3c13d2b8988d2a0cbb71f44ae81f52}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8a3c13d2b8988d2a0cbb71f44ae81f52}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}}
\index{set\+\_\+interactive\+\_\+mode@{set\+\_\+interactive\+\_\+mode}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{set\+\_\+interactive\+\_\+mode()}{set\_interactive\_mode()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+set\+\_\+interactive\+\_\+mode (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{mode,  }\item[{}]{shared = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Turn on interactive mode.
\end{DoxyVerb}
 

Definition at line 446 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
446     \textcolor{keyword}{def }set\_interactive\_mode(self, mode, shared=False):
447         \textcolor{stringliteral}{"""}
448 \textcolor{stringliteral}{        Turn on interactive mode.}
449 \textcolor{stringliteral}{        """}
450         super().set\_interactive\_mode(mode, shared)
451         \textcolor{keywordflow}{if} mode:
452             self.skip\_generation = \textcolor{keyword}{False}
453         \textcolor{keywordflow}{else}:
454             self.skip\_generation = self.opt.get(\textcolor{stringliteral}{'skip\_generation'}, \textcolor{keyword}{False})
455 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad10e64dd33f1add04ba5bcf36b86c2bf}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ad10e64dd33f1add04ba5bcf36b86c2bf}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!share@{share}}
\index{share@{share}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{share()}{share()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+share (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Share internal states between parent and child instances.
\end{DoxyVerb}
 

Definition at line 503 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
503     \textcolor{keyword}{def }share(self):
504         \textcolor{stringliteral}{"""}
505 \textcolor{stringliteral}{        Share internal states between parent and child instances.}
506 \textcolor{stringliteral}{        """}
507         shared = super().share()
508         \textcolor{keywordflow}{if} self.opt.get(\textcolor{stringliteral}{'numthreads'}, 1) > 1:
509             shared[\textcolor{stringliteral}{'states'}] = \{  \textcolor{comment}{# don't share optimizer states}
510                 \textcolor{stringliteral}{'optimizer\_type'}: self.opt[\textcolor{stringliteral}{'optimizer'}]
511             \}
512         \textcolor{keywordflow}{return} shared
513 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_afe2226ddfc838ec27580e3499cc0bae7}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_afe2226ddfc838ec27580e3499cc0bae7}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!train\+\_\+step@{train\+\_\+step}}
\index{train\+\_\+step@{train\+\_\+step}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{train\+\_\+step()}{train\_step()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+train\+\_\+step (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{batch }\end{DoxyParamCaption})}

\begin{DoxyVerb}Train on a single batch of examples.
\end{DoxyVerb}
 

Definition at line 590 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
590     \textcolor{keyword}{def }train\_step(self, batch):
591         \textcolor{stringliteral}{"""}
592 \textcolor{stringliteral}{        Train on a single batch of examples.}
593 \textcolor{stringliteral}{        """}
594         batchsize = batch.text\_vec.size(0)
595         \textcolor{comment}{# helps with memory usage}
596         self.\_init\_cuda\_buffer(batchsize, self.truncate \textcolor{keywordflow}{or} 256)
597         self.model.\hyperlink{namespaceprojects_1_1mastering__the__dungeon_1_1mturk_1_1tasks_1_1MTD_1_1run_a36a5f4f6f9df0611a6818610518d2cf0}{train}()
598         self.zero\_grad()
599 
600         \textcolor{keywordflow}{try}:
601             loss = self.compute\_loss(batch)
602             self.metrics[\textcolor{stringliteral}{'loss'}] += loss.item()
603             self.backward(loss)
604             self.update\_params()
605         \textcolor{keywordflow}{except} RuntimeError \textcolor{keyword}{as} e:
606             \textcolor{comment}{# catch out of memory exceptions during fwd/bck (skip batch)}
607             \textcolor{keywordflow}{if} \textcolor{stringliteral}{'out of memory'} \textcolor{keywordflow}{in} \hyperlink{namespacegenerate__task__READMEs_a5b88452ffb87b78c8c85ececebafc09f}{str}(e):
608                 print(
609                     \textcolor{stringliteral}{'| WARNING: ran out of memory, skipping batch. '}
610                     \textcolor{stringliteral}{'if this happens frequently, decrease batchsize or '}
611                     \textcolor{stringliteral}{'truncate the inputs to the model.'}
612                 )
613                 self.metrics[\textcolor{stringliteral}{'total\_skipped\_batches'}] += 1
614                 \textcolor{comment}{# gradients are synced on backward, now this model is going to be}
615                 \textcolor{comment}{# out of sync! catch up with the other workers}
616                 self.\_init\_cuda\_buffer(8, 8, \textcolor{keyword}{True})
617             \textcolor{keywordflow}{else}:
618                 \textcolor{keywordflow}{raise} e
619 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8bb3183c7de0e8831157536c6ce1751b}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a8bb3183c7de0e8831157536c6ce1751b}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!upgrade\+\_\+opt@{upgrade\+\_\+opt}}
\index{upgrade\+\_\+opt@{upgrade\+\_\+opt}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{upgrade\+\_\+opt()}{upgrade\_opt()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+upgrade\+\_\+opt (\begin{DoxyParamCaption}\item[{}]{cls,  }\item[{}]{opt\+\_\+from\+\_\+disk }\end{DoxyParamCaption})}



Definition at line 251 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
251     \textcolor{keyword}{def }upgrade\_opt(cls, opt\_from\_disk):
252         \textcolor{comment}{# call the parent upgrades}
253         opt\_from\_disk = super(TorchGeneratorAgent, cls).upgrade\_opt(opt\_from\_disk)
254 
255         \textcolor{comment}{# 2019-08-18: Adding support for generation other than beam search}
256         \textcolor{comment}{# Previously, selecting --beam-size > 1 enabled beam search and == 1 was}
257         \textcolor{comment}{# greedy. New behavior is --inference greedy or --inference beam.}
258         \textcolor{keywordflow}{if} \textcolor{stringliteral}{'inference'} \textcolor{keywordflow}{not} \textcolor{keywordflow}{in} opt\_from\_disk:
259             \textcolor{keyword}{assert} \textcolor{stringliteral}{'beam\_size'} \textcolor{keywordflow}{in} opt\_from\_disk
260             \textcolor{keywordflow}{if} opt\_from\_disk[\textcolor{stringliteral}{'beam\_size'}] == 1:
261                 method = \textcolor{stringliteral}{'greedy'}
262             \textcolor{keywordflow}{else}:
263                 method = \textcolor{stringliteral}{'beam'}
264             opt\_from\_disk[\textcolor{stringliteral}{'inference'}] = method
265             \hyperlink{namespaceparlai_1_1utils_1_1misc_acf146e70ea7f6867969a7c2b545d4b4b}{warn\_once}(f\textcolor{stringliteral}{'Old model inference method inferred as \{method\}'})
266         \textcolor{keywordflow}{return} opt\_from\_disk
267 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a66f36d7201bc1b9a019d3525a5934cf7}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a66f36d7201bc1b9a019d3525a5934cf7}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!vectorize@{vectorize}}
\index{vectorize@{vectorize}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{vectorize()}{vectorize()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+vectorize (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{args,  }\item[{}]{kwargs }\end{DoxyParamCaption})}

\begin{DoxyVerb}Override vectorize for generative models.
\end{DoxyVerb}
 

Definition at line 540 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
540     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1utils_a5c76cc39e3014c7bcf9199d566dbdc0f}{vectorize}(self, *args, **kwargs):
541         \textcolor{stringliteral}{"""}
542 \textcolor{stringliteral}{        Override vectorize for generative models.}
543 \textcolor{stringliteral}{        """}
544         kwargs[\textcolor{stringliteral}{'add\_start'}] = \textcolor{keyword}{False}  \textcolor{comment}{# model does this in module code}
545         kwargs[\textcolor{stringliteral}{'add\_end'}] = \textcolor{keyword}{True}  \textcolor{comment}{# we do want this}
546         \textcolor{keywordflow}{return} super().\hyperlink{namespaceparlai_1_1agents_1_1drqa_1_1utils_a5c76cc39e3014c7bcf9199d566dbdc0f}{vectorize}(*args, **kwargs)
547 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a64484ea8971fc2a665e99f99a60f0653}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a64484ea8971fc2a665e99f99a60f0653}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+block\+\_\+ngram@{beam\+\_\+block\+\_\+ngram}}
\index{beam\+\_\+block\+\_\+ngram@{beam\+\_\+block\+\_\+ngram}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+block\+\_\+ngram}{beam\_block\_ngram}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+block\+\_\+ngram}



Definition at line 348 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7991351ff26caf7c59e24fe2e36bf6ea}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a7991351ff26caf7c59e24fe2e36bf6ea}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+context\+\_\+block\+\_\+ngram@{beam\+\_\+context\+\_\+block\+\_\+ngram}}
\index{beam\+\_\+context\+\_\+block\+\_\+ngram@{beam\+\_\+context\+\_\+block\+\_\+ngram}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+context\+\_\+block\+\_\+ngram}{beam\_context\_block\_ngram}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+context\+\_\+block\+\_\+ngram}



Definition at line 350 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a63f7f11d4917e843498e95dc87e30eb1}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a63f7f11d4917e843498e95dc87e30eb1}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+min\+\_\+length@{beam\+\_\+min\+\_\+length}}
\index{beam\+\_\+min\+\_\+length@{beam\+\_\+min\+\_\+length}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+min\+\_\+length}{beam\_min\_length}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+min\+\_\+length}



Definition at line 347 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_acf02a68b75948cf5bafb24be48813127}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_acf02a68b75948cf5bafb24be48813127}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!beam\+\_\+size@{beam\+\_\+size}}
\index{beam\+\_\+size@{beam\+\_\+size}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{beam\+\_\+size}{beam\_size}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+beam\+\_\+size}



Definition at line 346 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a427057bbe1b2182e5bbd476b7739de31}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a427057bbe1b2182e5bbd476b7739de31}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!buffer\+\_\+initialized@{buffer\+\_\+initialized}}
\index{buffer\+\_\+initialized@{buffer\+\_\+initialized}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{buffer\+\_\+initialized}{buffer\_initialized}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+buffer\+\_\+initialized}



Definition at line 479 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_aa6f478c963651331f919fc0ebd44bac3}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_aa6f478c963651331f919fc0ebd44bac3}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!criterion@{criterion}}
\index{criterion@{criterion}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{criterion}{criterion}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+criterion}



Definition at line 375 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3b661c0eb6f3e65f061908142819bdc2}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a3b661c0eb6f3e65f061908142819bdc2}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!model@{model}}
\index{model@{model}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{model}{model}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+model}



Definition at line 377 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ab6ff17d050234854c4ce34fbff73bf79}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_ab6ff17d050234854c4ce34fbff73bf79}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!output\+\_\+token\+\_\+losses@{output\+\_\+token\+\_\+losses}}
\index{output\+\_\+token\+\_\+losses@{output\+\_\+token\+\_\+losses}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{output\+\_\+token\+\_\+losses}{output\_token\_losses}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+output\+\_\+token\+\_\+losses}



Definition at line 361 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a713b4b7ae6d30a664c97c4ea121f8e38}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorAgent_a713b4b7ae6d30a664c97c4ea121f8e38}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}!skip\+\_\+generation@{skip\+\_\+generation}}
\index{skip\+\_\+generation@{skip\+\_\+generation}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Agent}}
\subsubsection{\texorpdfstring{skip\+\_\+generation}{skip\_generation}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Agent.\+skip\+\_\+generation}



Definition at line 452 of file torch\+\_\+generator\+\_\+agent.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/core/\hyperlink{torch__generator__agent_8py}{torch\+\_\+generator\+\_\+agent.\+py}\end{DoxyCompactItemize}
