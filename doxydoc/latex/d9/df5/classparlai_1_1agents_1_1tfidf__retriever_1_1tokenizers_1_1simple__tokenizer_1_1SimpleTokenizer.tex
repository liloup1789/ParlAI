\hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer}{}\section{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer Class Reference}
\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer}\index{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer@{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer}}


Inheritance diagram for parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=231pt]{d2/d45/classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=231pt]{dc/d4d/classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a6a038fd66269e0a8e76e62260b13f4d9}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, kwargs)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a690bc237be6349de5c3f105e0be37ea7}{tokenize} (self, text)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_aa2edbea9c08e8b1fbe5eef7d61e3f432}{annotators}
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_aa6fcedf1435823fe5d79b8c73e769158}{A\+L\+P\+H\+A\+\_\+\+N\+UM}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a1b1a131ce26f695a109c07a04f857ab5}{N\+O\+N\+\_\+\+WS}
\end{DoxyCompactItemize}


\subsection{Detailed Description}


Definition at line 16 of file simple\+\_\+tokenizer.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a6a038fd66269e0a8e76e62260b13f4d9}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a6a038fd66269e0a8e76e62260b13f4d9}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{kwargs }\end{DoxyParamCaption})}

\begin{DoxyVerb}Args:
    annotators: None or empty set (only tokenizes).
\end{DoxyVerb}
 

Definition at line 20 of file simple\+\_\+tokenizer.\+py.


\begin{DoxyCode}
20     \textcolor{keyword}{def }\_\_init\_\_(self, **kwargs):
21         \textcolor{stringliteral}{"""}
22 \textcolor{stringliteral}{        Args:}
23 \textcolor{stringliteral}{            annotators: None or empty set (only tokenizes).}
24 \textcolor{stringliteral}{        """}
25         self.\_regexp = regex.compile(
26             \textcolor{stringliteral}{'(%s)|(%s)'} % (self.ALPHA\_NUM, self.NON\_WS),
27             flags=regex.IGNORECASE + regex.UNICODE + regex.MULTILINE,
28         )
29         \textcolor{keywordflow}{if} len(kwargs.get(\textcolor{stringliteral}{'annotators'}, \{\})) > 0:
30             logger.warning(
31                 \textcolor{stringliteral}{'%s only tokenizes! Skipping annotators: %s'}
32                 % (\hyperlink{namespaceparlai_1_1agents_1_1tfidf__retriever_1_1build__tfidf_ad5dfae268e23f506da084a9efb72f619}{type}(self).\_\_name\_\_, kwargs.get(\textcolor{stringliteral}{'annotators'}))
33             )
34         self.annotators = set()
35 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a690bc237be6349de5c3f105e0be37ea7}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a690bc237be6349de5c3f105e0be37ea7}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}!tokenize@{tokenize}}
\index{tokenize@{tokenize}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}}
\subsubsection{\texorpdfstring{tokenize()}{tokenize()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+tokenize (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}



Definition at line 36 of file simple\+\_\+tokenizer.\+py.


\begin{DoxyCode}
36     \textcolor{keyword}{def }\hyperlink{namespaceparlai_1_1agents_1_1tfidf__retriever_1_1build__tfidf_a1fdb457e98eb4e4c26047e229686a616}{tokenize}(self, text):
37         data = []
38         matches = [m \textcolor{keywordflow}{for} m \textcolor{keywordflow}{in} self.\_regexp.finditer(text)]
39         \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(len(matches)):
40             \textcolor{comment}{# Get text}
41             token = matches[i].group()
42 
43             \textcolor{comment}{# Get whitespace}
44             span = matches[i].span()
45             start\_ws = span[0]
46             \textcolor{keywordflow}{if} i + 1 < len(matches):
47                 end\_ws = matches[i + 1].span()[0]
48             \textcolor{keywordflow}{else}:
49                 end\_ws = span[1]
50 
51             \textcolor{comment}{# Format data}
52             data.append((token, text[start\_ws:end\_ws], span))
53         \textcolor{keywordflow}{return} Tokens(data, self.annotators)
54 \end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_aa6fcedf1435823fe5d79b8c73e769158}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_aa6fcedf1435823fe5d79b8c73e769158}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}!A\+L\+P\+H\+A\+\_\+\+N\+UM@{A\+L\+P\+H\+A\+\_\+\+N\+UM}}
\index{A\+L\+P\+H\+A\+\_\+\+N\+UM@{A\+L\+P\+H\+A\+\_\+\+N\+UM}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}}
\subsubsection{\texorpdfstring{A\+L\+P\+H\+A\+\_\+\+N\+UM}{ALPHA\_NUM}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+A\+L\+P\+H\+A\+\_\+\+N\+UM\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 17 of file simple\+\_\+tokenizer.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_aa2edbea9c08e8b1fbe5eef7d61e3f432}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_aa2edbea9c08e8b1fbe5eef7d61e3f432}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}!annotators@{annotators}}
\index{annotators@{annotators}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}}
\subsubsection{\texorpdfstring{annotators}{annotators}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+annotators}



Definition at line 34 of file simple\+\_\+tokenizer.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a1b1a131ce26f695a109c07a04f857ab5}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1simple__tokenizer_1_1SimpleTokenizer_a1b1a131ce26f695a109c07a04f857ab5}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}!N\+O\+N\+\_\+\+WS@{N\+O\+N\+\_\+\+WS}}
\index{N\+O\+N\+\_\+\+WS@{N\+O\+N\+\_\+\+WS}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::simple\+\_\+tokenizer\+::\+Simple\+Tokenizer}}
\subsubsection{\texorpdfstring{N\+O\+N\+\_\+\+WS}{NON\_WS}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+N\+O\+N\+\_\+\+WS\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 18 of file simple\+\_\+tokenizer.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/agents/tfidf\+\_\+retriever/tokenizers/\hyperlink{simple__tokenizer_8py}{simple\+\_\+tokenizer.\+py}\end{DoxyCompactItemize}
