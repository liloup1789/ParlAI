\hypertarget{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder}{}\section{projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder Class Reference}
\label{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder}\index{projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder@{projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder}}


Inheritance diagram for projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=229pt]{d0/dd1/classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=229pt]{d7/d93/classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_a30bdd85c8d48f70f1c903e0832f618f8}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, \hyperlink{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_aaf8e62c67b68634bd0e3ea1be88b7a6c}{transformer})
\item 
def \hyperlink{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_a482a0f0798408978ba2902159517d84b}{forward} (self, src\+\_\+tokens, know\+\_\+tokens, ck\+\_\+mask, cs\+\_\+ids, use\+\_\+cs\+\_\+ids)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_aa1c8bdeb31ac36e8ce13856fb6c47006}{embeddings}
\item 
\hyperlink{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_af06900dbcf4bcd72ed923dbe8930b0e0}{embed\+\_\+dim}
\item 
\hyperlink{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_aaf8e62c67b68634bd0e3ea1be88b7a6c}{transformer}
\end{DoxyCompactItemize}


\subsection{Detailed Description}


Definition at line 55 of file modules.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_a30bdd85c8d48f70f1c903e0832f618f8}\label{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_a30bdd85c8d48f70f1c903e0832f618f8}} 
\index{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{transformer }\end{DoxyParamCaption})}



Definition at line 56 of file modules.\+py.


\begin{DoxyCode}
56     \textcolor{keyword}{def }\_\_init\_\_(self, transformer):
57         super().\_\_init\_\_()
58         \textcolor{comment}{# The transformer takes care of most of the work, but other modules}
59         \textcolor{comment}{# expect us to have an embeddings available}
60         self.embeddings = transformer.embeddings
61         self.embed\_dim = transformer.embeddings.embedding\_dim
62         self.transformer = transformer
63 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_a482a0f0798408978ba2902159517d84b}\label{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_a482a0f0798408978ba2902159517d84b}} 
\index{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}!forward@{forward}}
\index{forward@{forward}!projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}}
\subsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily def projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder.\+forward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{src\+\_\+tokens,  }\item[{}]{know\+\_\+tokens,  }\item[{}]{ck\+\_\+mask,  }\item[{}]{cs\+\_\+ids,  }\item[{}]{use\+\_\+cs\+\_\+ids }\end{DoxyParamCaption})}



Definition at line 64 of file modules.\+py.


\begin{DoxyCode}
64     \textcolor{keyword}{def }forward(self, src\_tokens, know\_tokens, ck\_mask, cs\_ids, use\_cs\_ids):
65         \textcolor{comment}{# encode the context, pretty basic}
66         context\_encoded, context\_mask = self.transformer(src\_tokens)
67 
68         \textcolor{comment}{# make all the knowledge into a 2D matrix to encode}
69         N, K, Tk = know\_tokens.size()
70         know\_flat = know\_tokens.reshape(-1, Tk)
71         know\_encoded, know\_mask = self.transformer(know\_flat)
72 
73         \textcolor{comment}{# compute our sentence embeddings for context and knowledge}
74         context\_use = \hyperlink{namespaceprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_aa0e28a2592caa75f5c687c6200d2a68d}{universal\_sentence\_embedding}(context\_encoded, 
      context\_mask)
75         know\_use = \hyperlink{namespaceprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_aa0e28a2592caa75f5c687c6200d2a68d}{universal\_sentence\_embedding}(know\_encoded, know\_mask)
76 
77         \textcolor{comment}{# remash it back into the shape we need}
78         know\_use = know\_use.reshape(N, know\_tokens.size(1), self.embed\_dim)
79         context\_use /= np.sqrt(self.embed\_dim)
80         know\_use /= np.sqrt(self.embed\_dim)
81 
82         ck\_attn = th.bmm(know\_use, context\_use.unsqueeze(-1)).squeeze(-1)
83         \textcolor{comment}{# fill with near -inf}
84         ck\_attn.masked\_fill\_(~ck\_mask, \hyperlink{namespaceparlai_1_1utils_1_1misc_a68c44ca571de7149b683539db659c330}{neginf}(context\_encoded.dtype))
85 
86         \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} use\_cs\_ids:
87             \textcolor{comment}{# if we're not given the true chosen\_sentence (test time), pick our}
88             \textcolor{comment}{# best guess}
89             \_, cs\_ids = ck\_attn.max(1)
90 
91         \textcolor{comment}{# pick the true chosen sentence. remember that TransformerEncoder outputs}
92         \textcolor{comment}{#   (batch, time, embed)}
93         \textcolor{comment}{# but because know\_encoded is a flattened, it's really}
94         \textcolor{comment}{#   (N * K, T, D)}
95         \textcolor{comment}{# We need to compute the offsets of the chosen\_sentences}
96         cs\_offsets = th.arange(N, device=cs\_ids.device) * K + cs\_ids
97         cs\_encoded = know\_encoded[cs\_offsets]
98         \textcolor{comment}{# but padding is (N * K, T)}
99         cs\_mask = know\_mask[cs\_offsets]
100 
101         \textcolor{comment}{# finally, concatenate it all}
102         full\_enc = th.cat([cs\_encoded, context\_encoded], dim=1)
103         full\_mask = th.cat([cs\_mask, context\_mask], dim=1)
104 
105         \textcolor{comment}{# also return the knowledge selection mask for the loss}
106         \textcolor{keywordflow}{return} full\_enc, full\_mask, ck\_attn
107 
108 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_af06900dbcf4bcd72ed923dbe8930b0e0}\label{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_af06900dbcf4bcd72ed923dbe8930b0e0}} 
\index{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}!embed\+\_\+dim@{embed\+\_\+dim}}
\index{embed\+\_\+dim@{embed\+\_\+dim}!projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}}
\subsubsection{\texorpdfstring{embed\+\_\+dim}{embed\_dim}}
{\footnotesize\ttfamily projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder.\+embed\+\_\+dim}



Definition at line 61 of file modules.\+py.

\mbox{\Hypertarget{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_aa1c8bdeb31ac36e8ce13856fb6c47006}\label{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_aa1c8bdeb31ac36e8ce13856fb6c47006}} 
\index{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}!embeddings@{embeddings}}
\index{embeddings@{embeddings}!projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}}
\subsubsection{\texorpdfstring{embeddings}{embeddings}}
{\footnotesize\ttfamily projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder.\+embeddings}



Definition at line 60 of file modules.\+py.

\mbox{\Hypertarget{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_aaf8e62c67b68634bd0e3ea1be88b7a6c}\label{classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1ContextKnowledgeEncoder_aaf8e62c67b68634bd0e3ea1be88b7a6c}} 
\index{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}!transformer@{transformer}}
\index{transformer@{transformer}!projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder@{projects\+::wizard\+\_\+of\+\_\+wikipedia\+::generator\+::modules\+::\+Context\+Knowledge\+Encoder}}
\subsubsection{\texorpdfstring{transformer}{transformer}}
{\footnotesize\ttfamily projects.\+wizard\+\_\+of\+\_\+wikipedia.\+generator.\+modules.\+Context\+Knowledge\+Encoder.\+transformer}



Definition at line 62 of file modules.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
projects/wizard\+\_\+of\+\_\+wikipedia/generator/\hyperlink{projects_2wizard__of__wikipedia_2generator_2modules_8py}{modules.\+py}\end{DoxyCompactItemize}
