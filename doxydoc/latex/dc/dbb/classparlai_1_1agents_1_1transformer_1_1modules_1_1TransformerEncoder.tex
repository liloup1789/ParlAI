\hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder}{}\section{parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder Class Reference}
\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder}\index{parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder@{parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder}}


Inheritance diagram for parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=247pt]{da/db7/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=247pt]{dd/ddb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a362f8b951877f3712ca59f0fb6a0ae9c}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab6830a5aa0850e50549c159586c17515}{n\+\_\+heads}, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a1fac9c2d34c4d2268f50fc90b1e74e04}{n\+\_\+layers}, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a57f137ae98789edeae26de90118efdd6}{embedding\+\_\+size}, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_afadc86cb37af464565167dc169447057}{ffn\+\_\+size}, vocabulary\+\_\+size, embedding=None, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_af28dbf5c6c0f70c1a032a3bbb5359661}{dropout}=0.\+0, attention\+\_\+dropout=0.\+0, relu\+\_\+dropout=0.\+0, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a74702a13d7e41afc3e77c94bb60bd119}{padding\+\_\+idx}=0, learn\+\_\+positional\+\_\+embeddings=False, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a80122462ebd32da923d7b4479053ab01}{embeddings\+\_\+scale}=False, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a2703f337fd44344ccd93743e57be554e}{reduction\+\_\+type}=\textquotesingle{}mean\textquotesingle{}, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab885dd6b80284dbd2837ecaf75f96cb0}{n\+\_\+positions}=1024, activation=\textquotesingle{}relu\textquotesingle{}, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a6ea46aeb8ca865c97ec8e99746bedd7b}{variant}=\textquotesingle{}aiayn\textquotesingle{}, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab5ec60adca3ce418f73e409187a82625}{n\+\_\+segments}=0, \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ad904c0d06a4f6851b38fbbc0cab224f9}{output\+\_\+scaling}=1.\+0)
\item 
def \hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a23005871ba6683940f63511ed463266f}{forward} (self, input, positions=None, segments=None)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a57f137ae98789edeae26de90118efdd6}{embedding\+\_\+size}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_afadc86cb37af464565167dc169447057}{ffn\+\_\+size}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a1fac9c2d34c4d2268f50fc90b1e74e04}{n\+\_\+layers}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab6830a5aa0850e50549c159586c17515}{n\+\_\+heads}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab56fa99f887753677dc7f4d435595114}{dim}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a80122462ebd32da923d7b4479053ab01}{embeddings\+\_\+scale}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a2703f337fd44344ccd93743e57be554e}{reduction\+\_\+type}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a74702a13d7e41afc3e77c94bb60bd119}{padding\+\_\+idx}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_af28dbf5c6c0f70c1a032a3bbb5359661}{dropout}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a6ea46aeb8ca865c97ec8e99746bedd7b}{variant}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab5ec60adca3ce418f73e409187a82625}{n\+\_\+segments}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab885dd6b80284dbd2837ecaf75f96cb0}{n\+\_\+positions}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_afd4ec22c3a8b8611a4a1caa85225b426}{out\+\_\+dim}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a179492c3f7ebaf6ba8fb3a7f912e93ce}{embeddings}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ad2dd819e6d66d17f69e8bfa5026d192a}{position\+\_\+embeddings}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ae8676d5d506949c00d35c34ac41b9fff}{norm\+\_\+embeddings}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_acbc50af3764335ae22ef2ba06a65c4a7}{segment\+\_\+embeddings}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_acbeff4ac94daff4e1627b6d93cd37424}{layers}
\item 
\hyperlink{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ad904c0d06a4f6851b38fbbc0cab224f9}{output\+\_\+scaling}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}Transformer encoder module.

:param int n_heads: the number of multihead attention heads.
:param int n_layers: number of transformer layers.
:param int embedding_size: the embedding sizes. Must be a multiple of n_heads.
:param int ffn_size: the size of the hidden layer in the FFN
:param embedding: an embedding matrix for the bottom layer of the transformer.
    If none, one is created for this encoder.
:param float dropout: Dropout used around embeddings and before layer
    layer normalizations. This is used in Vaswani 2017 and works well on
    large datasets.
:param float attention_dropout: Dropout performed after the multhead attention
    softmax. This is not used in Vaswani 2017.
:param float relu_attention: Dropout used after the ReLU in the FFN. Not used
    in Vaswani 2017, but used in Tensor2Tensor.
:param int padding_idx: Reserved padding index in the embeddings matrix.
:param bool learn_positional_embeddings: If off, sinusoidal embeddings are
    used. If on, position embeddings are learned from scratch.
:param bool embeddings_scale: Scale embeddings relative to their dimensionality.
    Found useful in fairseq.
:param bool reduction: If true, returns the mean vector for the entire encoding
    sequence.
:param int n_positions:
    Size of the position embeddings matrix.
:param int n_segments:
    Number of segments/lang/sentence embeddings.
:param activation:
    Type of nonlinear activation. Can be relu or gelu.
:param variant:
    Which transformer architecture to use. Could be AIAYN or XLM.
    Future versions may support things like GPT-2, ...
:param output_scaling:
    Scale the outputs by a given scalar
\end{DoxyVerb}
 

Definition at line 346 of file modules.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a362f8b951877f3712ca59f0fb6a0ae9c}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a362f8b951877f3712ca59f0fb6a0ae9c}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{n\+\_\+heads,  }\item[{}]{n\+\_\+layers,  }\item[{}]{embedding\+\_\+size,  }\item[{}]{ffn\+\_\+size,  }\item[{}]{vocabulary\+\_\+size,  }\item[{}]{embedding = {\ttfamily None},  }\item[{}]{dropout = {\ttfamily 0.0},  }\item[{}]{attention\+\_\+dropout = {\ttfamily 0.0},  }\item[{}]{relu\+\_\+dropout = {\ttfamily 0.0},  }\item[{}]{padding\+\_\+idx = {\ttfamily 0},  }\item[{}]{learn\+\_\+positional\+\_\+embeddings = {\ttfamily False},  }\item[{}]{embeddings\+\_\+scale = {\ttfamily False},  }\item[{}]{reduction\+\_\+type = {\ttfamily \textquotesingle{}mean\textquotesingle{}},  }\item[{}]{n\+\_\+positions = {\ttfamily 1024},  }\item[{}]{activation = {\ttfamily \textquotesingle{}relu\textquotesingle{}},  }\item[{}]{variant = {\ttfamily \textquotesingle{}aiayn\textquotesingle{}},  }\item[{}]{n\+\_\+segments = {\ttfamily 0},  }\item[{}]{output\+\_\+scaling = {\ttfamily 1.0} }\end{DoxyParamCaption})}



Definition at line 403 of file modules.\+py.


\begin{DoxyCode}
403     ):
404         super(TransformerEncoder, self).\_\_init\_\_()
405 
406         self.embedding\_size = embedding\_size
407         self.ffn\_size = ffn\_size
408         self.n\_layers = n\_layers
409         self.n\_heads = n\_heads
410         self.dim = embedding\_size
411         self.embeddings\_scale = embeddings\_scale
412         self.reduction\_type = reduction\_type
413         self.padding\_idx = padding\_idx
414         \textcolor{comment}{# this is --dropout, not --relu-dropout or --attention-dropout}
415         self.dropout = nn.Dropout(p=dropout)
416         self.variant = variant
417         self.n\_segments = n\_segments
418 
419         self.n\_positions = n\_positions
420         self.out\_dim = embedding\_size
421         \textcolor{keyword}{assert} (
422             embedding\_size % n\_heads == 0
423         ), \textcolor{stringliteral}{'Transformer embedding size must be a multiple of n\_heads'}
424 
425         \textcolor{comment}{# check input formats:}
426         \textcolor{keywordflow}{if} embedding \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
427             \textcolor{keyword}{assert} (
428                 embedding\_size \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{or} embedding\_size == embedding.weight.shape[1]
429             ), \textcolor{stringliteral}{"Embedding dim must match the embedding size."}
430 
431         \textcolor{keywordflow}{if} embedding \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}:
432             self.embeddings = embedding
433         \textcolor{keywordflow}{else}:
434             \textcolor{keywordflow}{raise} AssertionError(
435                 \textcolor{stringliteral}{"This code should not execute. Left here in case we want to enable it."}
436             )
437             \textcolor{keyword}{assert} padding\_idx \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}
438             self.embeddings = nn.Embedding(
439                 vocabulary\_size, embedding\_size, padding\_idx=padding\_idx
440             )
441             nn.init.normal\_(self.embeddings.weight, 0, embedding\_size ** -0.5)
442 
443         \textcolor{comment}{# create the positional embeddings}
444         self.position\_embeddings = nn.Embedding(n\_positions, embedding\_size)
445         \textcolor{keywordflow}{if} \textcolor{keywordflow}{not} learn\_positional\_embeddings:
446             \hyperlink{namespaceparlai_1_1agents_1_1transformer_1_1modules_a0b86437e6e9682fa3100e9cadcaae259}{create\_position\_codes}(
447                 n\_positions, embedding\_size, out=self.position\_embeddings.weight
448             )
449         \textcolor{keywordflow}{else}:
450             nn.init.normal\_(self.position\_embeddings.weight, 0, embedding\_size ** -0.5)
451 
452         \textcolor{comment}{# embedding normalization}
453         \textcolor{keywordflow}{if} self.variant == \textcolor{stringliteral}{'xlm'}:
454             self.norm\_embeddings = LayerNorm(self.dim, eps=LAYER\_NORM\_EPS)
455         \textcolor{keywordflow}{elif} self.variant == \textcolor{stringliteral}{'aiayn'}:
456             \textcolor{keywordflow}{pass}
457         \textcolor{keywordflow}{else}:
458             \textcolor{keywordflow}{raise} ValueError(\textcolor{stringliteral}{"Can't handle --variant \{\}"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(self.variant))
459 
460         \textcolor{keywordflow}{if} self.n\_segments >= 1:
461             self.segment\_embeddings = nn.Embedding(self.n\_segments, self.dim)
462 
463         \textcolor{comment}{# build the model}
464         self.layers = nn.ModuleList()
465         \textcolor{keywordflow}{for} \_ \textcolor{keywordflow}{in} range(self.n\_layers):
466             self.layers.append(
467                 TransformerEncoderLayer(
468                     n\_heads,
469                     embedding\_size,
470                     ffn\_size,
471                     attention\_dropout=attention\_dropout,
472                     relu\_dropout=relu\_dropout,
473                     dropout=dropout,
474                     variant=variant,
475                     activation=activation,
476                 )
477             )
478         self.output\_scaling = output\_scaling
479 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a23005871ba6683940f63511ed463266f}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a23005871ba6683940f63511ed463266f}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!forward@{forward}}
\index{forward@{forward}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily def parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+forward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{input,  }\item[{}]{positions = {\ttfamily None},  }\item[{}]{segments = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Forward pass.

:param LongTensor[batch,seqlen] input:
    The input IDs
:param BoolTensor[batch,seqlen] mask:
    The attention mask; 1 means attend, 0 means ignore.
:param LongTensor[batch,seqlen]:
    If provided, additionally adds ``segments`` as extra embedding features.
\end{DoxyVerb}
 

Definition at line 480 of file modules.\+py.


\begin{DoxyCode}
480     \textcolor{keyword}{def }forward(self, input, positions=None, segments=None):
481         \textcolor{stringliteral}{"""}
482 \textcolor{stringliteral}{        Forward pass.}
483 \textcolor{stringliteral}{}
484 \textcolor{stringliteral}{        :param LongTensor[batch,seqlen] input:}
485 \textcolor{stringliteral}{            The input IDs}
486 \textcolor{stringliteral}{        :param BoolTensor[batch,seqlen] mask:}
487 \textcolor{stringliteral}{            The attention mask; 1 means attend, 0 means ignore.}
488 \textcolor{stringliteral}{        :param LongTensor[batch,seqlen]:}
489 \textcolor{stringliteral}{            If provided, additionally adds ``segments`` as extra embedding features.}
490 \textcolor{stringliteral}{        """}
491         mask = input != self.padding\_idx
492         \textcolor{keywordflow}{if} positions \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
493             positions = (mask.cumsum(dim=1, dtype=torch.int64) - 1).clamp\_(min=0)
494         tensor = self.embeddings(input)
495         \textcolor{keywordflow}{if} self.embeddings\_scale:
496             tensor = tensor * np.sqrt(self.dim)
497 
498         \textcolor{keywordflow}{if} positions.max().item() > self.n\_positions:
499             \hyperlink{namespaceparlai_1_1utils_1_1misc_acf146e70ea7f6867969a7c2b545d4b4b}{warn\_once}(
500                 \textcolor{stringliteral}{'You are inputting a sequence of \{x\} length, but only have '}
501                 \textcolor{stringliteral}{'--n-positions \{y\}. Set --truncate or increase --n-positions'}.
      \hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(
502                     x=positions.max().item(), y=self.n\_positions
503                 )
504             )
505         position\_embs = self.position\_embeddings(positions).expand\_as(tensor)
506         tensor = tensor + position\_embs
507 
508         \textcolor{keywordflow}{if} self.n\_segments >= 1:
509             \textcolor{keywordflow}{if} segments \textcolor{keywordflow}{is} \textcolor{keywordtype}{None}:
510                 segments = torch.zeros\_like(input)
511             tensor = tensor + self.segment\_embeddings(segments)
512 
513         \textcolor{keywordflow}{if} self.variant == \textcolor{stringliteral}{'xlm'}:
514             tensor = \_normalize(tensor, self.norm\_embeddings)
515 
516         \textcolor{comment}{# --dropout on the embeddings}
517         tensor = self.dropout(tensor)
518 
519         tensor *= mask.unsqueeze(-1).type\_as(tensor)
520         \textcolor{keywordflow}{for} i \textcolor{keywordflow}{in} range(self.n\_layers):
521             tensor = self.layers[i](tensor, mask)
522 
523         tensor *= self.output\_scaling
524         \textcolor{keywordflow}{if} self.reduction\_type == \textcolor{stringliteral}{'first'}:
525             \textcolor{keywordflow}{return} tensor[:, 0, :]
526         \textcolor{keywordflow}{elif} self.reduction\_type == \textcolor{stringliteral}{'max'}:
527             \textcolor{keywordflow}{return} tensor.max(dim=1)[0]
528         \textcolor{keywordflow}{elif} self.reduction\_type == \textcolor{stringliteral}{'mean'}:
529             divisor = mask.float().sum(dim=1).unsqueeze(-1).clamp(min=1).type\_as(tensor)
530             output = tensor.sum(dim=1) / divisor
531             \textcolor{keywordflow}{return} output
532         \textcolor{keywordflow}{elif} self.reduction\_type \textcolor{keywordflow}{is} \textcolor{keywordtype}{None} \textcolor{keywordflow}{or} \textcolor{stringliteral}{'none'} \textcolor{keywordflow}{in} self.reduction\_type:
533             output = tensor
534             ret = (output, mask)
535             \textcolor{keywordflow}{if} self.reduction\_type == \textcolor{stringliteral}{'none\_with\_pos\_embs'}:
536                 ret = (output, mask, position\_embs)
537             \textcolor{keywordflow}{return} ret
538         \textcolor{keywordflow}{else}:
539             \textcolor{keywordflow}{raise} ValueError(
540                 \textcolor{stringliteral}{"Can't handle --reduction-type \{\}"}.\hyperlink{namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_a32e2e2022b824fbaf80c747160b52a76}{format}(self.reduction\_type)
541             )
542 
543 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab56fa99f887753677dc7f4d435595114}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab56fa99f887753677dc7f4d435595114}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!dim@{dim}}
\index{dim@{dim}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{dim}{dim}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+dim}



Definition at line 410 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_af28dbf5c6c0f70c1a032a3bbb5359661}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_af28dbf5c6c0f70c1a032a3bbb5359661}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!dropout@{dropout}}
\index{dropout@{dropout}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{dropout}{dropout}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+dropout}



Definition at line 415 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a57f137ae98789edeae26de90118efdd6}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a57f137ae98789edeae26de90118efdd6}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!embedding\+\_\+size@{embedding\+\_\+size}}
\index{embedding\+\_\+size@{embedding\+\_\+size}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{embedding\+\_\+size}{embedding\_size}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+embedding\+\_\+size}



Definition at line 406 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a179492c3f7ebaf6ba8fb3a7f912e93ce}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a179492c3f7ebaf6ba8fb3a7f912e93ce}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!embeddings@{embeddings}}
\index{embeddings@{embeddings}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{embeddings}{embeddings}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+embeddings}



Definition at line 432 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a80122462ebd32da923d7b4479053ab01}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a80122462ebd32da923d7b4479053ab01}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!embeddings\+\_\+scale@{embeddings\+\_\+scale}}
\index{embeddings\+\_\+scale@{embeddings\+\_\+scale}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{embeddings\+\_\+scale}{embeddings\_scale}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+embeddings\+\_\+scale}



Definition at line 411 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_afadc86cb37af464565167dc169447057}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_afadc86cb37af464565167dc169447057}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!ffn\+\_\+size@{ffn\+\_\+size}}
\index{ffn\+\_\+size@{ffn\+\_\+size}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{ffn\+\_\+size}{ffn\_size}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+ffn\+\_\+size}



Definition at line 407 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_acbeff4ac94daff4e1627b6d93cd37424}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_acbeff4ac94daff4e1627b6d93cd37424}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!layers@{layers}}
\index{layers@{layers}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{layers}{layers}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+layers}



Definition at line 464 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab6830a5aa0850e50549c159586c17515}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab6830a5aa0850e50549c159586c17515}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!n\+\_\+heads@{n\+\_\+heads}}
\index{n\+\_\+heads@{n\+\_\+heads}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{n\+\_\+heads}{n\_heads}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+n\+\_\+heads}



Definition at line 409 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a1fac9c2d34c4d2268f50fc90b1e74e04}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a1fac9c2d34c4d2268f50fc90b1e74e04}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!n\+\_\+layers@{n\+\_\+layers}}
\index{n\+\_\+layers@{n\+\_\+layers}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{n\+\_\+layers}{n\_layers}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+n\+\_\+layers}



Definition at line 408 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab885dd6b80284dbd2837ecaf75f96cb0}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab885dd6b80284dbd2837ecaf75f96cb0}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!n\+\_\+positions@{n\+\_\+positions}}
\index{n\+\_\+positions@{n\+\_\+positions}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{n\+\_\+positions}{n\_positions}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+n\+\_\+positions}



Definition at line 419 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab5ec60adca3ce418f73e409187a82625}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ab5ec60adca3ce418f73e409187a82625}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!n\+\_\+segments@{n\+\_\+segments}}
\index{n\+\_\+segments@{n\+\_\+segments}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{n\+\_\+segments}{n\_segments}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+n\+\_\+segments}



Definition at line 417 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ae8676d5d506949c00d35c34ac41b9fff}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ae8676d5d506949c00d35c34ac41b9fff}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!norm\+\_\+embeddings@{norm\+\_\+embeddings}}
\index{norm\+\_\+embeddings@{norm\+\_\+embeddings}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{norm\+\_\+embeddings}{norm\_embeddings}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+norm\+\_\+embeddings}



Definition at line 454 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_afd4ec22c3a8b8611a4a1caa85225b426}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_afd4ec22c3a8b8611a4a1caa85225b426}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!out\+\_\+dim@{out\+\_\+dim}}
\index{out\+\_\+dim@{out\+\_\+dim}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{out\+\_\+dim}{out\_dim}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+out\+\_\+dim}



Definition at line 420 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ad904c0d06a4f6851b38fbbc0cab224f9}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ad904c0d06a4f6851b38fbbc0cab224f9}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!output\+\_\+scaling@{output\+\_\+scaling}}
\index{output\+\_\+scaling@{output\+\_\+scaling}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{output\+\_\+scaling}{output\_scaling}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+output\+\_\+scaling}



Definition at line 478 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a74702a13d7e41afc3e77c94bb60bd119}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a74702a13d7e41afc3e77c94bb60bd119}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!padding\+\_\+idx@{padding\+\_\+idx}}
\index{padding\+\_\+idx@{padding\+\_\+idx}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{padding\+\_\+idx}{padding\_idx}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+padding\+\_\+idx}



Definition at line 413 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ad2dd819e6d66d17f69e8bfa5026d192a}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_ad2dd819e6d66d17f69e8bfa5026d192a}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!position\+\_\+embeddings@{position\+\_\+embeddings}}
\index{position\+\_\+embeddings@{position\+\_\+embeddings}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{position\+\_\+embeddings}{position\_embeddings}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+position\+\_\+embeddings}



Definition at line 444 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a2703f337fd44344ccd93743e57be554e}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a2703f337fd44344ccd93743e57be554e}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!reduction\+\_\+type@{reduction\+\_\+type}}
\index{reduction\+\_\+type@{reduction\+\_\+type}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{reduction\+\_\+type}{reduction\_type}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+reduction\+\_\+type}



Definition at line 412 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_acbc50af3764335ae22ef2ba06a65c4a7}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_acbc50af3764335ae22ef2ba06a65c4a7}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!segment\+\_\+embeddings@{segment\+\_\+embeddings}}
\index{segment\+\_\+embeddings@{segment\+\_\+embeddings}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{segment\+\_\+embeddings}{segment\_embeddings}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+segment\+\_\+embeddings}



Definition at line 461 of file modules.\+py.

\mbox{\Hypertarget{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a6ea46aeb8ca865c97ec8e99746bedd7b}\label{classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder_a6ea46aeb8ca865c97ec8e99746bedd7b}} 
\index{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}!variant@{variant}}
\index{variant@{variant}!parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder@{parlai\+::agents\+::transformer\+::modules\+::\+Transformer\+Encoder}}
\subsubsection{\texorpdfstring{variant}{variant}}
{\footnotesize\ttfamily parlai.\+agents.\+transformer.\+modules.\+Transformer\+Encoder.\+variant}



Definition at line 416 of file modules.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/agents/transformer/\hyperlink{parlai_2agents_2transformer_2modules_8py}{modules.\+py}\end{DoxyCompactItemize}
