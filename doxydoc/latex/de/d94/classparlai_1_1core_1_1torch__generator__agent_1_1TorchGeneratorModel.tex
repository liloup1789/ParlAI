\hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel}{}\section{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model Class Reference}
\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel}\index{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model@{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model}}


Inheritance diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d2/de7/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=223pt]{da/d74/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_aaec943d5add4e6d90fdd451f740be6af}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, padding\+\_\+idx=0, start\+\_\+idx=1, end\+\_\+idx=2, unknown\+\_\+idx=3, input\+\_\+dropout=0, \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}{longest\+\_\+label}=1)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_abfc801c11be6fc49dfbc4e70dc6b8ed9}{decode\+\_\+forced} (self, encoder\+\_\+states, ys)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a9ed5aecabe977856b4c385ba74fa6107}{reorder\+\_\+encoder\+\_\+states} (self, encoder\+\_\+states, indices)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a828d2881fb73ead7d27691c73d1f6f36}{reorder\+\_\+decoder\+\_\+incremental\+\_\+state} (self, incremental\+\_\+state, inds)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a5f1915200b6a8c6518fe17889d2b7cdc}{forward} (self, xs, ys=None, prev\+\_\+enc=None, maxlen=None, bsz=None)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a686d4c12ada077cbf2b9c57544cbbe20}{N\+U\+L\+L\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a1d9cfef6046368b5e7b77bc44b13473e}{E\+N\+D\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}{longest\+\_\+label}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}Abstract TorchGeneratorModel.

This interface expects you to implement model with the following reqs:

:attribute model.encoder:
    takes input returns tuple (enc_out, enc_hidden, attn_mask)

:attribute model.decoder:
    takes decoder params and returns decoder outputs after attn

:attribute model.output:
    takes decoder outputs and returns distr over dictionary
\end{DoxyVerb}
 

Definition at line 56 of file torch\+\_\+generator\+\_\+agent.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_aaec943d5add4e6d90fdd451f740be6af}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_aaec943d5add4e6d90fdd451f740be6af}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{padding\+\_\+idx = {\ttfamily 0},  }\item[{}]{start\+\_\+idx = {\ttfamily 1},  }\item[{}]{end\+\_\+idx = {\ttfamily 2},  }\item[{}]{unknown\+\_\+idx = {\ttfamily 3},  }\item[{}]{input\+\_\+dropout = {\ttfamily 0},  }\item[{}]{longest\+\_\+label = {\ttfamily 1} }\end{DoxyParamCaption})}



Definition at line 80 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
80     ):
81         super().\_\_init\_\_()
82         self.NULL\_IDX = padding\_idx
83         self.END\_IDX = end\_idx
84         self.register\_buffer(\textcolor{stringliteral}{'START'}, torch.LongTensor([start\_idx]))
85         self.longest\_label = longest\_label
86 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_abfc801c11be6fc49dfbc4e70dc6b8ed9}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_abfc801c11be6fc49dfbc4e70dc6b8ed9}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!decode\+\_\+forced@{decode\+\_\+forced}}
\index{decode\+\_\+forced@{decode\+\_\+forced}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{decode\+\_\+forced()}{decode\_forced()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+decode\+\_\+forced (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{encoder\+\_\+states,  }\item[{}]{ys }\end{DoxyParamCaption})}

\begin{DoxyVerb}Decode with a fixed, true sequence, computing loss.

Useful for training, or ranking fixed candidates.

:param ys:
    the prediction targets. Contains both the start and end tokens.

:type ys:
    LongTensor[bsz, time]

:param encoder_states:
    Output of the encoder. Model specific types.

:type encoder_states:
    model specific

:return:
    pair (logits, choices) containing the logits and MLE predictions

:rtype:
    (FloatTensor[bsz, ys, vocab], LongTensor[bsz, ys])
\end{DoxyVerb}
 

Definition at line 87 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
87     \textcolor{keyword}{def }decode\_forced(self, encoder\_states, ys):
88         \textcolor{stringliteral}{"""}
89 \textcolor{stringliteral}{        Decode with a fixed, true sequence, computing loss.}
90 \textcolor{stringliteral}{}
91 \textcolor{stringliteral}{        Useful for training, or ranking fixed candidates.}
92 \textcolor{stringliteral}{}
93 \textcolor{stringliteral}{        :param ys:}
94 \textcolor{stringliteral}{            the prediction targets. Contains both the start and end tokens.}
95 \textcolor{stringliteral}{}
96 \textcolor{stringliteral}{        :type ys:}
97 \textcolor{stringliteral}{            LongTensor[bsz, time]}
98 \textcolor{stringliteral}{}
99 \textcolor{stringliteral}{        :param encoder\_states:}
100 \textcolor{stringliteral}{            Output of the encoder. Model specific types.}
101 \textcolor{stringliteral}{}
102 \textcolor{stringliteral}{        :type encoder\_states:}
103 \textcolor{stringliteral}{            model specific}
104 \textcolor{stringliteral}{}
105 \textcolor{stringliteral}{        :return:}
106 \textcolor{stringliteral}{            pair (logits, choices) containing the logits and MLE predictions}
107 \textcolor{stringliteral}{}
108 \textcolor{stringliteral}{        :rtype:}
109 \textcolor{stringliteral}{            (FloatTensor[bsz, ys, vocab], LongTensor[bsz, ys])}
110 \textcolor{stringliteral}{        """}
111         bsz = ys.size(0)
112         seqlen = ys.size(1)
113         inputs = ys.narrow(1, 0, seqlen - 1)
114         inputs = torch.cat([self.START.detach().expand(bsz, 1), inputs], 1)
115         latent, \_ = self.decoder(inputs, encoder\_states)
116         logits = self.output(latent)
117         \_, preds = logits.max(dim=2)
118         \textcolor{keywordflow}{return} logits, preds
119 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a5f1915200b6a8c6518fe17889d2b7cdc}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a5f1915200b6a8c6518fe17889d2b7cdc}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!forward@{forward}}
\index{forward@{forward}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+forward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{xs,  }\item[{}]{ys = {\ttfamily None},  }\item[{}]{prev\+\_\+enc = {\ttfamily None},  }\item[{}]{maxlen = {\ttfamily None},  }\item[{}]{bsz = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Get output predictions from the model.

:param xs:
    input to the encoder
:type xs:
    LongTensor[bsz, seqlen]
:param ys:
    Expected output from the decoder. Used
    for teacher forcing to calculate loss.
:type ys:
    LongTensor[bsz, outlen]
:param prev_enc:
    if you know you'll pass in the same xs multiple times, you can pass
    in the encoder output from the last forward pass to skip
    recalcuating the same encoder output.
:param maxlen:
    max number of tokens to decode. if not set, will use the length of
    the longest label this model has seen. ignored when ys is not None.
:param bsz:
    if ys is not provided, then you must specify the bsz for greedy
    decoding.

:return:
    (scores, candidate_scores, encoder_states) tuple

    - scores contains the model's predicted token scores.
      (FloatTensor[bsz, seqlen, num_features])
    - candidate_scores are the score the model assigned to each candidate.
      (FloatTensor[bsz, num_cands])
    - encoder_states are the output of model.encoder. Model specific types.
      Feed this back in to skip encoding on the next call.
\end{DoxyVerb}
 

Definition at line 202 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
202     \textcolor{keyword}{def }forward(self, *xs, ys=None, prev\_enc=None, maxlen=None, bsz=None):
203         \textcolor{stringliteral}{"""}
204 \textcolor{stringliteral}{        Get output predictions from the model.}
205 \textcolor{stringliteral}{}
206 \textcolor{stringliteral}{        :param xs:}
207 \textcolor{stringliteral}{            input to the encoder}
208 \textcolor{stringliteral}{        :type xs:}
209 \textcolor{stringliteral}{            LongTensor[bsz, seqlen]}
210 \textcolor{stringliteral}{        :param ys:}
211 \textcolor{stringliteral}{            Expected output from the decoder. Used}
212 \textcolor{stringliteral}{            for teacher forcing to calculate loss.}
213 \textcolor{stringliteral}{        :type ys:}
214 \textcolor{stringliteral}{            LongTensor[bsz, outlen]}
215 \textcolor{stringliteral}{        :param prev\_enc:}
216 \textcolor{stringliteral}{            if you know you'll pass in the same xs multiple times, you can pass}
217 \textcolor{stringliteral}{            in the encoder output from the last forward pass to skip}
218 \textcolor{stringliteral}{            recalcuating the same encoder output.}
219 \textcolor{stringliteral}{        :param maxlen:}
220 \textcolor{stringliteral}{            max number of tokens to decode. if not set, will use the length of}
221 \textcolor{stringliteral}{            the longest label this model has seen. ignored when ys is not None.}
222 \textcolor{stringliteral}{        :param bsz:}
223 \textcolor{stringliteral}{            if ys is not provided, then you must specify the bsz for greedy}
224 \textcolor{stringliteral}{            decoding.}
225 \textcolor{stringliteral}{}
226 \textcolor{stringliteral}{        :return:}
227 \textcolor{stringliteral}{            (scores, candidate\_scores, encoder\_states) tuple}
228 \textcolor{stringliteral}{}
229 \textcolor{stringliteral}{            - scores contains the model's predicted token scores.}
230 \textcolor{stringliteral}{              (FloatTensor[bsz, seqlen, num\_features])}
231 \textcolor{stringliteral}{            - candidate\_scores are the score the model assigned to each candidate.}
232 \textcolor{stringliteral}{              (FloatTensor[bsz, num\_cands])}
233 \textcolor{stringliteral}{            - encoder\_states are the output of model.encoder. Model specific types.}
234 \textcolor{stringliteral}{              Feed this back in to skip encoding on the next call.}
235 \textcolor{stringliteral}{        """}
236         \textcolor{keyword}{assert} ys \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}, \textcolor{stringliteral}{"Greedy decoding in TGModel.forward no longer supported."}
237         \textcolor{comment}{# TODO: get rid of longest\_label}
238         \textcolor{comment}{# keep track of longest label we've ever seen}
239         \textcolor{comment}{# we'll never produce longer ones than that during prediction}
240         self.longest\_label = max(self.longest\_label, ys.size(1))
241 
242         \textcolor{comment}{# use cached encoding if available}
243         encoder\_states = prev\_enc \textcolor{keywordflow}{if} prev\_enc \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} self.encoder(*xs)
244 
245         \textcolor{comment}{# use teacher forcing}
246         scores, preds = self.decode\_forced(encoder\_states, ys)
247 
248         \textcolor{keywordflow}{return} scores, preds, encoder\_states
249 
250 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a828d2881fb73ead7d27691c73d1f6f36}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a828d2881fb73ead7d27691c73d1f6f36}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!reorder\+\_\+decoder\+\_\+incremental\+\_\+state@{reorder\+\_\+decoder\+\_\+incremental\+\_\+state}}
\index{reorder\+\_\+decoder\+\_\+incremental\+\_\+state@{reorder\+\_\+decoder\+\_\+incremental\+\_\+state}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{reorder\+\_\+decoder\+\_\+incremental\+\_\+state()}{reorder\_decoder\_incremental\_state()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+reorder\+\_\+decoder\+\_\+incremental\+\_\+state (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{incremental\+\_\+state,  }\item[{}]{inds }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reorder incremental state for the decoder.

Used to expand selected beams in beam search. Unlike reorder_encoder_states,
implementing this method is optional. However, without incremental decoding,
decoding a single beam becomes O(n^2) instead of O(n), which can make
beam search impractically slow.

In order to fall back to non-incremental decoding, just return None from this
method.

:param incremental_state:
    second output of model.decoder
:type incremental_state:
    model specific
:param inds:
    indices to select and reorder over.
:type inds:
    LongTensor[n]

:return:
    The re-ordered decoder incremental states. It should be the same
    type as incremental_state, and usable as an input to the decoder.
    This method should return None if the model does not support
    incremental decoding.

:rtype:
    model specific
\end{DoxyVerb}
 

Definition at line 170 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
170     \textcolor{keyword}{def }reorder\_decoder\_incremental\_state(self, incremental\_state, inds):
171         \textcolor{stringliteral}{"""}
172 \textcolor{stringliteral}{        Reorder incremental state for the decoder.}
173 \textcolor{stringliteral}{}
174 \textcolor{stringliteral}{        Used to expand selected beams in beam search. Unlike reorder\_encoder\_states,}
175 \textcolor{stringliteral}{        implementing this method is optional. However, without incremental decoding,}
176 \textcolor{stringliteral}{        decoding a single beam becomes O(n^2) instead of O(n), which can make}
177 \textcolor{stringliteral}{        beam search impractically slow.}
178 \textcolor{stringliteral}{}
179 \textcolor{stringliteral}{        In order to fall back to non-incremental decoding, just return None from this}
180 \textcolor{stringliteral}{        method.}
181 \textcolor{stringliteral}{}
182 \textcolor{stringliteral}{        :param incremental\_state:}
183 \textcolor{stringliteral}{            second output of model.decoder}
184 \textcolor{stringliteral}{        :type incremental\_state:}
185 \textcolor{stringliteral}{            model specific}
186 \textcolor{stringliteral}{        :param inds:}
187 \textcolor{stringliteral}{            indices to select and reorder over.}
188 \textcolor{stringliteral}{        :type inds:}
189 \textcolor{stringliteral}{            LongTensor[n]}
190 \textcolor{stringliteral}{}
191 \textcolor{stringliteral}{        :return:}
192 \textcolor{stringliteral}{            The re-ordered decoder incremental states. It should be the same}
193 \textcolor{stringliteral}{            type as incremental\_state, and usable as an input to the decoder.}
194 \textcolor{stringliteral}{            This method should return None if the model does not support}
195 \textcolor{stringliteral}{            incremental decoding.}
196 \textcolor{stringliteral}{}
197 \textcolor{stringliteral}{        :rtype:}
198 \textcolor{stringliteral}{            model specific}
199 \textcolor{stringliteral}{        """}
200         \textcolor{keywordflow}{pass}
201 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a9ed5aecabe977856b4c385ba74fa6107}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a9ed5aecabe977856b4c385ba74fa6107}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!reorder\+\_\+encoder\+\_\+states@{reorder\+\_\+encoder\+\_\+states}}
\index{reorder\+\_\+encoder\+\_\+states@{reorder\+\_\+encoder\+\_\+states}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{reorder\+\_\+encoder\+\_\+states()}{reorder\_encoder\_states()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+reorder\+\_\+encoder\+\_\+states (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{encoder\+\_\+states,  }\item[{}]{indices }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reorder encoder states according to a new set of indices.

This is an abstract method, and *must* be implemented by the user.

Its purpose is to provide beam search with a model-agnostic interface for
beam search. For example, this method is used to sort hypotheses,
expand beams, etc.

For example, assume that encoder_states is an bsz x 1 tensor of values

.. code-block:: python

    indices = [0, 2, 2]
    encoder_states = [[0.1]
              [0.2]
              [0.3]]

then the output will be

.. code-block:: python

    output = [[0.1]
      [0.3]
      [0.3]]

:param encoder_states:
    output from encoder. type is model specific.

:type encoder_states:
    model specific

:param indices:
    the indices to select over. The user must support non-tensor
    inputs.

:type indices: list[int]

:return:
    The re-ordered encoder states. It should be of the same type as
    encoder states, and it must be a valid input to the decoder.

:rtype:
    model specific
\end{DoxyVerb}
 

Definition at line 121 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
121     \textcolor{keyword}{def }reorder\_encoder\_states(self, encoder\_states, indices):
122         \textcolor{stringliteral}{"""}
123 \textcolor{stringliteral}{        Reorder encoder states according to a new set of indices.}
124 \textcolor{stringliteral}{}
125 \textcolor{stringliteral}{        This is an abstract method, and *must* be implemented by the user.}
126 \textcolor{stringliteral}{}
127 \textcolor{stringliteral}{        Its purpose is to provide beam search with a model-agnostic interface for}
128 \textcolor{stringliteral}{        beam search. For example, this method is used to sort hypotheses,}
129 \textcolor{stringliteral}{        expand beams, etc.}
130 \textcolor{stringliteral}{}
131 \textcolor{stringliteral}{        For example, assume that encoder\_states is an bsz x 1 tensor of values}
132 \textcolor{stringliteral}{}
133 \textcolor{stringliteral}{        .. code-block:: python}
134 \textcolor{stringliteral}{}
135 \textcolor{stringliteral}{            indices = [0, 2, 2]}
136 \textcolor{stringliteral}{            encoder\_states = [[0.1]}
137 \textcolor{stringliteral}{                              [0.2]}
138 \textcolor{stringliteral}{                              [0.3]]}
139 \textcolor{stringliteral}{}
140 \textcolor{stringliteral}{        then the output will be}
141 \textcolor{stringliteral}{}
142 \textcolor{stringliteral}{        .. code-block:: python}
143 \textcolor{stringliteral}{}
144 \textcolor{stringliteral}{            output = [[0.1]}
145 \textcolor{stringliteral}{                      [0.3]}
146 \textcolor{stringliteral}{                      [0.3]]}
147 \textcolor{stringliteral}{}
148 \textcolor{stringliteral}{        :param encoder\_states:}
149 \textcolor{stringliteral}{            output from encoder. type is model specific.}
150 \textcolor{stringliteral}{}
151 \textcolor{stringliteral}{        :type encoder\_states:}
152 \textcolor{stringliteral}{            model specific}
153 \textcolor{stringliteral}{}
154 \textcolor{stringliteral}{        :param indices:}
155 \textcolor{stringliteral}{            the indices to select over. The user must support non-tensor}
156 \textcolor{stringliteral}{            inputs.}
157 \textcolor{stringliteral}{}
158 \textcolor{stringliteral}{        :type indices: list[int]}
159 \textcolor{stringliteral}{}
160 \textcolor{stringliteral}{        :return:}
161 \textcolor{stringliteral}{            The re-ordered encoder states. It should be of the same type as}
162 \textcolor{stringliteral}{            encoder states, and it must be a valid input to the decoder.}
163 \textcolor{stringliteral}{}
164 \textcolor{stringliteral}{        :rtype:}
165 \textcolor{stringliteral}{            model specific}
166 \textcolor{stringliteral}{        """}
167         \textcolor{keywordflow}{pass}
168 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a1d9cfef6046368b5e7b77bc44b13473e}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a1d9cfef6046368b5e7b77bc44b13473e}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}}
\index{E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{E\+N\+D\+\_\+\+I\+DX}{END\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+E\+N\+D\+\_\+\+I\+DX}



Definition at line 83 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!longest\+\_\+label@{longest\+\_\+label}}
\index{longest\+\_\+label@{longest\+\_\+label}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{longest\+\_\+label}{longest\_label}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+longest\+\_\+label}



Definition at line 85 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a686d4c12ada077cbf2b9c57544cbbe20}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a686d4c12ada077cbf2b9c57544cbbe20}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}}
\index{N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{N\+U\+L\+L\+\_\+\+I\+DX}{NULL\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+N\+U\+L\+L\+\_\+\+I\+DX}



Definition at line 82 of file torch\+\_\+generator\+\_\+agent.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/core/\hyperlink{torch__generator__agent_8py}{torch\+\_\+generator\+\_\+agent.\+py}\end{DoxyCompactItemize}
