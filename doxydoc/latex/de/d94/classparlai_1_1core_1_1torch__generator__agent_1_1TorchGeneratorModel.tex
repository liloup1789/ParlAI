\hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel}{}\section{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model Class Reference}
\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel}\index{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model@{parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model}}


Inheritance diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d2/de7/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=223pt]{da/d74/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_aaec943d5add4e6d90fdd451f740be6af}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, padding\+\_\+idx=0, start\+\_\+idx=1, end\+\_\+idx=2, unknown\+\_\+idx=3, input\+\_\+dropout=0, \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}{longest\+\_\+label}=1)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_abfc801c11be6fc49dfbc4e70dc6b8ed9}{decode\+\_\+forced} (self, encoder\+\_\+states, ys)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a9ed5aecabe977856b4c385ba74fa6107}{reorder\+\_\+encoder\+\_\+states} (self, encoder\+\_\+states, indices)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a828d2881fb73ead7d27691c73d1f6f36}{reorder\+\_\+decoder\+\_\+incremental\+\_\+state} (self, incremental\+\_\+state, inds)
\item 
def \hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a5f1915200b6a8c6518fe17889d2b7cdc}{forward} (self, xs, ys=None, prev\+\_\+enc=None, maxlen=None, bsz=None)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a686d4c12ada077cbf2b9c57544cbbe20}{N\+U\+L\+L\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a1d9cfef6046368b5e7b77bc44b13473e}{E\+N\+D\+\_\+\+I\+DX}
\item 
\hyperlink{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}{longest\+\_\+label}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}Abstract TorchGeneratorModel.

This interface expects you to implement model with the following reqs:

:attribute model.encoder:
    takes input returns tuple (enc_out, enc_hidden, attn_mask)

:attribute model.decoder:
    takes decoder params and returns decoder outputs after attn

:attribute model.output:
    takes decoder outputs and returns distr over dictionary
\end{DoxyVerb}
 

Definition at line 45 of file torch\+\_\+generator\+\_\+agent.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_aaec943d5add4e6d90fdd451f740be6af}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_aaec943d5add4e6d90fdd451f740be6af}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{padding\+\_\+idx = {\ttfamily 0},  }\item[{}]{start\+\_\+idx = {\ttfamily 1},  }\item[{}]{end\+\_\+idx = {\ttfamily 2},  }\item[{}]{unknown\+\_\+idx = {\ttfamily 3},  }\item[{}]{input\+\_\+dropout = {\ttfamily 0},  }\item[{}]{longest\+\_\+label = {\ttfamily 1} }\end{DoxyParamCaption})}



Definition at line 69 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
69     ):
70         super().\_\_init\_\_()
71         self.NULL\_IDX = padding\_idx
72         self.END\_IDX = end\_idx
73         self.register\_buffer(\textcolor{stringliteral}{'START'}, torch.LongTensor([start\_idx]))
74         self.longest\_label = longest\_label
75 
\end{DoxyCode}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_abfc801c11be6fc49dfbc4e70dc6b8ed9}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_abfc801c11be6fc49dfbc4e70dc6b8ed9}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!decode\+\_\+forced@{decode\+\_\+forced}}
\index{decode\+\_\+forced@{decode\+\_\+forced}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{decode\+\_\+forced()}{decode\_forced()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+decode\+\_\+forced (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{encoder\+\_\+states,  }\item[{}]{ys }\end{DoxyParamCaption})}

\begin{DoxyVerb}Decode with a fixed, true sequence, computing loss.

Useful for training, or ranking fixed candidates.

:param ys:
    the prediction targets. Contains both the start and end tokens.

:type ys:
    LongTensor[bsz, time]

:param encoder_states:
    Output of the encoder. Model specific types.

:type encoder_states:
    model specific

:return:
    pair (logits, choices) containing the logits and MLE predictions

:rtype:
    (FloatTensor[bsz, ys, vocab], LongTensor[bsz, ys])
\end{DoxyVerb}
 

Definition at line 76 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
76     \textcolor{keyword}{def }decode\_forced(self, encoder\_states, ys):
77         \textcolor{stringliteral}{"""}
78 \textcolor{stringliteral}{        Decode with a fixed, true sequence, computing loss.}
79 \textcolor{stringliteral}{}
80 \textcolor{stringliteral}{        Useful for training, or ranking fixed candidates.}
81 \textcolor{stringliteral}{}
82 \textcolor{stringliteral}{        :param ys:}
83 \textcolor{stringliteral}{            the prediction targets. Contains both the start and end tokens.}
84 \textcolor{stringliteral}{}
85 \textcolor{stringliteral}{        :type ys:}
86 \textcolor{stringliteral}{            LongTensor[bsz, time]}
87 \textcolor{stringliteral}{}
88 \textcolor{stringliteral}{        :param encoder\_states:}
89 \textcolor{stringliteral}{            Output of the encoder. Model specific types.}
90 \textcolor{stringliteral}{}
91 \textcolor{stringliteral}{        :type encoder\_states:}
92 \textcolor{stringliteral}{            model specific}
93 \textcolor{stringliteral}{}
94 \textcolor{stringliteral}{        :return:}
95 \textcolor{stringliteral}{            pair (logits, choices) containing the logits and MLE predictions}
96 \textcolor{stringliteral}{}
97 \textcolor{stringliteral}{        :rtype:}
98 \textcolor{stringliteral}{            (FloatTensor[bsz, ys, vocab], LongTensor[bsz, ys])}
99 \textcolor{stringliteral}{        """}
100         bsz = ys.size(0)
101         seqlen = ys.size(1)
102         inputs = ys.narrow(1, 0, seqlen - 1)
103         inputs = torch.cat([self.START.detach().expand(bsz, 1), inputs], 1)
104         latent, \_ = self.decoder(inputs, encoder\_states)
105         logits = self.output(latent)
106         \_, preds = logits.max(dim=2)
107         \textcolor{keywordflow}{return} logits, preds
108 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a5f1915200b6a8c6518fe17889d2b7cdc}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a5f1915200b6a8c6518fe17889d2b7cdc}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!forward@{forward}}
\index{forward@{forward}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+forward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{xs,  }\item[{}]{ys = {\ttfamily None},  }\item[{}]{prev\+\_\+enc = {\ttfamily None},  }\item[{}]{maxlen = {\ttfamily None},  }\item[{}]{bsz = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Get output predictions from the model.

:param xs:
    input to the encoder
:type xs:
    LongTensor[bsz, seqlen]
:param ys:
    Expected output from the decoder. Used
    for teacher forcing to calculate loss.
:type ys:
    LongTensor[bsz, outlen]
:param prev_enc:
    if you know you'll pass in the same xs multiple times, you can pass
    in the encoder output from the last forward pass to skip
    recalcuating the same encoder output.
:param maxlen:
    max number of tokens to decode. if not set, will use the length of
    the longest label this model has seen. ignored when ys is not None.
:param bsz:
    if ys is not provided, then you must specify the bsz for greedy
    decoding.

:return:
    (scores, candidate_scores, encoder_states) tuple

    - scores contains the model's predicted token scores.
      (FloatTensor[bsz, seqlen, num_features])
    - candidate_scores are the score the model assigned to each candidate.
      (FloatTensor[bsz, num_cands])
    - encoder_states are the output of model.encoder. Model specific types.
      Feed this back in to skip encoding on the next call.
\end{DoxyVerb}
 

Definition at line 191 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
191     \textcolor{keyword}{def }forward(self, *xs, ys=None, prev\_enc=None, maxlen=None, bsz=None):
192         \textcolor{stringliteral}{"""}
193 \textcolor{stringliteral}{        Get output predictions from the model.}
194 \textcolor{stringliteral}{}
195 \textcolor{stringliteral}{        :param xs:}
196 \textcolor{stringliteral}{            input to the encoder}
197 \textcolor{stringliteral}{        :type xs:}
198 \textcolor{stringliteral}{            LongTensor[bsz, seqlen]}
199 \textcolor{stringliteral}{        :param ys:}
200 \textcolor{stringliteral}{            Expected output from the decoder. Used}
201 \textcolor{stringliteral}{            for teacher forcing to calculate loss.}
202 \textcolor{stringliteral}{        :type ys:}
203 \textcolor{stringliteral}{            LongTensor[bsz, outlen]}
204 \textcolor{stringliteral}{        :param prev\_enc:}
205 \textcolor{stringliteral}{            if you know you'll pass in the same xs multiple times, you can pass}
206 \textcolor{stringliteral}{            in the encoder output from the last forward pass to skip}
207 \textcolor{stringliteral}{            recalcuating the same encoder output.}
208 \textcolor{stringliteral}{        :param maxlen:}
209 \textcolor{stringliteral}{            max number of tokens to decode. if not set, will use the length of}
210 \textcolor{stringliteral}{            the longest label this model has seen. ignored when ys is not None.}
211 \textcolor{stringliteral}{        :param bsz:}
212 \textcolor{stringliteral}{            if ys is not provided, then you must specify the bsz for greedy}
213 \textcolor{stringliteral}{            decoding.}
214 \textcolor{stringliteral}{}
215 \textcolor{stringliteral}{        :return:}
216 \textcolor{stringliteral}{            (scores, candidate\_scores, encoder\_states) tuple}
217 \textcolor{stringliteral}{}
218 \textcolor{stringliteral}{            - scores contains the model's predicted token scores.}
219 \textcolor{stringliteral}{              (FloatTensor[bsz, seqlen, num\_features])}
220 \textcolor{stringliteral}{            - candidate\_scores are the score the model assigned to each candidate.}
221 \textcolor{stringliteral}{              (FloatTensor[bsz, num\_cands])}
222 \textcolor{stringliteral}{            - encoder\_states are the output of model.encoder. Model specific types.}
223 \textcolor{stringliteral}{              Feed this back in to skip encoding on the next call.}
224 \textcolor{stringliteral}{        """}
225         \textcolor{keyword}{assert} ys \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None}, \textcolor{stringliteral}{"Greedy decoding in TGModel.forward no longer supported."}
226         \textcolor{comment}{# TODO: get rid of longest\_label}
227         \textcolor{comment}{# keep track of longest label we've ever seen}
228         \textcolor{comment}{# we'll never produce longer ones than that during prediction}
229         self.longest\_label = max(self.longest\_label, ys.size(1))
230 
231         \textcolor{comment}{# use cached encoding if available}
232         encoder\_states = prev\_enc \textcolor{keywordflow}{if} prev\_enc \textcolor{keywordflow}{is} \textcolor{keywordflow}{not} \textcolor{keywordtype}{None} \textcolor{keywordflow}{else} self.encoder(*xs)
233 
234         \textcolor{comment}{# use teacher forcing}
235         scores, preds = self.decode\_forced(encoder\_states, ys)
236 
237         \textcolor{keywordflow}{return} scores, preds, encoder\_states
238 
239 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a828d2881fb73ead7d27691c73d1f6f36}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a828d2881fb73ead7d27691c73d1f6f36}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!reorder\+\_\+decoder\+\_\+incremental\+\_\+state@{reorder\+\_\+decoder\+\_\+incremental\+\_\+state}}
\index{reorder\+\_\+decoder\+\_\+incremental\+\_\+state@{reorder\+\_\+decoder\+\_\+incremental\+\_\+state}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{reorder\+\_\+decoder\+\_\+incremental\+\_\+state()}{reorder\_decoder\_incremental\_state()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+reorder\+\_\+decoder\+\_\+incremental\+\_\+state (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{incremental\+\_\+state,  }\item[{}]{inds }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reorder incremental state for the decoder.

Used to expand selected beams in beam search. Unlike reorder_encoder_states,
implementing this method is optional. However, without incremental decoding,
decoding a single beam becomes O(n^2) instead of O(n), which can make
beam search impractically slow.

In order to fall back to non-incremental decoding, just return None from this
method.

:param incremental_state:
    second output of model.decoder
:type incremental_state:
    model specific
:param inds:
    indices to select and reorder over.
:type inds:
    LongTensor[n]

:return:
    The re-ordered decoder incremental states. It should be the same
    type as incremental_state, and usable as an input to the decoder.
    This method should return None if the model does not support
    incremental decoding.

:rtype:
    model specific
\end{DoxyVerb}
 

Definition at line 159 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
159     \textcolor{keyword}{def }reorder\_decoder\_incremental\_state(self, incremental\_state, inds):
160         \textcolor{stringliteral}{"""}
161 \textcolor{stringliteral}{        Reorder incremental state for the decoder.}
162 \textcolor{stringliteral}{}
163 \textcolor{stringliteral}{        Used to expand selected beams in beam search. Unlike reorder\_encoder\_states,}
164 \textcolor{stringliteral}{        implementing this method is optional. However, without incremental decoding,}
165 \textcolor{stringliteral}{        decoding a single beam becomes O(n^2) instead of O(n), which can make}
166 \textcolor{stringliteral}{        beam search impractically slow.}
167 \textcolor{stringliteral}{}
168 \textcolor{stringliteral}{        In order to fall back to non-incremental decoding, just return None from this}
169 \textcolor{stringliteral}{        method.}
170 \textcolor{stringliteral}{}
171 \textcolor{stringliteral}{        :param incremental\_state:}
172 \textcolor{stringliteral}{            second output of model.decoder}
173 \textcolor{stringliteral}{        :type incremental\_state:}
174 \textcolor{stringliteral}{            model specific}
175 \textcolor{stringliteral}{        :param inds:}
176 \textcolor{stringliteral}{            indices to select and reorder over.}
177 \textcolor{stringliteral}{        :type inds:}
178 \textcolor{stringliteral}{            LongTensor[n]}
179 \textcolor{stringliteral}{}
180 \textcolor{stringliteral}{        :return:}
181 \textcolor{stringliteral}{            The re-ordered decoder incremental states. It should be the same}
182 \textcolor{stringliteral}{            type as incremental\_state, and usable as an input to the decoder.}
183 \textcolor{stringliteral}{            This method should return None if the model does not support}
184 \textcolor{stringliteral}{            incremental decoding.}
185 \textcolor{stringliteral}{}
186 \textcolor{stringliteral}{        :rtype:}
187 \textcolor{stringliteral}{            model specific}
188 \textcolor{stringliteral}{        """}
189         \textcolor{keywordflow}{pass}
190 
\end{DoxyCode}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a9ed5aecabe977856b4c385ba74fa6107}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a9ed5aecabe977856b4c385ba74fa6107}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!reorder\+\_\+encoder\+\_\+states@{reorder\+\_\+encoder\+\_\+states}}
\index{reorder\+\_\+encoder\+\_\+states@{reorder\+\_\+encoder\+\_\+states}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{reorder\+\_\+encoder\+\_\+states()}{reorder\_encoder\_states()}}
{\footnotesize\ttfamily def parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+reorder\+\_\+encoder\+\_\+states (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{encoder\+\_\+states,  }\item[{}]{indices }\end{DoxyParamCaption})}

\begin{DoxyVerb}Reorder encoder states according to a new set of indices.

This is an abstract method, and *must* be implemented by the user.

Its purpose is to provide beam search with a model-agnostic interface for
beam search. For example, this method is used to sort hypotheses,
expand beams, etc.

For example, assume that encoder_states is an bsz x 1 tensor of values

.. code-block:: python

    indices = [0, 2, 2]
    encoder_states = [[0.1]
              [0.2]
              [0.3]]

then the output will be

.. code-block:: python

    output = [[0.1]
      [0.3]
      [0.3]]

:param encoder_states:
    output from encoder. type is model specific.

:type encoder_states:
    model specific

:param indices:
    the indices to select over. The user must support non-tensor
    inputs.

:type indices: list[int]

:return:
    The re-ordered encoder states. It should be of the same type as
    encoder states, and it must be a valid input to the decoder.

:rtype:
    model specific
\end{DoxyVerb}
 

Definition at line 110 of file torch\+\_\+generator\+\_\+agent.\+py.


\begin{DoxyCode}
110     \textcolor{keyword}{def }reorder\_encoder\_states(self, encoder\_states, indices):
111         \textcolor{stringliteral}{"""}
112 \textcolor{stringliteral}{        Reorder encoder states according to a new set of indices.}
113 \textcolor{stringliteral}{}
114 \textcolor{stringliteral}{        This is an abstract method, and *must* be implemented by the user.}
115 \textcolor{stringliteral}{}
116 \textcolor{stringliteral}{        Its purpose is to provide beam search with a model-agnostic interface for}
117 \textcolor{stringliteral}{        beam search. For example, this method is used to sort hypotheses,}
118 \textcolor{stringliteral}{        expand beams, etc.}
119 \textcolor{stringliteral}{}
120 \textcolor{stringliteral}{        For example, assume that encoder\_states is an bsz x 1 tensor of values}
121 \textcolor{stringliteral}{}
122 \textcolor{stringliteral}{        .. code-block:: python}
123 \textcolor{stringliteral}{}
124 \textcolor{stringliteral}{            indices = [0, 2, 2]}
125 \textcolor{stringliteral}{            encoder\_states = [[0.1]}
126 \textcolor{stringliteral}{                              [0.2]}
127 \textcolor{stringliteral}{                              [0.3]]}
128 \textcolor{stringliteral}{}
129 \textcolor{stringliteral}{        then the output will be}
130 \textcolor{stringliteral}{}
131 \textcolor{stringliteral}{        .. code-block:: python}
132 \textcolor{stringliteral}{}
133 \textcolor{stringliteral}{            output = [[0.1]}
134 \textcolor{stringliteral}{                      [0.3]}
135 \textcolor{stringliteral}{                      [0.3]]}
136 \textcolor{stringliteral}{}
137 \textcolor{stringliteral}{        :param encoder\_states:}
138 \textcolor{stringliteral}{            output from encoder. type is model specific.}
139 \textcolor{stringliteral}{}
140 \textcolor{stringliteral}{        :type encoder\_states:}
141 \textcolor{stringliteral}{            model specific}
142 \textcolor{stringliteral}{}
143 \textcolor{stringliteral}{        :param indices:}
144 \textcolor{stringliteral}{            the indices to select over. The user must support non-tensor}
145 \textcolor{stringliteral}{            inputs.}
146 \textcolor{stringliteral}{}
147 \textcolor{stringliteral}{        :type indices: list[int]}
148 \textcolor{stringliteral}{}
149 \textcolor{stringliteral}{        :return:}
150 \textcolor{stringliteral}{            The re-ordered encoder states. It should be of the same type as}
151 \textcolor{stringliteral}{            encoder states, and it must be a valid input to the decoder.}
152 \textcolor{stringliteral}{}
153 \textcolor{stringliteral}{        :rtype:}
154 \textcolor{stringliteral}{            model specific}
155 \textcolor{stringliteral}{        """}
156         \textcolor{keywordflow}{pass}
157 
\end{DoxyCode}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a1d9cfef6046368b5e7b77bc44b13473e}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a1d9cfef6046368b5e7b77bc44b13473e}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}}
\index{E\+N\+D\+\_\+\+I\+DX@{E\+N\+D\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{E\+N\+D\+\_\+\+I\+DX}{END\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+E\+N\+D\+\_\+\+I\+DX}



Definition at line 72 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a14dcf5ba14c4438bb4919565ebd30fa8}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!longest\+\_\+label@{longest\+\_\+label}}
\index{longest\+\_\+label@{longest\+\_\+label}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{longest\+\_\+label}{longest\_label}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+longest\+\_\+label}



Definition at line 74 of file torch\+\_\+generator\+\_\+agent.\+py.

\mbox{\Hypertarget{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a686d4c12ada077cbf2b9c57544cbbe20}\label{classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel_a686d4c12ada077cbf2b9c57544cbbe20}} 
\index{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}!N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}}
\index{N\+U\+L\+L\+\_\+\+I\+DX@{N\+U\+L\+L\+\_\+\+I\+DX}!parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model@{parlai\+::core\+::torch\+\_\+generator\+\_\+agent\+::\+Torch\+Generator\+Model}}
\subsubsection{\texorpdfstring{N\+U\+L\+L\+\_\+\+I\+DX}{NULL\_IDX}}
{\footnotesize\ttfamily parlai.\+core.\+torch\+\_\+generator\+\_\+agent.\+Torch\+Generator\+Model.\+N\+U\+L\+L\+\_\+\+I\+DX}



Definition at line 71 of file torch\+\_\+generator\+\_\+agent.\+py.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/core/\hyperlink{torch__generator__agent_8py}{torch\+\_\+generator\+\_\+agent.\+py}\end{DoxyCompactItemize}
