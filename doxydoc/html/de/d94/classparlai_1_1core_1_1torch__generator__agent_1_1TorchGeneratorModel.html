<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: parlai.core.torch_generator_agent.TorchGeneratorModel Class Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d5/d22/namespaceparlai.html">parlai</a></li><li class="navelem"><a class="el" href="../../d1/d43/namespaceparlai_1_1core.html">core</a></li><li class="navelem"><a class="el" href="../../de/d94/namespaceparlai_1_1core_1_1torch__generator__agent.html">torch_generator_agent</a></li><li class="navelem"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html">TorchGeneratorModel</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="../../da/d43/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">parlai.core.torch_generator_agent.TorchGeneratorModel Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for parlai.core.torch_generator_agent.TorchGeneratorModel:</div>
<div class="dyncontent">
<div class="center"><img src="../../d2/de7/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel__inherit__graph.png" border="0" usemap="#parlai_8core_8torch__generator__agent_8TorchGeneratorModel_inherit__map" alt="Inheritance graph"/></div>
<map name="parlai_8core_8torch__generator__agent_8TorchGeneratorModel_inherit__map" id="parlai_8core_8torch__generator__agent_8TorchGeneratorModel_inherit__map">
<area shape="rect" id="node4" href="../../d7/daa/classparlai_1_1agents_1_1seq2seq_1_1modules_1_1Seq2seq.html" title="parlai.agents.seq2seq.modules.\lSeq2seq" alt="" coords="364,5,571,47"/>
<area shape="rect" id="node5" href="../../d6/d14/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerGeneratorModel.html" title="parlai.agents.transformer.modules.\lTransformerGeneratorModel" alt="" coords="356,71,579,112"/>
<area shape="rect" id="node6" href="../../dd/d15/classprojects_1_1wizard__of__wikipedia_1_1generator_1_1modules_1_1EndToEndModel.html" title="projects.wizard_of\l_wikipedia.generator.modules.\lEndToEndModel" alt="" coords="627,63,825,119"/>
</map>
<center><span class="legend">[<a href="../../graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for parlai.core.torch_generator_agent.TorchGeneratorModel:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/d74/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel__coll__graph.png" border="0" usemap="#parlai_8core_8torch__generator__agent_8TorchGeneratorModel_coll__map" alt="Collaboration graph"/></div>
<map name="parlai_8core_8torch__generator__agent_8TorchGeneratorModel_coll__map" id="parlai_8core_8torch__generator__agent_8TorchGeneratorModel_coll__map">
</map>
<center><span class="legend">[<a href="../../graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aaec943d5add4e6d90fdd451f740be6af"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#aaec943d5add4e6d90fdd451f740be6af">__init__</a> (self, padding_idx=0, start_idx=1, end_idx=2, unknown_idx=3, input_dropout=0, <a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#a14dcf5ba14c4438bb4919565ebd30fa8">longest_label</a>=1)</td></tr>
<tr class="separator:aaec943d5add4e6d90fdd451f740be6af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfc801c11be6fc49dfbc4e70dc6b8ed9"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#abfc801c11be6fc49dfbc4e70dc6b8ed9">decode_forced</a> (self, encoder_states, ys)</td></tr>
<tr class="separator:abfc801c11be6fc49dfbc4e70dc6b8ed9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ed5aecabe977856b4c385ba74fa6107"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#a9ed5aecabe977856b4c385ba74fa6107">reorder_encoder_states</a> (self, encoder_states, indices)</td></tr>
<tr class="separator:a9ed5aecabe977856b4c385ba74fa6107"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a828d2881fb73ead7d27691c73d1f6f36"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#a828d2881fb73ead7d27691c73d1f6f36">reorder_decoder_incremental_state</a> (self, incremental_state, inds)</td></tr>
<tr class="separator:a828d2881fb73ead7d27691c73d1f6f36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f1915200b6a8c6518fe17889d2b7cdc"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#a5f1915200b6a8c6518fe17889d2b7cdc">forward</a> (self, xs, ys=None, prev_enc=None, maxlen=None, bsz=None)</td></tr>
<tr class="separator:a5f1915200b6a8c6518fe17889d2b7cdc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a686d4c12ada077cbf2b9c57544cbbe20"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#a686d4c12ada077cbf2b9c57544cbbe20">NULL_IDX</a></td></tr>
<tr class="separator:a686d4c12ada077cbf2b9c57544cbbe20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d9cfef6046368b5e7b77bc44b13473e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#a1d9cfef6046368b5e7b77bc44b13473e">END_IDX</a></td></tr>
<tr class="separator:a1d9cfef6046368b5e7b77bc44b13473e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14dcf5ba14c4438bb4919565ebd30fa8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../de/d94/classparlai_1_1core_1_1torch__generator__agent_1_1TorchGeneratorModel.html#a14dcf5ba14c4438bb4919565ebd30fa8">longest_label</a></td></tr>
<tr class="separator:a14dcf5ba14c4438bb4919565ebd30fa8"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Abstract TorchGeneratorModel.

This interface expects you to implement model with the following reqs:

:attribute model.encoder:
    takes input returns tuple (enc_out, enc_hidden, attn_mask)

:attribute model.decoder:
    takes decoder params and returns decoder outputs after attn

:attribute model.output:
    takes decoder outputs and returns distr over dictionary
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00045">45</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="aaec943d5add4e6d90fdd451f740be6af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaec943d5add4e6d90fdd451f740be6af">&#9670;&nbsp;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.core.torch_generator_agent.TorchGeneratorModel.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>padding_idx</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>start_idx</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>end_idx</em> = <code>2</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>unknown_idx</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_dropout</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>longest_label</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00069">69</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    ):</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        super().__init__()</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;        self.NULL_IDX = padding_idx</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;        self.END_IDX = end_idx</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;        self.register_buffer(<span class="stringliteral">&#39;START&#39;</span>, torch.LongTensor([start_idx]))</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;        self.longest_label = longest_label</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;</div></div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="abfc801c11be6fc49dfbc4e70dc6b8ed9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfc801c11be6fc49dfbc4e70dc6b8ed9">&#9670;&nbsp;</a></span>decode_forced()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.core.torch_generator_agent.TorchGeneratorModel.decode_forced </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encoder_states</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ys</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Decode with a fixed, true sequence, computing loss.

Useful for training, or ranking fixed candidates.

:param ys:
    the prediction targets. Contains both the start and end tokens.

:type ys:
    LongTensor[bsz, time]

:param encoder_states:
    Output of the encoder. Model specific types.

:type encoder_states:
    model specific

:return:
    pair (logits, choices) containing the logits and MLE predictions

:rtype:
    (FloatTensor[bsz, ys, vocab], LongTensor[bsz, ys])
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00076">76</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;    <span class="keyword">def </span>decode_forced(self, encoder_states, ys):</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="stringliteral">        Decode with a fixed, true sequence, computing loss.</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="stringliteral">        Useful for training, or ranking fixed candidates.</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="stringliteral">        :param ys:</span></div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="stringliteral">            the prediction targets. Contains both the start and end tokens.</span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="stringliteral">        :type ys:</span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="stringliteral">            LongTensor[bsz, time]</span></div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="stringliteral">        :param encoder_states:</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="stringliteral">            Output of the encoder. Model specific types.</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="stringliteral">        :type encoder_states:</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="stringliteral">            model specific</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="stringliteral">        :return:</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="stringliteral">            pair (logits, choices) containing the logits and MLE predictions</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="stringliteral">        :rtype:</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="stringliteral">            (FloatTensor[bsz, ys, vocab], LongTensor[bsz, ys])</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;<span class="stringliteral">        &quot;&quot;&quot;</span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        bsz = ys.size(0)</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        seqlen = ys.size(1)</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        inputs = ys.narrow(1, 0, seqlen - 1)</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        inputs = torch.cat([self.START.detach().expand(bsz, 1), inputs], 1)</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        latent, _ = self.decoder(inputs, encoder_states)</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        logits = self.output(latent)</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;        _, preds = logits.max(dim=2)</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        <span class="keywordflow">return</span> logits, preds</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;</div></div><!-- fragment -->
</div>
</div>
<a id="a5f1915200b6a8c6518fe17889d2b7cdc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f1915200b6a8c6518fe17889d2b7cdc">&#9670;&nbsp;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.core.torch_generator_agent.TorchGeneratorModel.forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>xs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ys</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>prev_enc</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>maxlen</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>bsz</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get output predictions from the model.

:param xs:
    input to the encoder
:type xs:
    LongTensor[bsz, seqlen]
:param ys:
    Expected output from the decoder. Used
    for teacher forcing to calculate loss.
:type ys:
    LongTensor[bsz, outlen]
:param prev_enc:
    if you know you'll pass in the same xs multiple times, you can pass
    in the encoder output from the last forward pass to skip
    recalcuating the same encoder output.
:param maxlen:
    max number of tokens to decode. if not set, will use the length of
    the longest label this model has seen. ignored when ys is not None.
:param bsz:
    if ys is not provided, then you must specify the bsz for greedy
    decoding.

:return:
    (scores, candidate_scores, encoder_states) tuple

    - scores contains the model's predicted token scores.
      (FloatTensor[bsz, seqlen, num_features])
    - candidate_scores are the score the model assigned to each candidate.
      (FloatTensor[bsz, num_cands])
    - encoder_states are the output of model.encoder. Model specific types.
      Feed this back in to skip encoding on the next call.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00191">191</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    <span class="keyword">def </span>forward(self, *xs, ys=None, prev_enc=None, maxlen=None, bsz=None):</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;        <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="stringliteral">        Get output predictions from the model.</span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;<span class="stringliteral">        :param xs:</span></div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;<span class="stringliteral">            input to the encoder</span></div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;<span class="stringliteral">        :type xs:</span></div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;<span class="stringliteral">            LongTensor[bsz, seqlen]</span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;<span class="stringliteral">        :param ys:</span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="stringliteral">            Expected output from the decoder. Used</span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;<span class="stringliteral">            for teacher forcing to calculate loss.</span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="stringliteral">        :type ys:</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="stringliteral">            LongTensor[bsz, outlen]</span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="stringliteral">        :param prev_enc:</span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="stringliteral">            if you know you&#39;ll pass in the same xs multiple times, you can pass</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="stringliteral">            in the encoder output from the last forward pass to skip</span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;<span class="stringliteral">            recalcuating the same encoder output.</span></div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;<span class="stringliteral">        :param maxlen:</span></div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;<span class="stringliteral">            max number of tokens to decode. if not set, will use the length of</span></div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;<span class="stringliteral">            the longest label this model has seen. ignored when ys is not None.</span></div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;<span class="stringliteral">        :param bsz:</span></div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;<span class="stringliteral">            if ys is not provided, then you must specify the bsz for greedy</span></div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;<span class="stringliteral">            decoding.</span></div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="stringliteral">        :return:</span></div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;<span class="stringliteral">            (scores, candidate_scores, encoder_states) tuple</span></div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;<span class="stringliteral">            - scores contains the model&#39;s predicted token scores.</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="stringliteral">              (FloatTensor[bsz, seqlen, num_features])</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="stringliteral">            - candidate_scores are the score the model assigned to each candidate.</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="stringliteral">              (FloatTensor[bsz, num_cands])</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="stringliteral">            - encoder_states are the output of model.encoder. Model specific types.</span></div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;<span class="stringliteral">              Feed this back in to skip encoding on the next call.</span></div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;<span class="stringliteral">        &quot;&quot;&quot;</span></div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;        <span class="keyword">assert</span> ys <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>, <span class="stringliteral">&quot;Greedy decoding in TGModel.forward no longer supported.&quot;</span></div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;        <span class="comment"># TODO: get rid of longest_label</span></div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;        <span class="comment"># keep track of longest label we&#39;ve ever seen</span></div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;        <span class="comment"># we&#39;ll never produce longer ones than that during prediction</span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;        self.longest_label = max(self.longest_label, ys.size(1))</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;        <span class="comment"># use cached encoding if available</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;        encoder_states = prev_enc <span class="keywordflow">if</span> prev_enc <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> self.encoder(*xs)</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;        <span class="comment"># use teacher forcing</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;        scores, preds = self.decode_forced(encoder_states, ys)</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;        <span class="keywordflow">return</span> scores, preds, encoder_states</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;</div></div><!-- fragment -->
</div>
</div>
<a id="a828d2881fb73ead7d27691c73d1f6f36"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a828d2881fb73ead7d27691c73d1f6f36">&#9670;&nbsp;</a></span>reorder_decoder_incremental_state()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.core.torch_generator_agent.TorchGeneratorModel.reorder_decoder_incremental_state </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>incremental_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inds</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Reorder incremental state for the decoder.

Used to expand selected beams in beam search. Unlike reorder_encoder_states,
implementing this method is optional. However, without incremental decoding,
decoding a single beam becomes O(n^2) instead of O(n), which can make
beam search impractically slow.

In order to fall back to non-incremental decoding, just return None from this
method.

:param incremental_state:
    second output of model.decoder
:type incremental_state:
    model specific
:param inds:
    indices to select and reorder over.
:type inds:
    LongTensor[n]

:return:
    The re-ordered decoder incremental states. It should be the same
    type as incremental_state, and usable as an input to the decoder.
    This method should return None if the model does not support
    incremental decoding.

:rtype:
    model specific
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00159">159</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    <span class="keyword">def </span>reorder_decoder_incremental_state(self, incremental_state, inds):</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;        <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="stringliteral">        Reorder incremental state for the decoder.</span></div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="stringliteral">        Used to expand selected beams in beam search. Unlike reorder_encoder_states,</span></div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="stringliteral">        implementing this method is optional. However, without incremental decoding,</span></div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="stringliteral">        decoding a single beam becomes O(n^2) instead of O(n), which can make</span></div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="stringliteral">        beam search impractically slow.</span></div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="stringliteral">        In order to fall back to non-incremental decoding, just return None from this</span></div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="stringliteral">        method.</span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="stringliteral">        :param incremental_state:</span></div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="stringliteral">            second output of model.decoder</span></div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="stringliteral">        :type incremental_state:</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="stringliteral">            model specific</span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="stringliteral">        :param inds:</span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="stringliteral">            indices to select and reorder over.</span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="stringliteral">        :type inds:</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="stringliteral">            LongTensor[n]</span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="stringliteral">        :return:</span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="stringliteral">            The re-ordered decoder incremental states. It should be the same</span></div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="stringliteral">            type as incremental_state, and usable as an input to the decoder.</span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="stringliteral">            This method should return None if the model does not support</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="stringliteral">            incremental decoding.</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="stringliteral">        :rtype:</span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="stringliteral">            model specific</span></div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="stringliteral">        &quot;&quot;&quot;</span></div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;        <span class="keywordflow">pass</span></div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;</div></div><!-- fragment -->
</div>
</div>
<a id="a9ed5aecabe977856b4c385ba74fa6107"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ed5aecabe977856b4c385ba74fa6107">&#9670;&nbsp;</a></span>reorder_encoder_states()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.core.torch_generator_agent.TorchGeneratorModel.reorder_encoder_states </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encoder_states</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indices</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Reorder encoder states according to a new set of indices.

This is an abstract method, and *must* be implemented by the user.

Its purpose is to provide beam search with a model-agnostic interface for
beam search. For example, this method is used to sort hypotheses,
expand beams, etc.

For example, assume that encoder_states is an bsz x 1 tensor of values

.. code-block:: python

    indices = [0, 2, 2]
    encoder_states = [[0.1]
              [0.2]
              [0.3]]

then the output will be

.. code-block:: python

    output = [[0.1]
      [0.3]
      [0.3]]

:param encoder_states:
    output from encoder. type is model specific.

:type encoder_states:
    model specific

:param indices:
    the indices to select over. The user must support non-tensor
    inputs.

:type indices: list[int]

:return:
    The re-ordered encoder states. It should be of the same type as
    encoder states, and it must be a valid input to the decoder.

:rtype:
    model specific
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00110">110</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    <span class="keyword">def </span>reorder_encoder_states(self, encoder_states, indices):</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;        <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="stringliteral">        Reorder encoder states according to a new set of indices.</span></div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="stringliteral">        This is an abstract method, and *must* be implemented by the user.</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;<span class="stringliteral">        Its purpose is to provide beam search with a model-agnostic interface for</span></div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;<span class="stringliteral">        beam search. For example, this method is used to sort hypotheses,</span></div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="stringliteral">        expand beams, etc.</span></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;<span class="stringliteral">        For example, assume that encoder_states is an bsz x 1 tensor of values</span></div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;<span class="stringliteral">        .. code-block:: python</span></div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;<span class="stringliteral">            indices = [0, 2, 2]</span></div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;<span class="stringliteral">            encoder_states = [[0.1]</span></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;<span class="stringliteral">                              [0.2]</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;<span class="stringliteral">                              [0.3]]</span></div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;<span class="stringliteral">        then the output will be</span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="stringliteral">        .. code-block:: python</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;<span class="stringliteral">            output = [[0.1]</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="stringliteral">                      [0.3]</span></div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;<span class="stringliteral">                      [0.3]]</span></div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="stringliteral">        :param encoder_states:</span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="stringliteral">            output from encoder. type is model specific.</span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="stringliteral">        :type encoder_states:</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="stringliteral">            model specific</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;<span class="stringliteral">        :param indices:</span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="stringliteral">            the indices to select over. The user must support non-tensor</span></div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="stringliteral">            inputs.</span></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;<span class="stringliteral">        :type indices: list[int]</span></div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;<span class="stringliteral">        :return:</span></div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="stringliteral">            The re-ordered encoder states. It should be of the same type as</span></div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="stringliteral">            encoder states, and it must be a valid input to the decoder.</span></div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="stringliteral">        :rtype:</span></div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="stringliteral">            model specific</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;<span class="stringliteral">        &quot;&quot;&quot;</span></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;        <span class="keywordflow">pass</span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;</div></div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a1d9cfef6046368b5e7b77bc44b13473e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d9cfef6046368b5e7b77bc44b13473e">&#9670;&nbsp;</a></span>END_IDX</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.core.torch_generator_agent.TorchGeneratorModel.END_IDX</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00072">72</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>

</div>
</div>
<a id="a14dcf5ba14c4438bb4919565ebd30fa8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a14dcf5ba14c4438bb4919565ebd30fa8">&#9670;&nbsp;</a></span>longest_label</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.core.torch_generator_agent.TorchGeneratorModel.longest_label</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00074">74</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>

</div>
</div>
<a id="a686d4c12ada077cbf2b9c57544cbbe20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a686d4c12ada077cbf2b9c57544cbbe20">&#9670;&nbsp;</a></span>NULL_IDX</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.core.torch_generator_agent.TorchGeneratorModel.NULL_IDX</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html#l00071">71</a> of file <a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>parlai/core/<a class="el" href="../../d5/d19/torch__generator__agent_8py_source.html">torch_generator_agent.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
