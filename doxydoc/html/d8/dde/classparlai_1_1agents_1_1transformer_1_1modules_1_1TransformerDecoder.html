<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: parlai.agents.transformer.modules.TransformerDecoder Class Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d5/d22/namespaceparlai.html">parlai</a></li><li class="navelem"><a class="el" href="../../dd/d61/namespaceparlai_1_1agents.html">agents</a></li><li class="navelem"><a class="el" href="../../d2/db2/namespaceparlai_1_1agents_1_1transformer.html">transformer</a></li><li class="navelem"><a class="el" href="../../d2/dba/namespaceparlai_1_1agents_1_1transformer_1_1modules.html">modules</a></li><li class="navelem"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html">TransformerDecoder</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="../../d5/d6e/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">parlai.agents.transformer.modules.TransformerDecoder Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for parlai.agents.transformer.modules.TransformerDecoder:</div>
<div class="dyncontent">
<div class="center"><img src="../../d4/d8d/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder__inherit__graph.png" border="0" usemap="#parlai_8agents_8transformer_8modules_8TransformerDecoder_inherit__map" alt="Inheritance graph"/></div>
<map name="parlai_8agents_8transformer_8modules_8TransformerDecoder_inherit__map" id="parlai_8agents_8transformer_8modules_8TransformerDecoder_inherit__map">
</map>
<center><span class="legend">[<a href="../../graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for parlai.agents.transformer.modules.TransformerDecoder:</div>
<div class="dyncontent">
<div class="center"><img src="../../d7/d21/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder__coll__graph.png" border="0" usemap="#parlai_8agents_8transformer_8modules_8TransformerDecoder_coll__map" alt="Collaboration graph"/></div>
<map name="parlai_8agents_8transformer_8modules_8TransformerDecoder_coll__map" id="parlai_8agents_8transformer_8modules_8TransformerDecoder_coll__map">
</map>
<center><span class="legend">[<a href="../../graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ac9356241c0dd44bf980a155124cbde59"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#ac9356241c0dd44bf980a155124cbde59">__init__</a> (self, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#af83edca868bacf80329be8606ffc7efb">n_heads</a>, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a20983026d2ed3edd48698ed08d666287">n_layers</a>, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#abb275df1d00ad62deb2424266f1563d6">embedding_size</a>, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a90c40d660300194a42a18dc38f7e9fb2">ffn_size</a>, vocabulary_size, embedding=None, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a0d41303200949e8406daf8426ce7cbb3">dropout</a>=0.0, attention_dropout=0.0, relu_dropout=0.0, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a45a356a825e02ed79cdc43cf7f5dc8af">embeddings_scale</a>=True, learn_positional_embeddings=False, padding_idx=None, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a91210271cf67a77c0ab81f03f29bf70d">n_positions</a>=1024, n_segments=0, <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a84349da2592ce07a34257a3995dd2254">variant</a>='aiayn', <a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#aced85fffc20320f29be295f94e686a63">activation</a>='relu')</td></tr>
<tr class="separator:ac9356241c0dd44bf980a155124cbde59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19b2e9eecef1384bcfa9f772cac24a20"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a19b2e9eecef1384bcfa9f772cac24a20">forward</a> (self, input, encoder_state, incr_state=None)</td></tr>
<tr class="separator:a19b2e9eecef1384bcfa9f772cac24a20"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:abb275df1d00ad62deb2424266f1563d6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#abb275df1d00ad62deb2424266f1563d6">embedding_size</a></td></tr>
<tr class="separator:abb275df1d00ad62deb2424266f1563d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90c40d660300194a42a18dc38f7e9fb2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a90c40d660300194a42a18dc38f7e9fb2">ffn_size</a></td></tr>
<tr class="separator:a90c40d660300194a42a18dc38f7e9fb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20983026d2ed3edd48698ed08d666287"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a20983026d2ed3edd48698ed08d666287">n_layers</a></td></tr>
<tr class="separator:a20983026d2ed3edd48698ed08d666287"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af83edca868bacf80329be8606ffc7efb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#af83edca868bacf80329be8606ffc7efb">n_heads</a></td></tr>
<tr class="separator:af83edca868bacf80329be8606ffc7efb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab29b2b4f3a44d3069d208c61ddba6f21"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#ab29b2b4f3a44d3069d208c61ddba6f21">dim</a></td></tr>
<tr class="separator:ab29b2b4f3a44d3069d208c61ddba6f21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aced85fffc20320f29be295f94e686a63"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#aced85fffc20320f29be295f94e686a63">activation</a></td></tr>
<tr class="separator:aced85fffc20320f29be295f94e686a63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84349da2592ce07a34257a3995dd2254"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a84349da2592ce07a34257a3995dd2254">variant</a></td></tr>
<tr class="separator:a84349da2592ce07a34257a3995dd2254"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45a356a825e02ed79cdc43cf7f5dc8af"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a45a356a825e02ed79cdc43cf7f5dc8af">embeddings_scale</a></td></tr>
<tr class="separator:a45a356a825e02ed79cdc43cf7f5dc8af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d41303200949e8406daf8426ce7cbb3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a0d41303200949e8406daf8426ce7cbb3">dropout</a></td></tr>
<tr class="separator:a0d41303200949e8406daf8426ce7cbb3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91210271cf67a77c0ab81f03f29bf70d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a91210271cf67a77c0ab81f03f29bf70d">n_positions</a></td></tr>
<tr class="separator:a91210271cf67a77c0ab81f03f29bf70d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18e16e542264d07a8c70f0c5b0d2e5ce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a18e16e542264d07a8c70f0c5b0d2e5ce">out_dim</a></td></tr>
<tr class="separator:a18e16e542264d07a8c70f0c5b0d2e5ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa6d97e0eeed7b3cc11e4b60fb4a86167"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#aa6d97e0eeed7b3cc11e4b60fb4a86167">embeddings</a></td></tr>
<tr class="separator:aa6d97e0eeed7b3cc11e4b60fb4a86167"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a930028ffdff0380897228bc156fe74"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a4a930028ffdff0380897228bc156fe74">norm_embeddings</a></td></tr>
<tr class="separator:a4a930028ffdff0380897228bc156fe74"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a253da75d3014b859206169b2d692ab07"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a253da75d3014b859206169b2d692ab07">position_embeddings</a></td></tr>
<tr class="separator:a253da75d3014b859206169b2d692ab07"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5007810b22cdfddf768bdd94c233f87e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d8/dde/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerDecoder.html#a5007810b22cdfddf768bdd94c233f87e">layers</a></td></tr>
<tr class="separator:a5007810b22cdfddf768bdd94c233f87e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Transformer Decoder layer.

:param int n_heads: the number of multihead attention heads.
:param int n_layers: number of transformer layers.
:param int embedding_size: the embedding sizes. Must be a multiple of n_heads.
:param int ffn_size: the size of the hidden layer in the FFN
:param embedding: an embedding matrix for the bottom layer of the transformer.
    If none, one is created for this encoder.
:param float dropout: Dropout used around embeddings and before layer
    layer normalizations. This is used in Vaswani 2017 and works well on
    large datasets.
:param float attention_dropout: Dropout performed after the multhead attention
    softmax. This is not used in Vaswani 2017.
:param float relu_attention: Dropout used after the ReLU in the FFN. Not used
    in Vaswani 2017, but used in Tensor2Tensor.
:param int padding_idx: Reserved padding index in the embeddings matrix.
:param bool learn_positional_embeddings: If off, sinusoidal embeddings are
    used. If on, position embeddings are learned from scratch.
:param bool embeddings_scale: Scale embeddings relative to their dimensionality.
    Found useful in fairseq.
:param int n_positions: Size of the position embeddings matrix.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00590">590</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ac9356241c0dd44bf980a155124cbde59"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9356241c0dd44bf980a155124cbde59">&#9670;&nbsp;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.agents.transformer.modules.TransformerDecoder.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_layers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>embedding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ffn_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vocabulary_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>embedding</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dropout</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_dropout</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>relu_dropout</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>embeddings_scale</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_positional_embeddings</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>padding_idx</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_positions</em> = <code>1024</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_segments</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>variant</em> = <code>'aiayn'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activation</em> = <code>'relu'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00633">633</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;    ):</div><div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;        super().__init__()</div><div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;        self.embedding_size = embedding_size</div><div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;        self.ffn_size = ffn_size</div><div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;        self.n_layers = n_layers</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;        self.n_heads = n_heads</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;        self.dim = embedding_size</div><div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;        self.activation = activation</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;        self.variant = variant</div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;        self.embeddings_scale = embeddings_scale</div><div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;        self.dropout = nn.Dropout(p=dropout)  <span class="comment"># --dropout</span></div><div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;</div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;        self.n_positions = n_positions</div><div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;        self.out_dim = embedding_size</div><div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;        <span class="keyword">assert</span> (</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;            embedding_size % n_heads == 0</div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;        ), <span class="stringliteral">&#39;Transformer embedding size must be a multiple of n_heads&#39;</span></div><div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;        self.embeddings = embedding</div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;</div><div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;        <span class="keywordflow">if</span> self.variant == <span class="stringliteral">&#39;xlm&#39;</span>:</div><div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;            self.norm_embeddings = LayerNorm(self.dim, eps=LAYER_NORM_EPS)</div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;        <span class="keywordflow">elif</span> self.variant == <span class="stringliteral">&#39;aiayn&#39;</span>:</div><div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;            <span class="keywordflow">pass</span></div><div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Can&#39;t handle --variant {}&quot;</span>.<a class="code" href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">format</a>(self.variant))</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;</div><div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;        <span class="comment"># create the positional embeddings</span></div><div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;        self.position_embeddings = nn.Embedding(n_positions, embedding_size)</div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;        <span class="keywordflow">if</span> <span class="keywordflow">not</span> learn_positional_embeddings:</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;            <a class="code" href="../../d2/dba/namespaceparlai_1_1agents_1_1transformer_1_1modules.html#a0b86437e6e9682fa3100e9cadcaae259">create_position_codes</a>(</div><div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;                n_positions, embedding_size, out=self.position_embeddings.weight</div><div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;            )</div><div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;            nn.init.normal_(self.position_embeddings.weight, 0, embedding_size ** -0.5)</div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;</div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;        <span class="comment"># build the model</span></div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;        self.layers = nn.ModuleList()</div><div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.n_layers):</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;            self.layers.append(</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;                TransformerDecoderLayer(</div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;                    n_heads,</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;                    embedding_size,</div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;                    ffn_size,</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;                    attention_dropout=attention_dropout,</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;                    relu_dropout=relu_dropout,</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;                    dropout=dropout,</div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;                    activation=activation,</div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;                    variant=variant,</div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;                )</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;            )</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;</div><div class="ttc" id="namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_html_a32e2e2022b824fbaf80c747160b52a76"><div class="ttname"><a href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">parlai.chat_service.services.messenger.shared_utils.format</a></div><div class="ttdeci">format</div><div class="ttdef"><b>Definition:</b> <a href="../../d6/da3/chat__service_2services_2messenger_2shared__utils_8py_source.html#l00029">shared_utils.py:29</a></div></div>
<div class="ttc" id="namespaceparlai_1_1agents_1_1transformer_1_1modules_html_a0b86437e6e9682fa3100e9cadcaae259"><div class="ttname"><a href="../../d2/dba/namespaceparlai_1_1agents_1_1transformer_1_1modules.html#a0b86437e6e9682fa3100e9cadcaae259">parlai.agents.transformer.modules.create_position_codes</a></div><div class="ttdeci">def create_position_codes(n_pos, dim, out)</div><div class="ttdef"><b>Definition:</b> <a href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00284">modules.py:284</a></div></div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a19b2e9eecef1384bcfa9f772cac24a20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a19b2e9eecef1384bcfa9f772cac24a20">&#9670;&nbsp;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.agents.transformer.modules.TransformerDecoder.forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encoder_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>incr_state</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Forward pass.

:param LongTensor[batch,seqlen] input:
    The decoder inputs (partial or full decoded token IDs).
:param encoder_state:
    Output from the encoder module forward pass.
:param incr_state:
    Ignored. Should always be ``None`` in this version.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00685">685</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;    <span class="keyword">def </span>forward(self, input, encoder_state, incr_state=None):</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;        <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;<span class="stringliteral">        Forward pass.</span></div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;<span class="stringliteral">        :param LongTensor[batch,seqlen] input:</span></div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;<span class="stringliteral">            The decoder inputs (partial or full decoded token IDs).</span></div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;<span class="stringliteral">        :param encoder_state:</span></div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;<span class="stringliteral">            Output from the encoder module forward pass.</span></div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;<span class="stringliteral">        :param incr_state:</span></div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;<span class="stringliteral">            Ignored. Should always be ``None`` in this version.</span></div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;<span class="stringliteral">        &quot;&quot;&quot;</span></div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;        encoder_output, encoder_mask = encoder_state</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;        seq_len = input.size(1)</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;        positions = input.new(seq_len).long()</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;        positions = torch.arange(seq_len, out=positions).unsqueeze(0)</div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;        tensor = self.embeddings(input)</div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;        <span class="keywordflow">if</span> self.embeddings_scale:</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;            tensor = tensor * np.sqrt(self.dim)</div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;        <span class="keywordflow">if</span> self.variant == <span class="stringliteral">&#39;xlm&#39;</span>:</div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;            tensor = _normalize(tensor, self.norm_embeddings)</div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;        <span class="keywordflow">if</span> positions.max().item() &gt; self.n_positions:</div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;            <a class="code" href="../../d7/db6/namespaceparlai_1_1utils_1_1misc.html#acf146e70ea7f6867969a7c2b545d4b4b">warn_once</a>(</div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;                <span class="stringliteral">&#39;You are inputting a sequence of {x} length, but only have &#39;</span></div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;                <span class="stringliteral">&#39;--n-positions {y}. Set --truncate or increase --n-positions&#39;</span>.<a class="code" href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">format</a>(</div><div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;                    x=positions.max().item(), y=self.n_positions</div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;                )</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;            )</div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;        tensor = tensor + self.position_embeddings(positions).expand_as(tensor)</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;        tensor = self.dropout(tensor)  <span class="comment"># --dropout</span></div><div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;</div><div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;        <span class="keywordflow">for</span> layer <span class="keywordflow">in</span> self.layers:</div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;            tensor = layer(tensor, encoder_output, encoder_mask)</div><div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;</div><div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;        <span class="keywordflow">return</span> tensor, <span class="keywordtype">None</span></div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;</div><div class="ttc" id="namespaceparlai_1_1utils_1_1misc_html_acf146e70ea7f6867969a7c2b545d4b4b"><div class="ttname"><a href="../../d7/db6/namespaceparlai_1_1utils_1_1misc.html#acf146e70ea7f6867969a7c2b545d4b4b">parlai.utils.misc.warn_once</a></div><div class="ttdeci">def warn_once(msg, warningtype=None)</div><div class="ttdef"><b>Definition:</b> <a href="../../d5/d02/misc_8py_source.html#l01064">misc.py:1064</a></div></div>
<div class="ttc" id="namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_html_a32e2e2022b824fbaf80c747160b52a76"><div class="ttname"><a href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">parlai.chat_service.services.messenger.shared_utils.format</a></div><div class="ttdeci">format</div><div class="ttdef"><b>Definition:</b> <a href="../../d6/da3/chat__service_2services_2messenger_2shared__utils_8py_source.html#l00029">shared_utils.py:29</a></div></div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="aced85fffc20320f29be295f94e686a63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aced85fffc20320f29be295f94e686a63">&#9670;&nbsp;</a></span>activation</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.activation</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00640">640</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="ab29b2b4f3a44d3069d208c61ddba6f21"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab29b2b4f3a44d3069d208c61ddba6f21">&#9670;&nbsp;</a></span>dim</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.dim</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00639">639</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a0d41303200949e8406daf8426ce7cbb3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d41303200949e8406daf8426ce7cbb3">&#9670;&nbsp;</a></span>dropout</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.dropout</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00643">643</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="abb275df1d00ad62deb2424266f1563d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb275df1d00ad62deb2424266f1563d6">&#9670;&nbsp;</a></span>embedding_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.embedding_size</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00635">635</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="aa6d97e0eeed7b3cc11e4b60fb4a86167"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa6d97e0eeed7b3cc11e4b60fb4a86167">&#9670;&nbsp;</a></span>embeddings</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.embeddings</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00651">651</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a45a356a825e02ed79cdc43cf7f5dc8af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45a356a825e02ed79cdc43cf7f5dc8af">&#9670;&nbsp;</a></span>embeddings_scale</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.embeddings_scale</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00642">642</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a90c40d660300194a42a18dc38f7e9fb2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90c40d660300194a42a18dc38f7e9fb2">&#9670;&nbsp;</a></span>ffn_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.ffn_size</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00636">636</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a5007810b22cdfddf768bdd94c233f87e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5007810b22cdfddf768bdd94c233f87e">&#9670;&nbsp;</a></span>layers</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.layers</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00670">670</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="af83edca868bacf80329be8606ffc7efb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af83edca868bacf80329be8606ffc7efb">&#9670;&nbsp;</a></span>n_heads</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.n_heads</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00638">638</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a20983026d2ed3edd48698ed08d666287"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20983026d2ed3edd48698ed08d666287">&#9670;&nbsp;</a></span>n_layers</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.n_layers</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00637">637</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a91210271cf67a77c0ab81f03f29bf70d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a91210271cf67a77c0ab81f03f29bf70d">&#9670;&nbsp;</a></span>n_positions</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.n_positions</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00645">645</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a4a930028ffdff0380897228bc156fe74"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a930028ffdff0380897228bc156fe74">&#9670;&nbsp;</a></span>norm_embeddings</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.norm_embeddings</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00654">654</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a18e16e542264d07a8c70f0c5b0d2e5ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18e16e542264d07a8c70f0c5b0d2e5ce">&#9670;&nbsp;</a></span>out_dim</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.out_dim</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00646">646</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a253da75d3014b859206169b2d692ab07"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a253da75d3014b859206169b2d692ab07">&#9670;&nbsp;</a></span>position_embeddings</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.position_embeddings</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00661">661</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a84349da2592ce07a34257a3995dd2254"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a84349da2592ce07a34257a3995dd2254">&#9670;&nbsp;</a></span>variant</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerDecoder.variant</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00641">641</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>parlai/agents/transformer/<a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
