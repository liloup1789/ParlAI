<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: parlai.utils.torch Namespace Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d5/d22/namespaceparlai.html">parlai</a></li><li class="navelem"><a class="el" href="../../d2/d79/namespaceparlai_1_1utils.html">utils</a></li><li class="navelem"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html">torch</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">parlai.utils.torch Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a6c6e25115353dba479cd72dc31dc76ae"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a6c6e25115353dba479cd72dc31dc76ae">neginf</a></td></tr>
<tr class="separator:a6c6e25115353dba479cd72dc31dc76ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30f55f2d76c1e7f01e2612ecef231946"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a30f55f2d76c1e7f01e2612ecef231946">padded_tensor</a></td></tr>
<tr class="separator:a30f55f2d76c1e7f01e2612ecef231946"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1494906187c1ba19f92defb0d4c19ffe"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a1494906187c1ba19f92defb0d4c19ffe">padded_3d</a></td></tr>
<tr class="separator:a1494906187c1ba19f92defb0d4c19ffe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c7101b91c9bc5f6e00c4c65fc5ab21c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a6c7101b91c9bc5f6e00c4c65fc5ab21c">argsort</a></td></tr>
<tr class="separator:a6c7101b91c9bc5f6e00c4c65fc5ab21c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd34433af9f43b196920120e6009494e"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#acd34433af9f43b196920120e6009494e">fp16_optimizer_wrapper</a></td></tr>
<tr class="separator:acd34433af9f43b196920120e6009494e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ab38e7db22c2af18f6be15a319b63c489"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#ab38e7db22c2af18f6be15a319b63c489">NEAR_INF</a></td></tr>
<tr class="separator:ab38e7db22c2af18f6be15a319b63c489"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af25a0bd083e5ec4a1532b48acb165911"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#af25a0bd083e5ec4a1532b48acb165911">NEAR_INF_FP16</a></td></tr>
<tr class="separator:af25a0bd083e5ec4a1532b48acb165911"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a6c7101b91c9bc5f6e00c4c65fc5ab21c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c7101b91c9bc5f6e00c4c65fc5ab21c">&#9670;&nbsp;</a></span>argsort()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.utils.torch.argsort </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>keys</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d80/torch_8py_source.html#l00153">153</a> of file <a class="el" href="../../d5/d80/torch_8py_source.html">torch.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="keyword">def </span><a class="code" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a6c7101b91c9bc5f6e00c4c65fc5ab21c">argsort</a>(keys: List[Any], *lists: List[List[Any]], descending: bool = <span class="keyword">False</span>):</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;<span class="stringliteral">    Reorder each list in lists by the (descending) sorted order of keys.</span></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="stringliteral">    :param iter keys:</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="stringliteral">        Keys to order by.</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="stringliteral">    :param list[list] lists:</span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="stringliteral">        Lists to reordered by keys&#39;s order.  Correctly handles lists and 1-D</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="stringliteral">        tensors.</span></div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="stringliteral">    :param bool descending:</span></div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="stringliteral">        Use descending order if true.</span></div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="stringliteral">    :returns:</span></div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="stringliteral">        The reordered items.</span></div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    ind_sorted = sorted(range(len(keys)), key=<span class="keyword">lambda</span> k: keys[k])</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;    <span class="keywordflow">if</span> descending:</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        ind_sorted = list(reversed(ind_sorted))</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;    output = []</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;    <span class="keywordflow">for</span> lst <span class="keywordflow">in</span> lists:</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        <span class="comment"># watch out in case we don&#39;t have torch installed</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;        <span class="keywordflow">if</span> isinstance(lst, torch.Tensor):</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;            output.append(lst[ind_sorted])</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;            output.append([lst[i] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> ind_sorted])</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;    <span class="keywordflow">return</span> output</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;</div><div class="ttc" id="namespaceparlai_1_1utils_1_1torch_html_a6c7101b91c9bc5f6e00c4c65fc5ab21c"><div class="ttname"><a href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a6c7101b91c9bc5f6e00c4c65fc5ab21c">parlai.utils.torch.argsort</a></div><div class="ttdeci">def argsort</div><div class="ttdef"><b>Definition:</b> <a href="../../d5/d80/torch_8py_source.html#l00153">torch.py:153</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="acd34433af9f43b196920120e6009494e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd34433af9f43b196920120e6009494e">&#9670;&nbsp;</a></span>fp16_optimizer_wrapper()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.utils.torch.fp16_optimizer_wrapper </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>optimizer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d80/torch_8py_source.html#l00182">182</a> of file <a class="el" href="../../d5/d80/torch_8py_source.html">torch.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;    optimizer: torch.optim.Optimizer,  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;    verbose: bool = <span class="keyword">False</span>,</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;    dynamic_loss_scale: bool = <span class="keyword">True</span>,</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;    loss_initial_scale: float = 2.0 ** 17,</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;):</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="stringliteral">    Wrap the an optimizer with FP16 loss scaling protection.</span></div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;<span class="stringliteral">    Requires apex to be installed. Will throw an ImportError if it is not.</span></div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;<span class="stringliteral">    :param optimizer:</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="stringliteral">        Any torch optimizer</span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="stringliteral">    :param bool verbose:</span></div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;<span class="stringliteral">        Enables verbose output in the FP16 optimizer. Turning this on can help</span></div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;<span class="stringliteral">        debug when FP16 is underperforming.</span></div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;<span class="stringliteral">    :param bool dynamic_loss_scaling:</span></div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;<span class="stringliteral">        FP16 requires loss scaling to avoid underflows. It is recommended this</span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;<span class="stringliteral">        stays on, but advanced users may want it off.</span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="stringliteral">    :param float loss_initial_scale:</span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;<span class="stringliteral">        Initial loss scaling. Default chosen empirically, but models with very low</span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="stringliteral">        or high loss values may need this adjusted. Stick with powers of 2.</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="stringliteral">    :returns:</span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="stringliteral">        An APEX FP16 optimizer. Please note this has different requirements on</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="stringliteral">        how backward() and step() are called.</span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;    <span class="keywordflow">try</span>:</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;        <span class="keyword">import</span> apex.fp16_utils</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    <span class="keywordflow">except</span> ImportError:</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;        <span class="keywordflow">raise</span> ImportError(</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;            <span class="stringliteral">&#39;No fp16 support without apex. Please install it from &#39;</span></div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;            <span class="stringliteral">&#39;https://github.com/NVIDIA/apex&#39;</span></div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;        )</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;    <span class="keywordflow">return</span> apex.fp16_utils.FP16_Optimizer(</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;        optimizer,</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;        dynamic_loss_scale=dynamic_loss_scale,</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        verbose=verbose,</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;        <span class="comment"># TODO: We may later want to remove this flag. Right now it</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;        <span class="comment"># empirically improves the first few backward passes, but future APEX</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;        <span class="comment"># improvements may make this unnecessary.</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;        dynamic_loss_args={<span class="stringliteral">&#39;init_scale&#39;</span>: loss_initial_scale},</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;    )</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;</div><!-- fragment -->
</div>
</div>
<a id="a6c6e25115353dba479cd72dc31dc76ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c6e25115353dba479cd72dc31dc76ae">&#9670;&nbsp;</a></span>neginf()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.utils.torch.neginf </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d80/torch_8py_source.html#l00024">24</a> of file <a class="el" href="../../d5/d80/torch_8py_source.html">torch.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="keyword">def </span><a class="code" href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a6c6e25115353dba479cd72dc31dc76ae">neginf</a>(dtype: torch.dtype) -&gt; float:</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="stringliteral">    Return a representable finite number near -inf for a dtype.</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;    <span class="keywordflow">if</span> dtype <span class="keywordflow">is</span> torch.float16:</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;        <span class="keywordflow">return</span> -NEAR_INF_FP16</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;    <span class="keywordflow">else</span>:</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;        <span class="keywordflow">return</span> -NEAR_INF</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="ttc" id="namespaceparlai_1_1utils_1_1torch_html_a6c6e25115353dba479cd72dc31dc76ae"><div class="ttname"><a href="../../da/dd4/namespaceparlai_1_1utils_1_1torch.html#a6c6e25115353dba479cd72dc31dc76ae">parlai.utils.torch.neginf</a></div><div class="ttdeci">def neginf</div><div class="ttdef"><b>Definition:</b> <a href="../../d5/d80/torch_8py_source.html#l00024">torch.py:24</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a1494906187c1ba19f92defb0d4c19ffe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1494906187c1ba19f92defb0d4c19ffe">&#9670;&nbsp;</a></span>padded_3d()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.utils.torch.padded_3d </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensors</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d80/torch_8py_source.html#l00106">106</a> of file <a class="el" href="../../d5/d80/torch_8py_source.html">torch.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    tensors: List[torch.LongTensor],</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;    pad_idx: int = 0,</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    use_cuda: bool = <span class="keyword">False</span>,</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    dtype: Optional[torch.dtype] = torch.long,</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    fp16friendly: bool = <span class="keyword">False</span>,</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;):</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="stringliteral">    Make 3D padded tensor for list of lists of 1D tensors or lists.</span></div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="stringliteral">    :param tensors:</span></div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;<span class="stringliteral">        list of lists of 1D tensors (or lists)</span></div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;<span class="stringliteral">    :param pad_idx:</span></div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="stringliteral">        padding to fill tensor with</span></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="stringliteral">    :param use_cuda:</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;<span class="stringliteral">        whether to call cuda() before returning</span></div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;<span class="stringliteral">    :param bool fp16friendly:</span></div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;<span class="stringliteral">        if True, pads the final dimension to be a multiple of 8.</span></div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;<span class="stringliteral">    :returns:</span></div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;<span class="stringliteral">        3D tensor with the maximum dimensions of the inputs</span></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    a = len(tensors)</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;    b = max(len(row) <span class="keywordflow">for</span> row <span class="keywordflow">in</span> tensors)  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;    c = max(len(item) <span class="keywordflow">for</span> row <span class="keywordflow">in</span> tensors <span class="keywordflow">for</span> item <span class="keywordflow">in</span> row)  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    <span class="comment"># pad empty tensors</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;    <span class="keywordflow">if</span> fp16friendly <span class="keywordflow">and</span> c % 8 != 0:</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;        c += 8 - (c % 8)</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    c = max(c, 1)</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    output = torch.full((a, b, c), pad_idx, dtype=dtype)</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    <span class="keywordflow">for</span> i, row <span class="keywordflow">in</span> enumerate(tensors):</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;        item: Sized</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;        <span class="keywordflow">for</span> j, item <span class="keywordflow">in</span> enumerate(row):  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;            <span class="keywordflow">if</span> len(item) == 0:</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;                <span class="keywordflow">continue</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;            <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(item, torch.Tensor):</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;                item = torch.Tensor(item, dtype=dtype)</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;            output[i, j, : len(item)] = item</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    <span class="keywordflow">if</span> use_cuda:</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        output = output.cuda()</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    <span class="keywordflow">return</span> output</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;</div></div><!-- fragment -->
</div>
</div>
<a id="a30f55f2d76c1e7f01e2612ecef231946"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30f55f2d76c1e7f01e2612ecef231946">&#9670;&nbsp;</a></span>padded_tensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.utils.torch.padded_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>items</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d80/torch_8py_source.html#l00035">35</a> of file <a class="el" href="../../d5/d80/torch_8py_source.html">torch.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;    items: List[Union[List[int], torch.LongTensor]],</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;    pad_idx: int = 0,</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;    use_cuda: bool = <span class="keyword">False</span>,</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;    left_padded: bool = <span class="keyword">False</span>,</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;    max_len: Optional[int] = <span class="keywordtype">None</span>,</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;    fp16friendly: bool = <span class="keyword">False</span>,</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;) -&gt; Tuple[torch.LongTensor, List[int]]:</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="stringliteral">    Create a right-padded matrix from an uneven list of lists.</span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="stringliteral">    Returns (padded, lengths), where padded is the padded matrix, and lengths</span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="stringliteral">    is a list containing the lengths of each row.</span></div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="stringliteral">    Matrix is right-padded (filled to the right) by default, but can be</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="stringliteral">    left padded if the flag is set to True.</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="stringliteral">    Matrix can also be placed on cuda automatically.</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="stringliteral">    :param list[iter[int]] items: List of items</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="stringliteral">    :param bool sort: If True, orders by the length</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="stringliteral">    :param int pad_idx: the value to use for padding</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="stringliteral">    :param bool use_cuda: if true, places `padded` on GPU</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="stringliteral">    :param bool left_padded:</span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="stringliteral">    :param int max_len: if None, the max length is the maximum item length</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="stringliteral">    :param bool fp16friendly: if True, pads the time dimension to be a multiple of 8.</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="stringliteral">    :returns: (padded, lengths) tuple</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="stringliteral">    :rtype: (Tensor[int64], list[int])</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="stringliteral">    &quot;&quot;&quot;</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;    <span class="comment"># number of items</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    n = len(items)</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    <span class="comment"># length of each item</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    lens: List[int] = [len(item) <span class="keywordflow">for</span> item <span class="keywordflow">in</span> items]  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <span class="comment"># max in time dimension</span></div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    t = max(lens) <span class="keywordflow">if</span> max_len <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> max_len</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <span class="comment"># if input tensors are empty, we should expand to nulls</span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    t = max(t, 1)</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    <span class="keywordflow">if</span> fp16friendly <span class="keywordflow">and</span> (t % 8 != 0):</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        <span class="comment"># pad to be a multiple of 8 to ensure we use the tensor cores</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        t += 8 - (t % 8)</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    <span class="keywordflow">if</span> isinstance(items[0], torch.Tensor):</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;        <span class="comment"># keep type of input tensors, they may already be cuda ones</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;        output = items[0].new(n, t)  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keywordflow">else</span>:</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;        output = torch.LongTensor(n, t)  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;    output.fill_(pad_idx)</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <span class="keywordflow">for</span> i, (item, length) <span class="keywordflow">in</span> enumerate(zip(items, lens)):</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;        <span class="keywordflow">if</span> length == 0:</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;            <span class="comment"># skip empty items</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;            <span class="keywordflow">continue</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;        <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(item, torch.Tensor):</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;            <span class="comment"># put non-tensors into a tensor</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;            item = torch.LongTensor(item)  <span class="comment"># type: ignore</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;        <span class="keywordflow">if</span> left_padded:</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;            <span class="comment"># place at end</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;            output[i, t - length :] = item</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;            <span class="comment"># place at beginning</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;            output[i, :length] = item</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    <span class="keywordflow">if</span> use_cuda:</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        output = output.cuda()</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;    <span class="keywordflow">return</span> output, lens</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;</div></div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="ab38e7db22c2af18f6be15a319b63c489"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab38e7db22c2af18f6be15a319b63c489">&#9670;&nbsp;</a></span>NEAR_INF</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.utils.torch.NEAR_INF</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d80/torch_8py_source.html#l00020">20</a> of file <a class="el" href="../../d5/d80/torch_8py_source.html">torch.py</a>.</p>

</div>
</div>
<a id="af25a0bd083e5ec4a1532b48acb165911"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af25a0bd083e5ec4a1532b48acb165911">&#9670;&nbsp;</a></span>NEAR_INF_FP16</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.utils.torch.NEAR_INF_FP16</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d5/d80/torch_8py_source.html#l00021">21</a> of file <a class="el" href="../../d5/d80/torch_8py_source.html">torch.py</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
