<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: docs/source/tutorial_torch_generator_agent.md Source File</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">docs/source/tutorial_torch_generator_agent.md</div>  </div>
</div><!--header-->
<div class="contents">
<a href="../../d9/d65/tutorial__torch__generator__agent_8md.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# Using Torch Generator Agent</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;**Authors**: Eric Smith</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;`parlai.core.torch_generator_agent.TorchGeneratorAgent` is an abstract parent class that provides functionality for building autoregressive generative models. Extending `TorchGeneratorAgent` requires your model conform to a strict interface, but then provides you rich functionality like beam search and sampling.</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;## Example Models</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;Two major models in ParlAI inherit from `TorchGeneratorAgent`: seq2seq and transformer. You can try the transformer with the example below:</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;```</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;python examples/train_model -m transformer/generator -t convai2 -mf /tmp/testtransformer \</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;  --beam-size 5 -bs 16</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;```</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;## Creating a Model</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;In order to write a generative model, your agent should extend `TorchGeneratorAgent`. This parent class implements `train_step` and `eval_step`, so you only need to implement your model and instantiate it through `build_model`. `TorchGeneratorAgent` will take care of many common generator features, such as forced decoding, beam search, n-gram beam blocking, top-k and top-p/nucleus sampling, etc.</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;Additionally, your model should implement the `TorchGeneratorModel` interface: see the tutorial below for an example of this.</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;## Tutorial</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;This tutorial will walk you through creating a simple generative model, found at `parlai.agents.examples.seq2seq`, that consists of a 1-layer-LSTM encoder and decoder.</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;### Extending `TorchGeneratorAgent`</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;Creating a generative model in ParlAI consists of subclassing `TorchGeneratorAgent` and subclassing `TorchGeneratorModel`. A minimal subclass of `TorchGeneratorAgent` only needs to implement `build_model()`, but if you want to specify any command-line arguments, you&#39;ll need to add `add_cmdline_args()` as well. Our implementation below first adds flags for `TorchGeneratorAgent` and then adds a `--hidden-size` flag for the hidden dimension of the LSTMs of the encoder and decoder.</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;In `build_model()`, we instantiate our example model (defined below) by passing in the agent&#39;s dict (set by `TorchAgent`) and the hidden size. We add lines to optionally copy pre-existing token embeddings into the model&#39;s embedding table.</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;Altogether, our example agent is defined as follows:</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;```</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;import parlai.core.torch_generator_agent as tga</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;class Seq2seqAgent(tga.TorchGeneratorAgent):</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    @classmethod</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;    def add_cmdline_args(cls, argparser):</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;        super(Seq2seqAgent, cls).add_cmdline_args(argparser)</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;        group = argparser.add_argument_group(&#39;Example TGA Agent&#39;)</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;        group.add_argument(</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;            &#39;-hid&#39;, &#39;--hidden-size&#39;, type=int, default=1024, help=&#39;Hidden size.&#39;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;        )</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    def build_model(self):</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;        model = ExampleModel(self.dict, self.opt[&#39;hidden_size&#39;])</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;        if self.opt[&#39;embedding_type&#39;] != &#39;random&#39;:</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;            self._copy_embeddings(</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;                model.embeddings.weight, self.opt[&#39;embedding_type&#39;]</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;            )</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;        return model</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;```</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;### Extending `TorchGeneratorModel`</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;We now subclass `TorchGeneratorModel` to create `ExampleModel`. We initialize this by first calling `super().__init__()` and passing in dictionary tokens for padding, start, end, and UNKs; we then create an embedding lookup table with `nn.Embedding` and instantiate the encoder and decoder, described in the following sections.</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;```</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;import torch.nn as nn</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;import torch.nn.functional as F</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;class ExampleModel(tga.TorchGeneratorModel):</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    def __init__(self, dictionary, esz=256, hidden_size=1024):</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        super().__init__(</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;            padding_idx=dictionary[dictionary.null_token],</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;            start_idx=dictionary[dictionary.start_token],</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;            end_idx=dictionary[dictionary.end_token],</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;            unknown_idx=dictionary[dictionary.unk_token],</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        )</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        self.embeddings = nn.Embedding(len(dictionary), esz)</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        self.encoder = Encoder(self.embeddings, hidden_size)</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        self.decoder = Decoder(self.embeddings, hidden_size)</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;```</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;We next define a function to project the output of the decoder back into the token space:</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;```</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;    def output(self, decoder_output):</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;        return F.linear(decoder_output, self.embeddings.weight)</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;```</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;Lastly, we define two functions to reindex the latent states of the encoder and decoder. For the encoder, the indices that we pass in index the samples in the batch, and for the decoder, the indices index the candidates that we want to retain for the next step of decoding (for instance, in beam search). We reindex the encoder at the very beginning of beam search and when ranking candidates during eval, and we reindex the decoder after each step of decoding. Since our encoder and decoder both are based on LSTMs, these encoder/decoder states are the hidden and cell states:</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;```</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    def reorder_encoder_states(self, encoder_states, indices):</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;        h, c = encoder_states</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;        return h[:, indices, :], c[:, indices, :]</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    def reorder_decoder_incremental_state(self, incr_state, indices):</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        h, c = incr_state</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        return h[:, indices, :], c[:, indices, :]</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;```</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;### Creating the encoder</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;The encoder is straightfoward: it contains an embedding layer and an LSTM, and a forward pass through the encoder consists of passing the sequences of input tokens through both of them sequentially. The final hidden state is returned.</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;```</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;class Encoder(nn.Module):</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    def __init__(self, embeddings, hidden_size):</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        super().__init__()</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;        _vocab_size, esz = embeddings.weight.shape</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;        self.embeddings = embeddings</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;        self.lstm = nn.LSTM(</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;            input_size=esz, hidden_size=hidden_size, num_layers=1, batch_first=True</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;        )</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;    def forward(self, input_tokens):</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;        embedded = self.embeddings(input_tokens)</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        _output, hidden = self.lstm(embedded)</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;        return hidden</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;```</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;### Creating the decoder</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;The decoder is initialized in the same way as the encoder, but now the forward pass reflects the fact that the input tokens need to be passed through the embedder and LSTM one token at a time rather than all at once. If this is the first pass through the decoder, we pass a tuple `encoder_state` to the LSTM that consists of the initial hidden and cell state, as taken from the output of the encoder. If this is a subsequent pass through the decoder, the LSTM will have given us the current values of the hidden and cell states, so we pass that back in to the LSTM, after potentially having reindexed the states with `ExampleModel().reorder_decoder_incremental_state()`.</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;```</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;class Decoder(nn.Module):</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    def __init__(self, embeddings, hidden_size):</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;        super().__init__()</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;        _vocab_size, self.esz = embeddings.weight.shape</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;        self.embeddings = embeddings</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;        self.lstm = nn.LSTM(</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;            input_size=self.esz, hidden_size=hidden_size, num_layers=1, batch_first=True</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;        )</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    def forward(self, input, encoder_state, incr_state=None):</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        embedded = self.embeddings(input)</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;        if incr_state is None:</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;            state = encoder_state</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;        else:</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;            state = incr_state</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;        output, incr_state = self.lstm(embedded, state)</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;        return output, incr_state</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;```</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;### Training</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;The full code for the agent can be seen [here](https://github.com/facebookresearch/ParlAI/tree/master/parlai/agents/examples/seq2seq.py). To call training:</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;```</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;python examples/train_model.py -m examples/seq2seq \</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    -mf /tmp/example_model \</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    -t convai2 -bs 32 -eps 2 --truncate 128</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;```</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;You should get a perplexity of around 140 and a token accuracy of around 28% on the ConvAI2 validation/test set.</div></div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
