<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: parlai.agents.transformer.modules.TransformerEncoder Class Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d5/d22/namespaceparlai.html">parlai</a></li><li class="navelem"><a class="el" href="../../dd/d61/namespaceparlai_1_1agents.html">agents</a></li><li class="navelem"><a class="el" href="../../d2/db2/namespaceparlai_1_1agents_1_1transformer.html">transformer</a></li><li class="navelem"><a class="el" href="../../d2/dba/namespaceparlai_1_1agents_1_1transformer_1_1modules.html">modules</a></li><li class="navelem"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html">TransformerEncoder</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="../../d5/d6f/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">parlai.agents.transformer.modules.TransformerEncoder Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for parlai.agents.transformer.modules.TransformerEncoder:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/db7/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder__inherit__graph.png" border="0" usemap="#parlai_8agents_8transformer_8modules_8TransformerEncoder_inherit__map" alt="Inheritance graph"/></div>
<map name="parlai_8agents_8transformer_8modules_8TransformerEncoder_inherit__map" id="parlai_8agents_8transformer_8modules_8TransformerEncoder_inherit__map">
</map>
<center><span class="legend">[<a href="../../graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for parlai.agents.transformer.modules.TransformerEncoder:</div>
<div class="dyncontent">
<div class="center"><img src="../../dd/ddb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder__coll__graph.png" border="0" usemap="#parlai_8agents_8transformer_8modules_8TransformerEncoder_coll__map" alt="Collaboration graph"/></div>
<map name="parlai_8agents_8transformer_8modules_8TransformerEncoder_coll__map" id="parlai_8agents_8transformer_8modules_8TransformerEncoder_coll__map">
</map>
<center><span class="legend">[<a href="../../graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a362f8b951877f3712ca59f0fb6a0ae9c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a362f8b951877f3712ca59f0fb6a0ae9c">__init__</a> (self, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ab6830a5aa0850e50549c159586c17515">n_heads</a>, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a1fac9c2d34c4d2268f50fc90b1e74e04">n_layers</a>, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a57f137ae98789edeae26de90118efdd6">embedding_size</a>, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#afadc86cb37af464565167dc169447057">ffn_size</a>, vocabulary_size, embedding=None, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#af28dbf5c6c0f70c1a032a3bbb5359661">dropout</a>=0.0, attention_dropout=0.0, relu_dropout=0.0, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a74702a13d7e41afc3e77c94bb60bd119">padding_idx</a>=0, learn_positional_embeddings=False, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a80122462ebd32da923d7b4479053ab01">embeddings_scale</a>=False, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a2703f337fd44344ccd93743e57be554e">reduction_type</a>='mean', <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ab885dd6b80284dbd2837ecaf75f96cb0">n_positions</a>=1024, activation='relu', <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a6ea46aeb8ca865c97ec8e99746bedd7b">variant</a>='aiayn', <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ab5ec60adca3ce418f73e409187a82625">n_segments</a>=0, <a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ad904c0d06a4f6851b38fbbc0cab224f9">output_scaling</a>=1.0)</td></tr>
<tr class="separator:a362f8b951877f3712ca59f0fb6a0ae9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23005871ba6683940f63511ed463266f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a23005871ba6683940f63511ed463266f">forward</a> (self, input, positions=None, segments=None)</td></tr>
<tr class="separator:a23005871ba6683940f63511ed463266f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a57f137ae98789edeae26de90118efdd6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a57f137ae98789edeae26de90118efdd6">embedding_size</a></td></tr>
<tr class="separator:a57f137ae98789edeae26de90118efdd6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afadc86cb37af464565167dc169447057"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#afadc86cb37af464565167dc169447057">ffn_size</a></td></tr>
<tr class="separator:afadc86cb37af464565167dc169447057"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fac9c2d34c4d2268f50fc90b1e74e04"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a1fac9c2d34c4d2268f50fc90b1e74e04">n_layers</a></td></tr>
<tr class="separator:a1fac9c2d34c4d2268f50fc90b1e74e04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6830a5aa0850e50549c159586c17515"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ab6830a5aa0850e50549c159586c17515">n_heads</a></td></tr>
<tr class="separator:ab6830a5aa0850e50549c159586c17515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab56fa99f887753677dc7f4d435595114"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ab56fa99f887753677dc7f4d435595114">dim</a></td></tr>
<tr class="separator:ab56fa99f887753677dc7f4d435595114"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80122462ebd32da923d7b4479053ab01"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a80122462ebd32da923d7b4479053ab01">embeddings_scale</a></td></tr>
<tr class="separator:a80122462ebd32da923d7b4479053ab01"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2703f337fd44344ccd93743e57be554e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a2703f337fd44344ccd93743e57be554e">reduction_type</a></td></tr>
<tr class="separator:a2703f337fd44344ccd93743e57be554e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74702a13d7e41afc3e77c94bb60bd119"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a74702a13d7e41afc3e77c94bb60bd119">padding_idx</a></td></tr>
<tr class="separator:a74702a13d7e41afc3e77c94bb60bd119"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af28dbf5c6c0f70c1a032a3bbb5359661"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#af28dbf5c6c0f70c1a032a3bbb5359661">dropout</a></td></tr>
<tr class="separator:af28dbf5c6c0f70c1a032a3bbb5359661"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6ea46aeb8ca865c97ec8e99746bedd7b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a6ea46aeb8ca865c97ec8e99746bedd7b">variant</a></td></tr>
<tr class="separator:a6ea46aeb8ca865c97ec8e99746bedd7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5ec60adca3ce418f73e409187a82625"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ab5ec60adca3ce418f73e409187a82625">n_segments</a></td></tr>
<tr class="separator:ab5ec60adca3ce418f73e409187a82625"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab885dd6b80284dbd2837ecaf75f96cb0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ab885dd6b80284dbd2837ecaf75f96cb0">n_positions</a></td></tr>
<tr class="separator:ab885dd6b80284dbd2837ecaf75f96cb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd4ec22c3a8b8611a4a1caa85225b426"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#afd4ec22c3a8b8611a4a1caa85225b426">out_dim</a></td></tr>
<tr class="separator:afd4ec22c3a8b8611a4a1caa85225b426"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a179492c3f7ebaf6ba8fb3a7f912e93ce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#a179492c3f7ebaf6ba8fb3a7f912e93ce">embeddings</a></td></tr>
<tr class="separator:a179492c3f7ebaf6ba8fb3a7f912e93ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2dd819e6d66d17f69e8bfa5026d192a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ad2dd819e6d66d17f69e8bfa5026d192a">position_embeddings</a></td></tr>
<tr class="separator:ad2dd819e6d66d17f69e8bfa5026d192a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8676d5d506949c00d35c34ac41b9fff"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ae8676d5d506949c00d35c34ac41b9fff">norm_embeddings</a></td></tr>
<tr class="separator:ae8676d5d506949c00d35c34ac41b9fff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbc50af3764335ae22ef2ba06a65c4a7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#acbc50af3764335ae22ef2ba06a65c4a7">segment_embeddings</a></td></tr>
<tr class="separator:acbc50af3764335ae22ef2ba06a65c4a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbeff4ac94daff4e1627b6d93cd37424"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#acbeff4ac94daff4e1627b6d93cd37424">layers</a></td></tr>
<tr class="separator:acbeff4ac94daff4e1627b6d93cd37424"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad904c0d06a4f6851b38fbbc0cab224f9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../dc/dbb/classparlai_1_1agents_1_1transformer_1_1modules_1_1TransformerEncoder.html#ad904c0d06a4f6851b38fbbc0cab224f9">output_scaling</a></td></tr>
<tr class="separator:ad904c0d06a4f6851b38fbbc0cab224f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Transformer encoder module.

:param int n_heads: the number of multihead attention heads.
:param int n_layers: number of transformer layers.
:param int embedding_size: the embedding sizes. Must be a multiple of n_heads.
:param int ffn_size: the size of the hidden layer in the FFN
:param embedding: an embedding matrix for the bottom layer of the transformer.
    If none, one is created for this encoder.
:param float dropout: Dropout used around embeddings and before layer
    layer normalizations. This is used in Vaswani 2017 and works well on
    large datasets.
:param float attention_dropout: Dropout performed after the multhead attention
    softmax. This is not used in Vaswani 2017.
:param float relu_attention: Dropout used after the ReLU in the FFN. Not used
    in Vaswani 2017, but used in Tensor2Tensor.
:param int padding_idx: Reserved padding index in the embeddings matrix.
:param bool learn_positional_embeddings: If off, sinusoidal embeddings are
    used. If on, position embeddings are learned from scratch.
:param bool embeddings_scale: Scale embeddings relative to their dimensionality.
    Found useful in fairseq.
:param bool reduction: If true, returns the mean vector for the entire encoding
    sequence.
:param int n_positions:
    Size of the position embeddings matrix.
:param int n_segments:
    Number of segments/lang/sentence embeddings.
:param activation:
    Type of nonlinear activation. Can be relu or gelu.
:param variant:
    Which transformer architecture to use. Could be AIAYN or XLM.
    Future versions may support things like GPT-2, ...
:param output_scaling:
    Scale the outputs by a given scalar
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00346">346</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a362f8b951877f3712ca59f0fb6a0ae9c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a362f8b951877f3712ca59f0fb6a0ae9c">&#9670;&nbsp;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.agents.transformer.modules.TransformerEncoder.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_layers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>embedding_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ffn_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vocabulary_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>embedding</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dropout</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_dropout</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>relu_dropout</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>padding_idx</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learn_positional_embeddings</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>embeddings_scale</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>reduction_type</em> = <code>'mean'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_positions</em> = <code>1024</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activation</em> = <code>'relu'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>variant</em> = <code>'aiayn'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_segments</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_scaling</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00403">403</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;    ):</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;        super(TransformerEncoder, self).__init__()</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;        self.embedding_size = embedding_size</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;        self.ffn_size = ffn_size</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;        self.n_layers = n_layers</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;        self.n_heads = n_heads</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;        self.dim = embedding_size</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;        self.embeddings_scale = embeddings_scale</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;        self.reduction_type = reduction_type</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;        self.padding_idx = padding_idx</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;        <span class="comment"># this is --dropout, not --relu-dropout or --attention-dropout</span></div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;        self.dropout = nn.Dropout(p=dropout)</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;        self.variant = variant</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;        self.n_segments = n_segments</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;        self.n_positions = n_positions</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;        self.out_dim = embedding_size</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;        <span class="keyword">assert</span> (</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;            embedding_size % n_heads == 0</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;        ), <span class="stringliteral">&#39;Transformer embedding size must be a multiple of n_heads&#39;</span></div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;        <span class="comment"># check input formats:</span></div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;        <span class="keywordflow">if</span> embedding <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;            <span class="keyword">assert</span> (</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;                embedding_size <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> embedding_size == embedding.weight.shape[1]</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;            ), <span class="stringliteral">&quot;Embedding dim must match the embedding size.&quot;</span></div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;        <span class="keywordflow">if</span> embedding <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;            self.embeddings = embedding</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;            <span class="keywordflow">raise</span> AssertionError(</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;                <span class="stringliteral">&quot;This code should not execute. Left here in case we want to enable it.&quot;</span></div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;            )</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;            <span class="keyword">assert</span> padding_idx <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span></div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;            self.embeddings = nn.Embedding(</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;                vocabulary_size, embedding_size, padding_idx=padding_idx</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;            )</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;            nn.init.normal_(self.embeddings.weight, 0, embedding_size ** -0.5)</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;</div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;        <span class="comment"># create the positional embeddings</span></div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;        self.position_embeddings = nn.Embedding(n_positions, embedding_size)</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;        <span class="keywordflow">if</span> <span class="keywordflow">not</span> learn_positional_embeddings:</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;            <a class="code" href="../../d2/dba/namespaceparlai_1_1agents_1_1transformer_1_1modules.html#a0b86437e6e9682fa3100e9cadcaae259">create_position_codes</a>(</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;                n_positions, embedding_size, out=self.position_embeddings.weight</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;            )</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;            nn.init.normal_(self.position_embeddings.weight, 0, embedding_size ** -0.5)</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;        <span class="comment"># embedding normalization</span></div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;        <span class="keywordflow">if</span> self.variant == <span class="stringliteral">&#39;xlm&#39;</span>:</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;            self.norm_embeddings = LayerNorm(self.dim, eps=LAYER_NORM_EPS)</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;        <span class="keywordflow">elif</span> self.variant == <span class="stringliteral">&#39;aiayn&#39;</span>:</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;            <span class="keywordflow">pass</span></div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;            <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Can&#39;t handle --variant {}&quot;</span>.<a class="code" href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">format</a>(self.variant))</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;        <span class="keywordflow">if</span> self.n_segments &gt;= 1:</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;            self.segment_embeddings = nn.Embedding(self.n_segments, self.dim)</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;        <span class="comment"># build the model</span></div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;        self.layers = nn.ModuleList()</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(self.n_layers):</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;            self.layers.append(</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;                TransformerEncoderLayer(</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;                    n_heads,</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;                    embedding_size,</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;                    ffn_size,</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;                    attention_dropout=attention_dropout,</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;                    relu_dropout=relu_dropout,</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;                    dropout=dropout,</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;                    variant=variant,</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;                    activation=activation,</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;                )</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;            )</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;        self.output_scaling = output_scaling</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;</div><div class="ttc" id="namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_html_a32e2e2022b824fbaf80c747160b52a76"><div class="ttname"><a href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">parlai.chat_service.services.messenger.shared_utils.format</a></div><div class="ttdeci">format</div><div class="ttdef"><b>Definition:</b> <a href="../../d6/da3/chat__service_2services_2messenger_2shared__utils_8py_source.html#l00029">shared_utils.py:29</a></div></div>
<div class="ttc" id="namespaceparlai_1_1agents_1_1transformer_1_1modules_html_a0b86437e6e9682fa3100e9cadcaae259"><div class="ttname"><a href="../../d2/dba/namespaceparlai_1_1agents_1_1transformer_1_1modules.html#a0b86437e6e9682fa3100e9cadcaae259">parlai.agents.transformer.modules.create_position_codes</a></div><div class="ttdeci">def create_position_codes(n_pos, dim, out)</div><div class="ttdef"><b>Definition:</b> <a href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00284">modules.py:284</a></div></div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a23005871ba6683940f63511ed463266f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23005871ba6683940f63511ed463266f">&#9670;&nbsp;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def parlai.agents.transformer.modules.TransformerEncoder.forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>positions</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>segments</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Forward pass.

:param LongTensor[batch,seqlen] input:
    The input IDs
:param BoolTensor[batch,seqlen] mask:
    The attention mask; 1 means attend, 0 means ignore.
:param LongTensor[batch,seqlen]:
    If provided, additionally adds ``segments`` as extra embedding features.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00480">480</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;    <span class="keyword">def </span>forward(self, input, positions=None, segments=None):</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;        <span class="stringliteral">&quot;&quot;&quot;</span></div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;<span class="stringliteral">        Forward pass.</span></div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;<span class="stringliteral"></span></div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;<span class="stringliteral">        :param LongTensor[batch,seqlen] input:</span></div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;<span class="stringliteral">            The input IDs</span></div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;<span class="stringliteral">        :param BoolTensor[batch,seqlen] mask:</span></div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;<span class="stringliteral">            The attention mask; 1 means attend, 0 means ignore.</span></div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;<span class="stringliteral">        :param LongTensor[batch,seqlen]:</span></div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;<span class="stringliteral">            If provided, additionally adds ``segments`` as extra embedding features.</span></div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;<span class="stringliteral">        &quot;&quot;&quot;</span></div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;        mask = input != self.padding_idx</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;        <span class="keywordflow">if</span> positions <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;            positions = (mask.cumsum(dim=1, dtype=torch.int64) - 1).clamp_(min=0)</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;        tensor = self.embeddings(input)</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;        <span class="keywordflow">if</span> self.embeddings_scale:</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;            tensor = tensor * np.sqrt(self.dim)</div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;        <span class="keywordflow">if</span> positions.max().item() &gt; self.n_positions:</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;            <a class="code" href="../../d7/db6/namespaceparlai_1_1utils_1_1misc.html#acf146e70ea7f6867969a7c2b545d4b4b">warn_once</a>(</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;                <span class="stringliteral">&#39;You are inputting a sequence of {x} length, but only have &#39;</span></div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;                <span class="stringliteral">&#39;--n-positions {y}. Set --truncate or increase --n-positions&#39;</span>.<a class="code" href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">format</a>(</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;                    x=positions.max().item(), y=self.n_positions</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;                )</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;            )</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;        position_embs = self.position_embeddings(positions).expand_as(tensor)</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;        tensor = tensor + position_embs</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;        <span class="keywordflow">if</span> self.n_segments &gt;= 1:</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;            <span class="keywordflow">if</span> segments <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;                segments = torch.zeros_like(input)</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;            tensor = tensor + self.segment_embeddings(segments)</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;        <span class="keywordflow">if</span> self.variant == <span class="stringliteral">&#39;xlm&#39;</span>:</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;            tensor = _normalize(tensor, self.norm_embeddings)</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;        <span class="comment"># --dropout on the embeddings</span></div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;        tensor = self.dropout(tensor)</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;        tensor *= mask.unsqueeze(-1).type_as(tensor)</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(self.n_layers):</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;            tensor = self.layers[i](tensor, mask)</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;        tensor *= self.output_scaling</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;        <span class="keywordflow">if</span> self.reduction_type == <span class="stringliteral">&#39;first&#39;</span>:</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;            <span class="keywordflow">return</span> tensor[:, 0, :]</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;        <span class="keywordflow">elif</span> self.reduction_type == <span class="stringliteral">&#39;max&#39;</span>:</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;            <span class="keywordflow">return</span> tensor.max(dim=1)[0]</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;        <span class="keywordflow">elif</span> self.reduction_type == <span class="stringliteral">&#39;mean&#39;</span>:</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;            divisor = mask.float().sum(dim=1).unsqueeze(-1).clamp(min=1).type_as(tensor)</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;            output = tensor.sum(dim=1) / divisor</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;            <span class="keywordflow">return</span> output</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;        <span class="keywordflow">elif</span> self.reduction_type <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> <span class="stringliteral">&#39;none&#39;</span> <span class="keywordflow">in</span> self.reduction_type:</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;            output = tensor</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;            ret = (output, mask)</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;            <span class="keywordflow">if</span> self.reduction_type == <span class="stringliteral">&#39;none_with_pos_embs&#39;</span>:</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;                ret = (output, mask, position_embs)</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;            <span class="keywordflow">return</span> ret</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;        <span class="keywordflow">else</span>:</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;            <span class="keywordflow">raise</span> ValueError(</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;                <span class="stringliteral">&quot;Can&#39;t handle --reduction-type {}&quot;</span>.<a class="code" href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">format</a>(self.reduction_type)</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;            )</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;</div><div class="ttc" id="namespaceparlai_1_1utils_1_1misc_html_acf146e70ea7f6867969a7c2b545d4b4b"><div class="ttname"><a href="../../d7/db6/namespaceparlai_1_1utils_1_1misc.html#acf146e70ea7f6867969a7c2b545d4b4b">parlai.utils.misc.warn_once</a></div><div class="ttdeci">def warn_once(msg, warningtype=None)</div><div class="ttdef"><b>Definition:</b> <a href="../../d5/d02/misc_8py_source.html#l01064">misc.py:1064</a></div></div>
<div class="ttc" id="namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils_html_a32e2e2022b824fbaf80c747160b52a76"><div class="ttname"><a href="../../d4/d94/namespaceparlai_1_1chat__service_1_1services_1_1messenger_1_1shared__utils.html#a32e2e2022b824fbaf80c747160b52a76">parlai.chat_service.services.messenger.shared_utils.format</a></div><div class="ttdeci">format</div><div class="ttdef"><b>Definition:</b> <a href="../../d6/da3/chat__service_2services_2messenger_2shared__utils_8py_source.html#l00029">shared_utils.py:29</a></div></div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ab56fa99f887753677dc7f4d435595114"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab56fa99f887753677dc7f4d435595114">&#9670;&nbsp;</a></span>dim</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.dim</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00410">410</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="af28dbf5c6c0f70c1a032a3bbb5359661"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af28dbf5c6c0f70c1a032a3bbb5359661">&#9670;&nbsp;</a></span>dropout</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.dropout</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00415">415</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a57f137ae98789edeae26de90118efdd6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a57f137ae98789edeae26de90118efdd6">&#9670;&nbsp;</a></span>embedding_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.embedding_size</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00406">406</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a179492c3f7ebaf6ba8fb3a7f912e93ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a179492c3f7ebaf6ba8fb3a7f912e93ce">&#9670;&nbsp;</a></span>embeddings</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.embeddings</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00432">432</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a80122462ebd32da923d7b4479053ab01"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80122462ebd32da923d7b4479053ab01">&#9670;&nbsp;</a></span>embeddings_scale</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.embeddings_scale</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00411">411</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="afadc86cb37af464565167dc169447057"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afadc86cb37af464565167dc169447057">&#9670;&nbsp;</a></span>ffn_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.ffn_size</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00407">407</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="acbeff4ac94daff4e1627b6d93cd37424"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbeff4ac94daff4e1627b6d93cd37424">&#9670;&nbsp;</a></span>layers</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.layers</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00464">464</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="ab6830a5aa0850e50549c159586c17515"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6830a5aa0850e50549c159586c17515">&#9670;&nbsp;</a></span>n_heads</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.n_heads</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00409">409</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a1fac9c2d34c4d2268f50fc90b1e74e04"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1fac9c2d34c4d2268f50fc90b1e74e04">&#9670;&nbsp;</a></span>n_layers</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.n_layers</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00408">408</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="ab885dd6b80284dbd2837ecaf75f96cb0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab885dd6b80284dbd2837ecaf75f96cb0">&#9670;&nbsp;</a></span>n_positions</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.n_positions</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00419">419</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="ab5ec60adca3ce418f73e409187a82625"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab5ec60adca3ce418f73e409187a82625">&#9670;&nbsp;</a></span>n_segments</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.n_segments</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00417">417</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="ae8676d5d506949c00d35c34ac41b9fff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae8676d5d506949c00d35c34ac41b9fff">&#9670;&nbsp;</a></span>norm_embeddings</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.norm_embeddings</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00454">454</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="afd4ec22c3a8b8611a4a1caa85225b426"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd4ec22c3a8b8611a4a1caa85225b426">&#9670;&nbsp;</a></span>out_dim</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.out_dim</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00420">420</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="ad904c0d06a4f6851b38fbbc0cab224f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad904c0d06a4f6851b38fbbc0cab224f9">&#9670;&nbsp;</a></span>output_scaling</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.output_scaling</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00478">478</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a74702a13d7e41afc3e77c94bb60bd119"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74702a13d7e41afc3e77c94bb60bd119">&#9670;&nbsp;</a></span>padding_idx</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.padding_idx</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00413">413</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="ad2dd819e6d66d17f69e8bfa5026d192a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2dd819e6d66d17f69e8bfa5026d192a">&#9670;&nbsp;</a></span>position_embeddings</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.position_embeddings</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00444">444</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a2703f337fd44344ccd93743e57be554e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2703f337fd44344ccd93743e57be554e">&#9670;&nbsp;</a></span>reduction_type</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.reduction_type</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00412">412</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="acbc50af3764335ae22ef2ba06a65c4a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbc50af3764335ae22ef2ba06a65c4a7">&#9670;&nbsp;</a></span>segment_embeddings</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.segment_embeddings</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00461">461</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<a id="a6ea46aeb8ca865c97ec8e99746bedd7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6ea46aeb8ca865c97ec8e99746bedd7b">&#9670;&nbsp;</a></span>variant</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">parlai.agents.transformer.modules.TransformerEncoder.variant</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html#l00416">416</a> of file <a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>parlai/agents/transformer/<a class="el" href="../../d6/df1/parlai_2agents_2transformer_2modules_8py_source.html">modules.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
